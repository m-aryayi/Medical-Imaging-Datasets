<h2> Awesome Public Medical Imaging Datasets </h2>


<img src="https://upload.wikimedia.org/wikipedia/commons/3/3e/Under_construction_icon-red.svg" alt="Under Construction" height="22"> ***Under construction: This list is being actively updated with additional datasets.***




## Table of Contents

- [Introduction](#introduction)
- [Head and Neck](#head-and-neck)
  - [Brain](#brain)
  - [Ears, Nose, Teeth, and Throat](#ears-nose-teeth-and-throat)
  - [Eyes](#eyes)
- [Chest and Abdomen](#chest-and-abdomen)
  - [Bowel](#bowel)
  - [Breast](#breast)
  - [Heart and Blood Vessels](#heart-and-blood-vessels)
  - [Kidneys and Urinary Tract](#kidneys-and-urinary-tract)
  - [Liver](#liver)
  - [Lungs](#lungs)
- [Musculoskeletal System](#musculoskeletal-system)
  - [Bones](#bones)
  - [Joints](#joints)
- [Pelvis and Reproductive Organs](#pelvis-and-reproductive-organs)
  - [Female Reproductive Organs](#female-reproductive-organs)
  - [Male Reproductive Organs](#male-reproductive-organs)
- [Other Organs and Systems](#other-organs-and-systems)
  - [Lymph Nodes](#lymph-nodes)
  - [Skin](#skin)
- [Multi Oragns Datasets](#multi-organs-datasets)

## Introduction

This repository is a collection of publicly available medical imaging datasets. It aims to provide a comprehensive and valuable resource for researchers, healthcare professionals, and developers working in the field of medical imaging analysis.


- ![Leaderboard](src/leaderboard.png) The link of leaderboard.
- ![paper](src/paper.png) The link of related papers.

![NumberOfDataSet](src/numberOfDatasets.png)

______

## Head and Neck

### Brain


- <a href="https://nda.nih.gov/edit_collection.html?id=3104"> **ABCD Neurocognitive Prediction**</a><br>
T1-weighted MRI scans and fluid intelligence scores for children aged 9–10 year <br>
***Keyboard:***  MRI, Segmentation, Labeled  <br>
<a href="https://arxiv.org/abs/1905.10831"> ![paper](src/paper.png)</a>

- <a href="http://fcon_1000.projects.nitrc.org/indi/abide"> **ABIDE**</a> (Autism Brain Imaging Data Exchange) <br>
***Keyboard:*** Autism spectrum disorders (ASDs), MRI <br>
<a href="https://pubmed.ncbi.nlm.nih.gov/23774715"> ![paper](src/paper.png)</a>

- <a href="http://fcon_1000.projects.nitrc.org/indi/adhd200"> **ADHD-200**</a> (Attention Deficit Hyperactivity Disorder) <br>
776 resting-state fMRI and anatomical datasets aggregated across 8 independent imaging sites. <br>
<a href="fcon_1000.projects.nitrc.org/indi/adhd200/results.html"> ![Leaderboard](src/leaderboard.png)</a> | <a href="https://www.sciencedirect.com/science/article/pii/S105381191630283X"> ![paper](src/paper.png)</a>

- <a href="https://adni.loni.usc.edu/data-samples/access-data"> **ADNI**</a> (Alzheimer's Disease Neuroimaging Initiative) <br>
***Keyboard:*** Multi-modality <br>
<a href="https://www.neurology.org/doi/abs/10.1212/wnl.0b013e3181cb3e25"> ![paper](src/paper.png)</a>

- <a href="https://www.nitrc.org/projects/age-ility"> **Age-ility**</a><br>
This data set consists of 136 subjects <br>
***Keyboard:*** MRI, EEG <br>
<a href="https://www.sciencedirect.com/science/article/pii/S105381191500347X"> ![paper](src/paper.png)</a>

- <a href="https://nilab-uva.github.io/AOMIC.github.io"> **AOMIC**</a> (the Amsterdam Open MRI Collection) <br>
It is a collection of three datasets with multimodal (3T) MRI data <br>
***Keyboard:*** MRI <br>
<a href="https://www.nature.com/articles/s41597-021-00870-6"> ![paper](src/paper.png) Dataset is described </a>

- <a href="https://atlas.grand-challenge.org"> **ATLAS R2.0**</a> (Anatomical Tracings of Lesions After Stroke) <br>
A larger dataset of T1w MRIs and manually segmented lesion masks <br>
***Keyboard:***  MRI, Segmentation, Labeled  <br>
<a href="https://atlas.grand-challenge.org/evaluation/lesion-segmentation-hidden-test-set/leaderboard/"> ![Leaderboard](src/leaderboard.png)</a> | <a href="https://www.nature.com/articles/s41597-022-01401-7"> ![paper](src/paper.png)</a>

- <a href="https://bigbrain.loris.ca/main.php"> **BigBrain**</a> <br>
Microscopic resolution 3D model of the human brain. <br>
***Keyboard:*** X-ray, Labeled <br>

- <a href="https://bonbid-hie2023.grand-challenge.org"> **BONBID-HIE**</a> (BOston Neonatal Brain Injury Dataset for Hypoxic Ischemic Encephalopathy) <br>
***Keyboard:***  MRI, Segmentation, Labeled  <br>
<a href="https://bonbid-hie2023.grand-challenge.org/evaluation/development-stage/leaderboard"> ![Leaderboard](src/leaderboard.png)</a> | <a href="https://www.biorxiv.org/content/10.1101/2023.06.30.546841v1"> ![paper](src/paper.png)  Data Descriptor</a>

- <a href="https://www.kaggle.com/datasets/ahmedhamada0/brain-tumor-detection"> **BR35H**</a><br>
Brain Tumor Detection <br>
***Keyboard:***  MRI, Detection, Classification, Labeled  <br>

- <a href="https://www.brainsimagebank.ac.uk"> **BRAINS**</a> (Brain Images of Normal Subjects) <br>
***Keyboard:*** MRI <br>
<a href="https://www.sciencedirect.com/science/article/pii/S1053811916000331"> ![paper](src/paper.png)</a>

- <a href="https://www.kaggle.com/datasets/sartajbhuvaji/brain-tumor-classification-mri"> **Brain Tumor Classification**</a> <br>
Classify MRI images into four classes <br>
***Keyboard:*** MRI, Labeled <br>

- <a href="https://www.kaggle.com/datasets/preetviradiya/brian-tumor-dataset"> **Brian Tumor Dataset**</a> <br>
This dataset consists of the scanned images of brain of patient diagnosed of brain tumour.<br>
***Keyboard:*** X-ray, Cancer, Labeled  <br>

- <a href="https://brainptm-2021.grand-challenge.org"> **BrainPTM 2021**</a> (Brain Pre-surgical white matter Tractography Mapping) <br>
Data consists of 75 cases<br>
***Keyboard:*** MRI, Cancer, Segmentation, Labeled  <br>
<a href="https://brainptm-2021.grand-challenge.org/evaluation/challenge/leaderboard"> ![Leaderboard](src/leaderboard.png)</a>

- <a href="https://www.smir.ch/BRATS/Start2012"> **BRATS2012**</a> (Brain Tumor Segmentation) <br>
The tumor and edema regions have been manually delineated.<br>
***Keyboard:*** Multimodal MRI, Cancer, Labeled <br>
<a href="https://ieeexplore.ieee.org/document/6975210"> ![paper](src/paper.png)</a>

- <a href="https://www.smir.ch/BRATS/Start2013"> **BRATS2013**</a> (Brain Tumor Segmentation) <br>
A collection of 60 de-identified clinical cases.l2<br>
***Keyboard:*** Multiparametric, MRI, Cancer, Labeled <br>
<a href="https://ieeexplore.ieee.org/document/6975210"> ![paper](src/paper.png)</a>

- <a href="https://www.smir.ch/BRATS/Start2014"> **BRATS2014**</a> (Brain Tumor Segmentation) <br>
***Keyboard:*** MRI, Cancer, Labeled <br>
<a href="https://ieeexplore.ieee.org/document/6975210"> ![paper](src/paper.png)</a>

- <a href="https://www.smir.ch/BRATS/Start2015"> **BRATS2015**</a> (Brain Tumor Segmentation) <br>
***Keyboard:*** MRI, Cancer, Labeled <br>

- <a href="https://www.med.upenn.edu/sbia/brats2017/data.html"> **BRATS2017**</a> (Brain Tumor Segmentation) <br>
***Keyboard:*** MRI, Cancer, Labeled <br>

- <a href="https://www.med.upenn.edu/sbia/brats2018/data.html"> **BRATS2018**</a> (Brain Tumor Segmentation) <br>
The dataset utilizes multi-institutional pre-operative MRI scans and focuses on the segmentation of intrinsically heterogeneous brain tumors. Furthemore, it also focuses on the prediction of patient overall survival, via integrative analyses of radiomic features and machine learning algorithms. <br>
***Keyboard:*** MRI, Cancer, Labeled <br>

- <a href="https://www.med.upenn.edu/cbica/brats-2019"> **BRATS2019**</a> (Brain Tumor Segmentation) <br>
***Keyboard:*** MRI, Cancer, Labeled <br>
<a href="https://arxiv.org/abs/1811.02629"> ![paper](src/paper.png)</a>

- <a href="https://www.med.upenn.edu/cbica/brats2020"> **BRATS2020**</a> (Brain Tumor Segmentation) <br>
***Keyboard:*** MRI, Cancer, Labeled <br>
<a href="https://arxiv.org/abs/1811.02629"> ![paper](src/paper.png)</a>

- <a href="http://www.braintumorsegmentation.org"> **BRATS2021**</a> (Brain Tumor Segmentation) <br>
***Keyboard:*** MRI, Cancer, Labeled <br>
<a href="https://arxiv.org/abs/1811.02629"> ![paper](src/paper.png)</a>

- <a href="https://www.synapse.org/brats2022"> **BRATS2022**</a> (Brain Tumor Segmentation) <br>
***Keyboard:*** MRI, Cancer, Labeled <br>
<a href="https://www.synapse.org/#!Synapse:syn27046444/wiki/626321"> ![Leaderboard](src/leaderboard.png)</a>

- <a href="https://synapse.org/brats2023"> **BRATS2023**</a> (Brain Tumor Segmentation) <br>
This version addressing additional, populations, tumors (e.g., meningioma), clinical concerns, and technical considerations. <br>
***Keyboard:*** MRI, Cancer, Labeled <br>
<a href="https://www.synapse.org/#!Synapse:syn51156910/wiki/622343"> ![Leaderboard](src/leaderboard.png)</a>

- <a href="https://cada.grand-challenge.org"> **CADA**</a> (Cerebral Aneurysm Detection and Analysis) <br>
Data of patients with cerebral aneurysms without vasospasm were collected for diagnostic and treatment decision purposes.<br>
***Keyboard:*** X-ray rotational angiography (3DRA), Segmentation, Labeled  <br>
<a href="https://cada.grand-challenge.org/evaluation/challenge/leaderboard"> ![Leaderboard](src/leaderboard.png)</a> | <a href="https://www.sciencedirect.com/science/article/abs/pii/S1361841521003789"> ![paper](src/paper.png)</a>

- <a href="https://caddementia.grand-challenge.org"> **CADDementia**</a> (Computer-Aided Diagnosis of Dementia) <br>
***Keyboard:*** Alzheimer's disease (AD), MRI  <br>
<a href="https://caddementia.grand-challenge.org/results_all"> ![Leaderboard](src/leaderboard.png)</a> | <a href="https://www.sciencedirect.com/science/article/abs/pii/S1053811915000737"> ![paper](src/paper.png)</a> | <a href="https://caddementia.grand-challenge.org/Publications"> ![paper](src/paper.png)</a>

- <a href="https://camcan-archive.mrc-cbu.cam.ac.uk/dataaccess"> **Cam-CAN**</a> (Cambridge Centre for Ageing and Neuroscience) <br>
Nearly 700 adults were scanned using structural Magnetic Resonance Imaging, functional MRI, magnetoencephalography, and completed multiple cognitive experiments. <br>
***Keyboard:*** lifespan, MRI, fMRI, MEG <br>
<a href="https://www.sciencedirect.com/science/article/pii/S1053811915008150"> ![paper](src/paper.png)</a> | <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4219118"> ![paper](src/paper.png)</a>

- <a href="http://fcon_1000.projects.nitrc.org/indi/cmi_healthy_brain_network"> **CMI-HBN**</a> (Child Mind Institute Healthy Brain Network) <br>
Data from 10,000 children and adolescents (ages 5-21). <br>
***Keyboard:*** Neuroimaging, MRI, EEG <br>
<a href="https://www.nature.com/articles/sdata2017181"> ![paper](src/paper.png) Data Descriptor</a> 

- <a href="http://fcon_1000.projects.nitrc.org/indi/retro/cobre.html"> **COBRE**</a> (Center for Biomedical Research Excellence)<br>
functional MR data from 72 patients with Schizophrenia and 75 healthy controls (ages ranging from 18 to 65 in each group)<br>
***Keyboard:*** fMRI <br>

- <a href="http://fcon_1000.projects.nitrc.org/indi/CoRR/html"> **CoRR**</a> (Consortium for Reliability and Reproducibility) <br>
It has aggregated 1,629 typical individuals resting state fMRI data. <br>
***Keyboard:*** Resting state fMRI (rfMRI) <br>
<a href="https://www.nature.com/articles/sdata201449"> ![paper](src/paper.png)</a>

- <a href="http://headctstudy.qure.ai"> **CQ500**</a> <br>
A dataset of 491 scans with 193,317 slices <br>
***Keyboard:*** CT Scan <br>
<a href="https://arxiv.org/abs/1803.05854"> ![paper](src/paper.png)</a>

- <a href="https://openneuro.org/datasets/ds002236/versions/1.1.1"> **Cross-Sectional Multidomain Lexical Processing**</a><br>
This dataset explores the neural mechanisms and development of lexical processing through task based fMRI of rhyming, spelling, and semantic judgement tasks in both the auditory and visual modalities.<br>
***Keyboard:*** fMRI <br>
<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6957861"> ![paper](src/paper.png)</a>

- <a href="https://crossmoda.grand-challenge.org"> **crossMoDA 2021**</a> (Cross-Modality Domain Adaptation) <br>
The goal is to segment two key brain structures involved in the follow-up and treatment planning of vestibular schwannoma (VS): the tumour and the cochlea<br>
***Keyboard:*** MRI, Segmentation <br>
<a href="https://crossmoda.grand-challenge.org/evaluation/challenge/leaderboard"> ![Leaderboard](src/leaderboard.png)</a> | <a href="https://www.sciencedirect.com/science/article/pii/S1361841522002560"> ![paper](src/paper.png)</a>

- <a href="https://crossmoda2022.grand-challenge.org"> **crossMoDA 2022**</a> (Cross-Modality Domain Adaptation) <br>
The goal is to segment two key brain structures involved in the follow-up and treatment planning of vestibular schwannoma (VS): the tumour and the cochlea, and to automatically classify hrT2 images with VS according to the Koos grade<br>
***Keyboard:*** MRI, Segmentation <br>
<a href="https://crossmoda2022.grand-challenge.org/evaluation/challenge/leaderboard"> ![Leaderboard](src/leaderboard.png)</a>

- <a href="https://www.synapse.org/#!Synapse:syn51236108/wiki/621615"> **crossMoDA 2023**</a> (Cross-Modality Domain Adaptation) <br>
The 2023 edition extends the segmentation task by including multi-institutional, heterogenous data acquired for routine surveillance purposes and introduces a sub-segmentation for the tumour (intra- and extra-meatal components) thereby leading to a 3 class problem. <br>
***Keyboard:*** MRI, Segmentation <br>

- <a href="https://www.ncbi.nlm.nih.gov/projects/gap/cgi-bin/study.cgi?study_id=phs000607.v3.p2"> **dbGaP**</a> (Genotypes and Phenotype)<br>
Study about Neurodevelopmental Genomics: Trajectories of Complex Phenotypes<br>
***Keyboard:*** MRI, Multimodal Neuroimaging <br>
<a href="https://www.sciencedirect.com/science/article/abs/pii/S1053811915002529"> ![paper](src/paper.png)</a> | <a href="https://www.sciencedirect.com/science/article/abs/pii/S1053811913008331"> ![paper](src/paper.png)</a>

- <a href="http://fcon_1000.projects.nitrc.org/indi/retro/dlbs.html"> **DLBS**</a> (Dallas Lifespan Brain Study)<br>
350 healthy adults, aged 20-89 who are thoroughly characterized in terms of cognition, brain structure and brain function across the adult lifespan<br>
***Keyboard:*** MRI, PET, Cognitive Data <br>

- <a href="https://feta.grand-challenge.org"> **FeTA**</a> (Fetal Tissue Annotation) <br>
A dataset of manually segmented pathological and non-pathological fetal magnetic resonance brain volume reconstructions across a range of gestational ages into different tissue categories <br>
***Keyboard:*** MRI, Labeled, Segmentation <br>
<a href="https://www.nature.com/articles/s41597-021-00946-3"> ![paper](src/paper.png)</a>

- <a href="https://zenodo.org/records/1206163"> **Gray matter segmentation at 7T MRI**</a> <br>
The dataset consist of 7 Tesla MRI anatomical images of living human brains and hand labeled cortical gray matter images. <br>
***Keyboard:*** High field MRI, Labeled, Segmentation <br>
<a href="https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0198335"> ![paper](src/paper.png)</a>

- <a href="https://www.neuroinfo.org/gsp"> **GSP**</a> (Genomics Superstruct Project) <br>
Personality and cognitive measures were obtained on a subset of participants. Each dataset contains a T1-weighted structural MRI scan and either one (n=1,570) or two (n=1,139) resting state functional MRI scans. <br>
***Keyboard:*** MRI <br>
<a href="https://www.nature.com/articles/sdata201531"> ![paper](src/paper.png)</a>

- <a href="https://www.nitrc.org/projects/ibsr/"> **IBSR**</a> (Internet Brain Segmentation Repository)  <br>
Manually-guided expert segmentation results along with magnetic resonance brain image data  <br>
***Keyboard:*** MRI, Labeled  <br>

- <a href="https://instance.grand-challenge.org"> **INSTANCE2022**</a> (INtracranial
hemorrhage SegmenTAtioN ChallengE) <br>
A training set of 100 cases with ground-truth and a validation set with 30 cases without ground-truth labels.<br>
***Keyboard:*** Intracranial hemorrhage (ICH), CT Scan, Labeled  <br>
<a href="https://instance.grand-challenge.org/evaluation/challenge/leaderboard"> ![Leaderboard](src/leaderboard.png)</a> | <a href="https://arxiv.org/abs/2301.03281"> ![paper](src/paper.png)</a>

- <a href="https://iseg2019.web.unc.edu"> **iSeg2019**</a> <br>
6 month old Infant Brain Segmentation<br>
***Keyboard:*** MRI, Labeled  <br>
<a href="https://iseg2019.web.unc.edu/evaluation-results"> ![Leaderboard](src/leaderboard.png)</a> | <a href="https://ieeexplore.ieee.org/document/9339962"> ![paper](src/paper.png)</a>

- <a href="http://www.isles-challenge.org"> **ISLES**</a> (Ischemic Stroke Lesion Segmentation) <br>
It has multi versions in 2015 to 2018 <br>
***Keyboard:*** MRI <br>
<a href="https://pubmed.ncbi.nlm.nih.gov/33957774"> ![paper](src/paper.png)</a>

- <a href="https://isles22.grand-challenge.org"> **ISLES'22**</a> (Ischemic Stroke Lesion Segmentation) <br>
Multimodal MRI infarct segmentation in acute and sub-acute stroke<br>
***Keyboard:*** MRI <br>
<a href="https://isles22.grand-challenge.org/evaluation/preliminary-docker-evaluation/leaderboard"> ![Leaderboard](src/leaderboard.png)</a>

- <a href="https://brain-development.org/ixi-dataset"> **IXI**</a> <br>
This dataset have been collected nearly 600 MR images from normal, healthy subjects. <br>
***Keyboard:*** MRI <br>

- <a href="https://openneuro.org/datasets/ds001486"> **Longitudinal Neuroimaging on Arithmetic Processing**</a><br>
Brain Correlates of Math Development in Children. <br>
***Keyboard:*** MRI <br>
<a href="https://www.nature.com/articles/sdata201940"> ![paper](src/paper.png)</a>

- <a href="https://openneuro.org/datasets/ds001894"> **Longitudinal Neuroimaging on Multisensory Lexical Processing**</a><br>
Longitudinal Brain Correlates of Multisensory Lexical Processing in Children. <br>
***Keyboard:*** MRI <br>
<a href="https://www.nature.com/articles/s41597-019-0338-5"> ![paper](src/paper.png)</a>

- <a href="https://www.massive-data.org/massive-data"> **MASSIVE**</a> (Multiple Acquisitions for Standardization of Structural Imaging Validation and Evaluation)<br>
The database consist of 8000 diffusion-weighted volumes and ten 3D FLAIR, T1-, and T2-weighted datasets of a single healthy subject. <br>
***Keyboard:*** diffusion MRI <br>
<a href="https://pubmed.ncbi.nlm.nih.gov/27173617"> ![paper](src/paper.png)</a>

- <a href="https://mindboggle.info/data.html"> **Mindboggle**</a>  <br>
Manually labeled human brain image data. <br>
***Keyboard:*** MRI, Labeled <br>
<a href="https://www.frontiersin.org/articles/10.3389/fnins.2012.00171/full"> ![paper](src/paper.png)</a>

- <a href="https://www.ucl.ac.uk/drc/research-clinical-trials/minimal-interval-resonance-imaging-alzheimers-disease-miriad"> **MIRIAD**</a> (Minimal Interval Resonance Imaging in Alzheimer's Disease) <br>
Dataset is a series of longitudinal volumetric T1 MRI scans of 46 mild–moderate Alzheimer's subjects and 23 controls. <br>
***Keyboard:*** Alzheimer's disease (AD), MRI <br>
<a href="https://www.sciencedirect.com/science/article/pii/S105381191201230X"> ![paper](src/paper.png) Overview </a>

- <a href="https://www.nitrc.org/projects/multimodal"> **MMRR**</a> (Multi-Modal MRI Reproducibility Resource)<br>
Scan-rescan imaging sessions on 21 healthy volunteers. <br>
***Keyboard:*** MRI, resting state fMRI <br>
<a href="https://www.sciencedirect.com/science/article/abs/pii/S1053811910015259"> ![paper](src/paper.png)</a>

- <a href="https://www.smir.ch/MTOP/Start2016"> **MTOP2016**</a> (Mild Traumatic Brain Injury Outcome Prediction) <br>
***Keyboard:*** MRI, Labeled <br>

- <a href="https://openneuro.org/datasets/ds001021"> **NKI-RS**</a> (Nathan Kline Institute-Rockland Sample)<br>
NKI-RS is an ongoing, institutionally centered endeavor aimed at creating a large-scale (N > 1000), deeply phenotyped, community-ascertained, lifespan sample (ages 6–85 years old) with advanced neuroimaging and genetics. <br>
***Keyboard:*** MRI<br>
<a href="https://www.frontiersin.org/journals/neuroscience/articles/10.3389/fnins.2012.00152/full"> ![paper](src/paper.png)</a>

- <a href="http://www.naturalscenesdataset.org"> **NSD**</a> (Natural Scenes Dataset) <br>
High-resolution fMRI responses to tens of thousands of richly annotated natural scenes <br>
***Keyboard:*** fMRI, Labeled <br>
<a href="https://www.nature.com/articles/s41593-021-00962-x">![paper](src/paper.png) Description of the dataset</a>

- <a href="https://oasis-brains.org"> **OASIS**</a> (Open Access Series of Imaging Studies) <br>
It has multi versions. <br>
***Keyboard:*** Multi modality, Neuroimaging <br>
<a href="https://direct.mit.edu/jocn/article-abstract/19/9/1498/4427/Open-Access-Series-of-Imaging-Studies-OASIS-Cross">![paper](src/paper.png)</a> | <a href="https://direct.mit.edu/jocn/article/22/12/2677/4983/Open-Access-Series-of-Imaging-Studies-Longitudinal"> ![paper](src/paper.png)</a> | <a href="https://www.medrxiv.org/content/10.1101/2019.12.13.19014902v1"> ![paper](src/paper.png)</a> | <a href="https://www.sciencedirect.com/science/article/pii/S2213158220300851"> ![paper](src/paper.png)</a>

- <a href="https://www.nitrc.org/projects/ping"> **PING**</a> (Pediatric Imaging, Neurocognition, and Genetics)<br>
The study includes 1400 children between the ages of 3 and 20 years so that links between genetic variation and developing patterns of brain connectivity can be examined. <br>
***Keyboard:*** MRI<br>
<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4628902"> ![paper](src/paper.png)</a>

- <a href="https://f1000research.com/articles/6-93/v2"> **Prenatal brain**</a><br>
It was collected from three traveling subjects with identical acquisition setting in ten imaging centers. <br>
***Keyboard:*** fetal MRI, Segmentation <br>

- <a href="https://oasis-brains.org"> **PREVENT-AD**</a> (Pre-symptomatic Evaluation of Experimental or Novel Treatments for Alzheimer Disease) <br>
***Keyboard:*** MRI, Labeled <br>
<a href="https://pubmed.ncbi.nlm.nih.gov/33964608">![paper](src/paper.png)</a> | <a href="https://pubmed.ncbi.nlm.nih.gov/32474466"> ![paper](src/paper.png)</a> | <a href="https://pubmed.ncbi.nlm.nih.gov/34192666"> ![paper](src/paper.png)</a>

- <a href="https://realnoisemri.grand-challenge.org"> **RealNoiseMRI**</a> <br>
Evaluating the performance of markerless prospective motion correction and selective reacquisition in a general clinical protocol <br>
***Keyboard:*** MRI <br>

- <a href="https://archive.norstore.no/pages/public/datasetDetail.jsf?id=10.11582/2017.00004"> **RESECT**</a> (REtroSpective Evaluation of Cerebral Tumors)  <br>
A clinical database of pre-oper, ative MRI and intra-operative ultrasound in low-grade glioma surgeries <br>
***Keyboard:*** Cancer, Registration, Labeled <br>
<a href="https://aapm.onlinelibrary.wiley.com/doi/full/10.1002/mp.12268"> ![paper](src/paper.png)</a>

- <a href="https://www.rsna.org/rsnai/ai-image-challenge/brain-tumor-ai-challenge-2021"> **RSNA Brain Tumor**</a> (Radiological Society of North America 2021) <br>
A dataset for brain tumor segmentation and radiogenomic classification <br>
***Keyboard:*** MRI, Labeled <br>

- <a href="https://www.rsna.org/rsnai/ai-image-challenge/rsna-intracranial-hemorrhage-detection-challenge-2019"> **RSNA Intracranial Hemorrhage Detection**</a> (Radiological Society of North America 2019) <br>
A dataset of more than 25,000 annotated cranial CT exams <br>
***Keyboard:*** CT scan, Labeled<br>
<a href="https://pubmed.ncbi.nlm.nih.gov/33937827"> ![paper](src/paper.png)</a>

- <a href="http://fcon_1000.projects.nitrc.org/indi/retro/sald.html"> **SALD**</a> (Southwest University Adult Lifespan Dataset)<br>
494 healthy adults (age range: 19-80 years; Males=187) were recruited and completed two multi-modal MRI scan sessions. <br>
***Keyboard:*** MRI, resting-state functional MRI (rs-fMRI)<br>
<a href="https://www.biorxiv.org/content/10.1101/177279v2"> ![paper](src/paper.png) Detailed description </a>

- <a href="https://shifts.grand-challenge.org"> **Shifts Challenge 2022**</a><br>
White Matter Multiple Sclerosis (MS) lesion segmentation in 3D Magnetic Resonance Imaging (MRI) of the brain <br>
***Keyboard:*** MRI <br>
<a href="https://shifts.grand-challenge.org/evaluation/ms-lesion-segmentation-phase-i/leaderboard"> ![Leaderboard](src/leaderboard.png)</a>

- <a href="http://fcon_1000.projects.nitrc.org/indi/retro/SIMON.html"> **SIMON**</a> (Single Individual volunteer for Multiple Observations across Networks)<br>
A sample of convenience of one healthy male aged between 29 and 46 years old, scanned in 73 sessions at multiple sites and with various scanner models. <br>
***Keyboard:*** MRI <br>

- <a href="https://slcn.grand-challenge.org"> **SLCN**</a> (Surface Learning for Clinical Neuroimaging)  <br>
Part of the <a href="http://www.developingconnectome.org"> dHCP</a> (Developing Human Connectome Project) <br>
***Keyboard:*** MRI <br>
<a href="https://slcn.grand-challenge.org/evaluation/preliminary-phase/leaderboard"> ![Leaderboard](src/leaderboard.png)</a>

- <a href="https://www.studyforrest.org"> **StudyForrest**</a> <br>
A Collection of datasets <br>
<a href="https://www.studyforrest.org/publications.html"> ![paper](src/paper.png) List of publications</a>

- <a href="https://surfer.nmr.mgh.harvard.edu/docs/synthstrip"> **SynthStrip**</a> <br>
***Keyboard:*** Multi-modality, Labeled, Segmentation <br>
<a href="https://www.sciencedirect.com/science/article/pii/S1053811922005900"> ![paper](src/paper.png)</a>

- <a href="http://hiresmri.ovgu.de"> **T1-weighted with 250 μm resolution**</a><br>
T1-weighted in vivo human whole brain MRI dataset with an ultrahigh isotropic resolution of 250 μm.<br>
***Keyboard:*** MRI, High field MRI<br>
<a href="https://www.nature.com/articles/sdata201732"> ![paper](src/paper.png)</a>

- <a href="https://topcow23.grand-challenge.org"> **TopCoW**</a> <br>
Topology-Aware Anatomical Segmentation of the Circle of Willis <br>
***Keyboard:*** Magnetic Resonance Angiography (MRA) and Computed Tomography Angiography (CTA) <br>
<a href="https://topcow23.grand-challenge.org/evaluation/validation-cta-multiclass/leaderboard"> ![Leaderboard](src/leaderboard.png)</a> | <a href="https://arxiv.org/abs/2312.17670"> ![paper](src/paper.png)</a>

- <a href="https://valdo.grand-challenge.org"> **VALDO**</a> (VAscular Lesions DetectiOn)  <br>
***Keyboard:*** MRI, cerebral small vessel disease (CSVD), Labeled  <br>
<a href="https://zenodo.org/records/4600654"> ![paper](src/paper.png)</a>



### Ears, Nose, Teeth, and Throat

- <a href="https://dentex.grand-challenge.org"> **DENTEX**</a> <br>
Dental Enumeration and Diagnosis on Panoramic X-rays <br>
***Keyboard:*** X-rays, Labeled <br>
<a href="https://dentex.grand-challenge.org/evaluation/challenge/leaderboard"> ![Leaderboard](src/leaderboard.png)</a> | <a href="https://arxiv.org/abs/2305.19112"> ![paper](src/paper.png)</a> | <a href="https://arxiv.org/abs/2303.06500"> ![paper](src/paper.png)</a>

- <a href="https://github.com/abenhamadou/3DTeethSeg22_challenge"> **3DTeethSeg22**</a> <br>
A total of 1800 3D intra-oral scan for 900 patients covering their upper and lower jaws separately.<br>
***Keyboard:***  Labeeld, Segmentation <br>
<a href="https://arxiv.org/abs/2305.18277"> ![paper](src/paper.png)</a> | <a href="https://arxiv.org/abs/2210.06094"> ![paper](src/paper.png)</a>

- <a href="https://zenodo.org/records/1473724"> **OpenEar**</a> <br>
A library consisting of eight three-dimensional models of the human temporal bone. <br>
***Keyboard:***  Cone Beam Computed Tomography (CBCT) <br>
<a href="https://www.nature.com/articles/sdata2018297"> ![paper](src/paper.png)</a>

- <a href="https://tn-scui2020.grand-challenge.org"> **TN-SCUI2020**</a> (Thyroid Nodule Segmentation and Classification in Ultrasound Images) <br>
A dataset of thyroid nodule with over 4,500 patient <br>
***Keyboard:***  Ultrasound Image, Thyroid <br>
<a href="https://tn-scui2020.grand-challenge.org/evaluation/challenge/leaderboard"> ![Leaderboard](src/leaderboard.png)</a>

- <a href="https://ditto.ing.unimore.it/toothfairy"> **ToothFairy**</a> <br>
A dataset of dental scans obtained by 3D CBCT <br>
***Keyboard:***  Cone Beam Computed Tomography (CBCT), Segmentation <br>
<a href="https://toothfairy.grand-challenge.org/evaluation/challenge/leaderboard"> ![Leaderboard](src/leaderboard.png)</a> | <a href="https://link.springer.com/chapter/10.1007/978-3-031-43148-7_44"> ![paper](src/paper.png)</a>



### Eyes

- <a href="https://amd.grand-challenge.org"> **ADAM**</a> <br>
Diagnosis of Age-related Macular degeneration (AMD) and segmentation of lesions in fundus photos from AMD patients <br>
***Keyboard:*** Labeled  <br>
<a href="https://amd.grand-challenge.org/evaluation/challenge/leaderboard/"> ![Leaderboard](src/leaderboard.png)</a> | <a href="https://ieeexplore.ieee.org/document/9768802"> ![paper](src/paper.png)</a>

- <a href="https://age.grand-challenge.org"> **AGE**</a> (Angle closure Glaucoma Evaluation) <br>
A dataset of 4800 annotated AS-OCT images<br>
***Keyboard:*** OCT <br>
<a href="https://age.grand-challenge.org/evaluation/challenge/leaderboard"> ![Leaderboard](src/leaderboard.png)</a> | <a href="https://pubmed.ncbi.nlm.nih.gov/31036585"> ![paper](src/paper.png) Clinical Background</a> | <a href="https://www.sciencedirect.com/science/article/abs/pii/S1361841520301626"> ![paper](src/paper.png)</a>

- <a href="https://airogs.grand-challenge.org"> **AIROGS**</a> (Artificial Intelligence for RObust Glaucoma Screening) <br>
This dataset includes around 113,000 images from about 60,000 patients<br>
***Keyboard:*** Fundus Images <br>
<a href="https://airogs.grand-challenge.org/evaluation/preliminary-test-phase-1/leaderboard"> ![Leaderboard](src/leaderboard.png)</a> | <a href="https://ieeexplore.ieee.org/abstract/document/10253652"> ![paper](src/paper.png) Summary Paper</a>

- <a href="https://cataracts.grand-challenge.org"> **CATARACTS**</a> <br>
Surgical tool detection in 50 videos of cataract surgeries<br>
***Keyboard:*** Video, Labeled  <br>
<a href="https://cataracts.grand-challenge.org/Results"> ![Leaderboard](src/leaderboard.png)</a> | <a href="https://www.sciencedirect.com/science/article/abs/pii/S136184151830865X"> ![paper](src/paper.png)</a>

- <a href="https://blogs.kingston.ac.uk/retinal/chasedb1"> **CHASE-DB1**</a> <br>
***Keyboard:*** Retinal, Labeled <br>

- <a href="https://drac22.grand-challenge.org"> **DRAC 2022**</a> (Diabetic Retinopathy Analysis Challenge) <br>
A ultra-wide optical coherence tomography angiography (UW-OCTA) dataset addressing three primary clinical tasks: DR lesion segmentation, image quality assessment, and DR grading.<br>
***Keyboard:*** Diabetic retinopathy, Segmentation, Classification<br>
<a href="https://drac22.grand-challenge.org/evaluation/challenge/leaderboard"> ![Leaderboard](src/leaderboard.png)</a> | <a href="https://arxiv.org/abs/2304.02389"> ![paper](src/paper.png)</a> | <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4593632"> ![paper](src/paper.png)</a>

- <a href="https://ipg.fer.hr/ipg/resources/image_database"> **DRiDB**</a> (Diabetic Retinopathy Image Dataset)<br>
***Keyboard:*** Fundus Images, Diabetic retinopathy<br>
<a href="https://ieeexplore.ieee.org/document/6703830"> ![paper](src/paper.png)</a>

- <a href="https://drive.grand-challenge.org"> **DRIVE**</a> (Digital Retinal Images for Vessel Extraction) <br>
***Keyboard:*** Retinal, Segmentation <br>
<a href="https://drive.grand-challenge.org/evaluation/challenge/leaderboard"> ![Leaderboard](src/leaderboard.png)</a> 

- <a href="https://projects.ics.forth.gr/cvrl/fire"> **FIRE**</a> (Fundus Image Registration Dataset) <br>
***Keyboard:*** Retinal, Labeled

- <a href="https://aistudio.baidu.com/competition/detail/90/0/introduction"> **GAMMA**</a> <br>
The dataset consists of 2D fundus images and 3D optical coherence tomography (OCT) images of 300 patients. The dataset was annotated with glaucoma grade in every sample, and macular fovea coordinates as well as optic disc/cup segmentation mask in the fundus image. <br>
***Keyboard:*** OCT images <br>
<a href="https://aistudio.baidu.com/competition/detail/90/0/leaderboard"> ![Leaderboard](src/leaderboard.png)</a> | <a href="https://arxiv.org/abs/2202.06511"> ![paper](src/paper.png)</a>

- <a href="https://idrid.grand-challenge.org/"> **IDRiD**</a> (Indian Diabetic Retinopathy Image Dataset) <br>
<a href="https://www.sciencedirect.com/science/article/abs/pii/S1361841519301033?via%3Dihub"> ![paper](src/paper.png) First Results and Analysis</a>  | <a href="https://www.mdpi.com/2306-5729/3/3/25"> ![paper](src/paper.png) Data Descriptor</a> 

- <a href="https://justraigs.grand-challenge.org"> **JustRAIGS**</a> (Justified Referral in AI Glaucoma Screening) <br>
The dataset is divided into a training subset with 101,442 gradable fundus images, spanning both referable and no referable glaucomatous cases, and a test subset comprising 9,741 fundus images. <br>
***Keyboard:*** Fundus Images, Labeled  <br>
<a href="https://justraigs.grand-challenge.org/evaluation/development-phase/leaderboard"> ![Leaderboard](src/leaderboard.png)</a> | <a href="https://www.sciencedirect.com/science/article/pii/S2666914523000325"> ![paper](src/paper.png)</a>

- <a href="https://github.com/SaharAlmahfouzNasser/MeDAL-Retina"> **MeDAL Retina Dataset**</a>  <br>
***Keyboard:*** Retinal, Labeled <br>
<a href="https://arxiv.org/pdf/2307.10698.pdf"> ![paper](src/paper.png) Comprehensive details</a> 

- <a href="https://blogs.kingston.ac.uk/retinal/messidor-ma-groundturth"> **Messidor MA Groundturth**</a> <br>
Microaneurysm (MA) detection in 20 retinal images <br>
***Keyboard:*** Retinal, Labeled <br>
<a href="https://ieeexplore.ieee.org/abstract/document/7820998"> ![paper](src/paper.png)</a>  | <a href="https://www.sciencedirect.com/science/article/pii/S2352914817300229"> ![paper](src/paper.png)</a>

- <a href="https://odir2019.grand-challenge.org"> **ODIR 2019**</a> (Ocular Disease Intelligent Recognition) <br>
A database of 5000 patients with age, color fundus photographs from left and right eyes <br>
***Keyboard:*** Labeled<br>
<a href="https://odir2019.grand-challenge.org/evaluation/challenge/leaderboard"> ![Leaderboard](src/leaderboard.png)</a>

- <a href="https://palm.grand-challenge.org"> **PALM**</a> <br>
Investigation and development of algorithms associated with the diagnosis of Pathological Myopia (PM) and segmentation of lesions in fundus photos from PM patients. <br>
***Keyboard:*** Labeled <br>
<a href="https://palm.grand-challenge.org/evaluation/challenge/leaderboard"> ![Leaderboard](src/leaderboard.png)</a>

- <a href="https://ravir.grand-challenge.org"> **RAVIR**</a> <br>
A Dataset and Methodology for the Semantic Segmentation and Quantitative Analysis of Retinal Arteries and Veins in Infrared Reflectance Imaging <br>
<a href="https://ravir.grand-challenge.org/evaluation/challenge/leaderboard"> ![Leaderboard](src/leaderboard.png)</a> | <a href="https://ieeexplore.ieee.org/abstract/document/9744459"> ![paper](src/paper.png)</a> | <a href="https://escholarship.org/uc/item/4r63v2bd"> ![paper](src/paper.png)</a>

- <a href="https://refuge.grand-challenge.org"> **REFUGE**</a> (Retinal Fundus Glaucoma) <br>
A data set of 1200 fundus images with ground truth segmentations and clinical glaucoma labels <br>
***Keyboard:*** Segmentation, Classification, Labeled <br>
<a href="https://refuge.grand-challenge.org/evaluation/challenge/leaderboard/"> ![Leaderboard](src/leaderboard.png)</a> | <a href="https://www.sciencedirect.com/science/article/abs/pii/S1361841519301100"> ![paper](src/paper.png)</a> | <a href="https://www.nature.com/articles/s41746-020-00329-9"> ![paper](src/paper.png)</a>

- <a href="https://retouch.grand-challenge.org"> **RETOUCH**</a> (Retinal OCT Fluid Challenge) <br>
Detect and segment various types of fluids on a common dataset of optical coherence tomography (OCT) volumes representing different retinal diseases, acquired with devices from different manufacturers. <br>
***Keyboard:*** OCT images <br>
<a href="https://retouch.grand-challenge.org/Results"> ![Leaderboard](src/leaderboard.png)</a> | <a href="https://ieeexplore.ieee.org/document/8653407"> ![paper](src/paper.png)</a>

- <a href="https://riadd.grand-challenge.org"> **RFMiD**</a> (Retinal Fundus Multi-Disease Image Dataset) <br>
It consists of 3200 fundus images<br>
***Keyboard:*** Fundus Images, Classification <br>
<a href="https://riadd.grand-challenge.org/evaluation/challenge/leaderboard"> ![Leaderboard](src/leaderboard.png)</a> | <a href="https://www.mdpi.com/2306-5729/6/2/14"> ![paper](src/paper.png) Data Descriptor</a> 

- <a href="http://webeye.ophth.uiowa.edu/ROC"> **ROC**</a> (Retinopathy Online Challenge) <br>
50 training images and 50 test images <br>
***Keyboard:*** Diabetic retinopathy, Fundus Images, Labeled <br>
<a href="https://ieeexplore.ieee.org/document/5282586"> ![paper](src/paper.png) Overview</a> 

- <a href="https://rocc.grand-challenge.org"> **ROCC**</a> (Retinal OCT Classification Challenge) <br>
A dataset of OCT volumes, acquired with Topcon SD-OCT devices <br>
***Keyboard:*** OCT images, Diabetic retinopathy <br>

- <a href="https://aistudio.baidu.com/competition/detail/1101/0/introduction"> **STAGE**</a> (Structural-Functional Transition in Glaucoma Assessment) <br>
400 OCT data and corresponding Visual Field test reports with Mean Deviation (MD) values, sensitivity maps and pattern deviation probability map labels. <br>
***Keyboard:*** OCT images <br>
<a href="https://aistudio.baidu.com/competition/detail/1101/0/leaderboard"> ![Leaderboard](src/leaderboard.png)</a>

- <a href="https://cecas.clemson.edu/~ahoover/stare"> **STARE**</a> (STructured Analysis of the Retina) <br>
***Keyboard:*** Labeled <br>

- <a href="https://blogs.kingston.ac.uk/retinal/uk-biobank"> **UK Biobank**</a> <br>
2 sets of manual segmentations for 20 UK Biobank retinal images <br>
***Keyboard:*** Retinal, Labeled <br>
<a href="https://ieeexplore.ieee.org/abstract/document/8310108"> ![paper](src/paper.png)</a>

______

## Chest and Abdomen


### Bowel

- <a href="https://conic-challenge.grand-challenge.org"> **CoNIC**</a> (Colon Nuclei Identification and Counting) <br>
***Keyboard:*** whole-slide images (WSI), Nuclear segmentation and classification <br>
<a href="https://conic-challenge.grand-challenge.org/evaluation/challenge/leaderboard"> ![Leaderboard](src/leaderboard.png)</a> | <a href="https://arxiv.org/abs/2111.14485"> ![paper](src/paper.png)</a> 

- <a href="https://digestpath2019.grand-challenge.org"> **Digestpath2019**</a> (Digestive-System Pathological 2019)<br>
Colonoscopy tissue segmentation and classification and Signet ring cell detection dataset  <br>
***Keyboard:*** Whole slide image (WSI), Cancer, Labeled <br>
<a href="https://www.sciencedirect.com/science/article/abs/pii/S1361841522001323"> ![paper](src/paper.png)</a> 

- <a href="https://endocv2021.grand-challenge.org"> **EndoCV2021**</a> (Endoscopy Computer Vision 2021)<br>
Addressing generalisability in polyp detection and segmentation <br>
***Keyboard:*** Colonoscopy, Labeled <br>

- <a href="https://paip2020.grand-challenge.org"> **PAIP2020**</a> <br>
Classification of molecular subtypes in colorectal cancer for whole-slide image analyses <br>
<a href="https://paip2020.grand-challenge.org/evaluation/validation/leaderboard/"> ![Leaderboard](src/leaderboard.png)</a>

- <a href="https://2023paip.grand-challenge.org"> **PAIP2023**</a> <br>
Tumor cellularity prediction in pancreatic cancer (supervised learning) and colon cancer (transfer learning) <br>
<a href="https://2023paip.grand-challenge.org/evaluation/challenge/leaderboard"> ![Leaderboard](src/leaderboard.png)</a>

- <a href="https://wiki.cancerimagingarchive.net/pages/viewpage.action?pageId=3539213"> **The National CT Colonography Trial (ACRIN 6664)**</a> <br>
A collection contains 825 cases of CT colonography imaging with accompanying spreadsheets that provide polyp descriptions and their location within the colon segments. <br>
<a href="https://www.nejm.org/doi/full/10.1056/NEJMoa0800996"> ![paper](src/paper.png)</a> 




### Breast

- <a href="https://wiki.cancerimagingarchive.net/pages/viewpage.action?pageId=30671268"> **ACRIN-FLT-Breast (ACRIN 6688)**</a> <br>
Examination both pre-therapy and post-therapy <br>
***Keyboard:*** 18F-FLT PET imaging, CT Scan, Cancer <br>

- <a href="https://acrobat.grand-challenge.org"> **ACROBAT**</a> (AutomatiC Registration Of Breast cAncer Tissue) <br>
Consisting of 4212 WSIs from 1153 patients <br>
***Keyboard:*** whole-slide images (WSI), Cancer <br>
<a href="https://acrobat.grand-challenge.org/evaluation/model-development/leaderboard"> ![Leaderboard](src/leaderboard.png)</a> | <a href="http://arxiv.org/abs/2211.13621"> ![paper](src/paper.png)</a> 

- <a href="https://iciar2018-challenge.grand-challenge.org"> **BACH**</a> (BreAst Cancer Histology) <br>
***Keyboard:*** Biopsy, Cancer <br>
<a href="https://iciar2018-challenge.grand-challenge.org/evaluation/part-a/leaderboard/"> ![Leaderboard](src/leaderboard.png)</a> | <a href="https://www.sciencedirect.com/science/article/abs/pii/S1361841518307941"> ![paper](src/paper.png)</a>

- <a href="https://bci.grand-challenge.org"> **BCI**</a> (Breast Cancer Immunohistochemical) <br>
***Keyboard:*** hematoxylin and eosin (HE) stained images, Image Generation, Labeled <br>
<a href="https://bci.grand-challenge.org/evaluation/challenge/leaderboard"> ![Leaderboard](src/leaderboard.png)</a> | <a href="Breast Cancer Immunohistochemical"> ![paper](src/paper.png)</a>

- <a href="https://bcnb.grand-challenge.org"> **BCNB**</a> (Breast Cancer Core-Needle Biopsy) <br>
A dataset of Early Breast Cancer Core-Needle Biopsy WSI, which includes core-needle biopsy whole slide images of early breast cancer patients and the corresponding clinical data.  <br>
***Keyboard:***  Whole-Slide Images (WSIs), Labeled <br>
<a href="https://pubmed.ncbi.nlm.nih.gov/34722313"> ![paper](src/paper.png)</a>

- <a href="https://github.com/PathologyDataScience/BCSS"> **BCSS**</a> (Breast Cancer Semantic Segmentation) <br>
The dataset contains over 20,000 segmentation annotations of tissue region from breast cancer images from TCGA. <br>
***Keyboard:***  Cancer, Labeled <br>
<a href="https://academic.oup.com/bioinformatics/article/35/18/3461/5307750"> ![paper](src/paper.png)</a>

- <a href="https://web.inf.ufpr.br/vri/databases/breast-cancer-histopathological-database-breakhis"> **BreakHis**</a> (Breast Cancer Histopathological) <br>
A dataset of 7909 breast cancer histopathology images acquired on 82 patients <br>
***Keyboard:*** Cancer, Labeled <br>
<a href="https://ieeexplore.ieee.org/document/7312934"> ![paper](src/paper.png)</a>

- <a href="https://www.kaggle.com/datasets/sabermalek/bcfpp"> **Breast Cancer CT**</a> <br>
***Keyboard:*** CT Scan, Labeled, Cancer <br>

- <a href="https://www.cancerimagingarchive.net/collection/breast-cancer-screening-dbt"> **Breast-Cancer-Screening-DBT**</a> (Digital Breast Tomosynthesis) <br>
It contains 22,032 reconstructed DBT volumes belonging to 5,610 studies from 5,060 patients. <br>
***Keyboard:*** Mammography, Cancer <br>
<a href="https://arxiv.org/abs/2011.07995"> ![paper](src/paper.png)</a>

- <a href="https://breastpathq.grand-challenge.org/"> **BreastPathQ**</a> <br>
Development of quantitative biomarkers for the determination of cancer cellularity from whole slide images (WSI) of breast cancer hematoxylin and eosin (H&E) stained pathological slides <br>
***Keyboard:*** Cancer, Haematoxylin and eosin (H&E) stained slides <br>
<a href="https://breastpathq.grand-challenge.org/evaluation/challenge/leaderboard"> ![Leaderboard](src/leaderboard.png)</a>

- <a href="https://wiki.cancerimagingarchive.net/pages/viewpage.action?pageId=22516629"> **CBIS-DDSM**</a> (Curated Breast Imaging Subset of Digital Database for Screening Mammography) <br>
The DDSM is a database of 2,620 scanned film mammography studies. It contains normal, benign, and malignant cases with verified pathology information. <br>
***Keyboard:***  Cancer, Labeled <br>
<a href="https://www.nature.com/articles/sdata2017177"> ![paper](src/paper.png)</a>

- <a href="https://wiki.cancerimagingarchive.net/pages/viewpage.action?pageId=70226903"> **Duke Breast Cancer MRI**</a> <br>
Dynamic contrast-enhanced magnetic resonance images of breast cancer patients with tumor locations. <br>
***Keyboard:*** Cancer, Labeled <br>
<a href="https://www.nature.com/articles/s41416-018-0185-8"> ![paper](src/paper.png)</a>

- <a href="https://ecdp2020.grand-challenge.org"> **HEROHE**</a> (HER2 on hematoxylin and eosin) <br>
The dataset consists of annotated, whole-slide images dataset (509), specifically collected for predicting human epidermal growth factor receptor 2 (HER2) status <br>
***Keyboard:*** whole-slide images (WSI), Cancer <br>
<a href="https://www.mdpi.com/2313-433X/8/8/213"> ![paper](src/paper.png)</a>

- <a href="https://www.kaggle.com/datasets/martholi/inbreast"> **INbreast**</a> <br>
The database has a total of 115 cases (410 images) from which 90 cases are from women with both breasts affected and 25 cases are from mastectomy patients. <br>
***Keyboard:*** Mammography, Cancer <br>
<a href="https://pubmed.ncbi.nlm.nih.gov/22078258"> ![paper](src/paper.png)</a>

- <a href="https://www.kaggle.com/datasets/kmader/mias-mammography"> **MIAS**</a> <br>
***Keyboard:*** Mammography, Cancer, Labeled <br>

- <a href="https://imig.science/midog2021"> **MIDOG 2021**</a> (Mitosis Domain Generalization 2021) <br>
Detect mitotic figures (cells undergoing cell division) from histopathology images (object detection) <br>
***Keyboard:*** Whole-Slide Images (WSI), Cancer, Labeled <br>
<a href="https://midog2021.grand-challenge.org/evaluation/challenge/leaderboard"> ![Leaderboard](src/leaderboard.png)</a> | <a href="https://www.sciencedirect.com/science/article/abs/pii/S1361841522003279"> ![paper](src/paper.png)</a> 

- <a href="https://imig.science/midog"> **MIDOG 2022**</a> (Mitosis Domain Generalization 2022) <br>
Detect mitotic figures (cells undergoing cell division) from histopathology images (object detection) <br>
***Keyboard:*** Whole-Slide Images (WSI), Cancer, Labeled <br>
<a href="https://midog2022.grand-challenge.org/evaluation/challenge/leaderboard"> ![Leaderboard](src/leaderboard.png)</a> | <a href="https://arxiv.org/abs/2309.15589"> ![paper](src/paper.png)</a>

- <a href="https://www.kaggle.com/datasets/cheddad/miniddsm2"> **Mini-DDSM**</a> (Digital Database for Screening Mammography) <br>
This is the light-weight version of the popular DDSM. <br>
***Keyboard:*** Mammography, Cancer <br>
<a href="https://dl.acm.org/doi/abs/10.1145/3441369.3441370"> ![paper](src/paper.png)</a>

- <a href="https://tdsc-abus2023.grand-challenge.org"> **MITOS-ATYPIA-14**</a> <br>
It is made up of two parts: Detection of mitosis on the one hand, and evaluation of nuclear atypia score on the other hand. <br>
***Keyboard:*** Cancer, Haematoxylin and eosin (H&E) stained slides <br>
<a href="https://mitos-atypia-14.grand-challenge.org/Results2"> ![Leaderboard](src/leaderboard.png)</a>

- <a href="https://sites.google.com/view/nucls"> **NuCLS**</a> <br>
The datasets contain over 220000 labeled nuclei from breast cancer images from TCGA <br>
***Keyboard:***  Cancer, Labeled <br>
<a href="https://arxiv.org/abs/2102.09099"> ![paper](src/paper.png)</a>

- <a href="https://wiki.cancerimagingarchive.net/display/Public/QIN-Breast"> **QIN-Breast**</a> <br>
This collection contains longitudinal PET/CT and quantitative MR images collected for the purpose of studying treatment assessment in breast cancer in the neoadjuvant setting. <br>
***Keyboard:*** PET/CT, MRI, Cancer <br>

- <a href="https://wiki.cancerimagingarchive.net/display/Public/QIN-BREAST-02"> **QIN-Breast-02**</a> <br>
This data is from a multi-site, multi-parametric quantitative MRI study of adult (18+ years old) females diagnosed with invasive breast cancer. <br>
***Keyboard:*** Cancer <br>

- <a href="https://wiki.cancerimagingarchive.net/display/Public/RIDER+Breast+MRI"> **RIDER Breast MRI**</a> (Reference Image Database to Evaluate Therapy Response) <br>
RIDER is a targeted data collection used to generate an initial consensus on how to harmonize data collection and analysis for quantitative imaging methods applied to measure the response to drug or radiation therapy. <br>
***Keyboard:***  Cancer <br>

- <a href="https://www.rsna.org/rsnai/ai-image-challenge/screening-mammography-breast-cancer-detection-ai-challenge"> **RSNA Screening Mammography Breast Cancer Detection**</a> (Radiological Society of North America 2023) <br>
***Keyboard:*** Radiographic breast images, Labeled<br>
<a href="https://www.kaggle.com/competitions/rsna-breast-cancer-detection/leaderboard"> ![Leaderboard](src/leaderboard.png)</a>

- <a href="https://tdsc-abus2023.grand-challenge.org"> **TDSC-ABUS2023**</a> (Tumor Detection, Segmentation and Classification Challenge on Automated 3D Breast Ultrasound 2023) <br>
***Keyboard:*** Ultrasound, Cancer, Labeled <br>
<a href="https://tdsc-abus2023.grand-challenge.org/evaluation/challenge/leaderboard"> ![Leaderboard](src/leaderboard.png)</a>

- <a href="https://tiger.grand-challenge.org"> **TIGER**</a> (Tumor InfiltratinG lymphocytes in breast cancER) <br>
***Keyboard:***  H&E Whole-Slide Images (WSI), Cancer, Detecion, Segmentation <br>
<a href="https://tiger.grand-challenge.org/evaluation/segmentation-and-detection-public-test/leaderboard"> ![Leaderboard](src/leaderboard.png)</a>

- <a href="https://tupac.grand-challenge.org"> **TUPAC**</a> (Tumor Proliferation Assessment Challenge) <br>
The dataset consisted of 500 training and 321 testing breast cancer histopathology WSIs. <br>
***Keyboard:***  Whole-Slide Images, Cancer <br>
<a href="https://pubmed.ncbi.nlm.nih.gov/30861443"> ![paper](src/paper.png)</a>




### Heart and Blood Vessels

- <a href="https://www.creatis.insa-lyon.fr/Challenge/acdc"> **ACDC**</a> (Automated Cardiac Diagnosis Challenge) <br>
The dataset contains data from 150 multi-equipments CMRI recordings with reference measurements and classification from two medical experts. <br>
***Keyboard:***  Cardiac MRI (CMR), Segmentation <br>
<a href="https://www.creatis.insa-lyon.fr/Challenge/acdc/results.html"> ![Leaderboard](src/leaderboard.png)</a> | <a href="https://pubmed.ncbi.nlm.nih.gov/29994302"> ![paper](src/paper.png)</a>

- <a href="https://arcade.grand-challenge.org"> **ARCADE**</a> <br>
Automatic Region-based Coronary Artery Disease Diagnostics Using X-Ray Angiography Images <br>
***Keyboard:***  X-ray coronary angiography, Labeled <br>
<a href="https://arcade.grand-challenge.org/evaluation/phase_1_segmentation_detection/leaderboard"> ![Leaderboard](src/leaderboard.png)</a> | <a href="https://www.nature.com/articles/s41597-023-02871-z"> ![paper](src/paper.png)</a>

- <a href="https://asoca.grand-challenge.org"> **ASOCA**</a> (Automated Segmentation of Coronary Arteries) <br>
A set of Cardiac Computed Tomography Angiography (CCTA) with contrast agent showing the coronary arteries <br>
***Keyboard:***  CCTA, Labeled <br>
<a href="https://asoca.grand-challenge.org/evaluation/challenge/leaderboard"> ![Leaderboard](src/leaderboard.png)</a>

- <a href="https://camus.creatis.insa-lyon.fr/challenge"> **CAMUS**</a> (Cardiac Acquisitions for Multi-structure Ultrasound Segmentation) <br>
The dataset consists of clinical exams from 500 patients<br>
***Keyboard:***  2D echocardiographic images <br>
<a href="https://www.creatis.insa-lyon.fr/Challenge/camus/results.html"> ![Leaderboard](src/leaderboard.png)</a> | <a href="https://pubmed.ncbi.nlm.nih.gov/30802851"> ![paper](src/paper.png)</a>

- <a href="https://www.kaggle.com/datasets/xiaoweixumedicalai/imagealcapa"> **CardiacUDA**</a> (Unsupervised Domain Adaption) <br>
***Keyboard:*** Echocardiogram Videos <br>
<a href="https://arxiv.org/abs/2309.11145"> ![paper](src/paper.png)</a>

- <a href="https://vessel-wall-segmentation.grand-challenge.org"> **Carotid Artery Vessel Wall**</a> <br>
***Keyboard:*** Segmentation, Labeled <br>

- <a href="https://www.creatis.insa-lyon.fr/Challenge/CETUS/"> **CETUS**</a> (Challenge on Endocardial Three-dimensional Ultrasound Segmentation) <br>
The dataset is composed of 45 sequences of 3D ultrasound volumes of one cardiac cycle from 45 patients to compare left ventricle segmentation methods for both End Diastolic and End Systolic phase instances.<br>
***Keyboard:***  Ultrasound imaging, Segmentation <br>
<a href="https://www.creatis.insa-lyon.fr/Challenge/CETUS/results.html"> ![Leaderboard](src/leaderboard.png)</a>

- <a href="https://vessel-wall-segmentation-2022.grand-challenge.org"> **COSMOS**</a> (CarOtid vessel wall SegMentation and atherosclerOsis diagnosiS) <br>
***Keyboard:***  3D-VISTA (volume isotropic turbo spin echo acquisition) images <br>
<a href="https://vessel-wall-segmentation-2022.grand-challenge.org/evaluation/validation/leaderboard"> ![Leaderboard](src/leaderboard.png)</a>

- <a href="https://echonet.github.io/dynamic/index.html"> **EchoNet-Dynamic**</a><br>
A Cardiac Motion Video Data Resource for Medical Machine Learning includes 10,030 labeled echocardiogram videos <br>
***Keyboard:*** Echocardiography, Labeled <br>
<a href="https://www.semanticscholar.org/paper/EchoNet-Dynamic%3A-a-Large-New-Cardiac-Motion-Video-Ouyang-He/44bfcf2409c0826584c7c409b6a2fcf8c9910c88"> ![paper](src/paper.png)</a>

- <a href="https://www.kaggle.com/datasets/xiaoweixumedicalai/imagealcapa"> **ImageALCAPA**</a> (Anomalous left coronary artery from pulmonary artery) <br>
30 3D CTA images. <br>
***Keyboard:*** CTA (Computed tomography angiography), Labeled, Segmentation  <br>
<a href="https://www.sciencedirect.com/science/article/abs/pii/S0895611123001052"> ![paper](src/paper.png)</a>

- <a href="https://www.kaggle.com/datasets/xiaoweixumedicalai/imagecas"> **ImageCAS**</a> (Coronary Artery Segmentation) <br>
A Dataset and for Coronary Artery Segmentation based on CT. <br>
***Keyboard:*** CTA (Computed tomography angiography), Segmentation  <br>
<a href="https://ieeexplore.ieee.org/document/9994951"> ![paper](src/paper.png)</a>

- <a href="https://www.kaggle.com/datasets/xiaoweixumedicalai/imagechd"> **ImageCHD**</a> (Congenital Heart Disease) <br>
A 3D CT Image Dataset for classification of Congenital Heart Disease. <br>
***Keyboard:*** CT scan, Labeled <br>
<a href="https://arxiv.org/abs/2101.10799"> ![paper](src/paper.png)</a> 

- <a href="https://www.kaggle.com/datasets/xiaoweixumedicalai/imagetbad"> **ImageTBAD**</a> <br>
A 3D CT Image Dataset for Automatic Segmentation of of Type-B Aortic Dissection. <br>
***Keyboard:*** CTA (Computed tomography angiography), Labeled, Aorta <br>
<a href="https://www.frontiersin.org/articles/10.3389/fphys.2021.732711/full"> ![paper](src/paper.png)</a> 

- <a href="https://zmiclab.github.io/zxh/0/mmwhs"> **MM-WHS**</a> (Multi-Modality Whole Heart Segmentation)<br>
It provides multi-modality cardiac images acquired in real clinical environment. <br>
***Keyboard:*** Anonymized clinical MRI and CT scan, Labeled <br>
<a href="https://ieeexplore.ieee.org/document/8458220"> ![paper](src/paper.png)</a> | <a href="https://ieeexplore.ieee.org/document/9921323"> ![paper](src/paper.png)</a>

- <a href="https://www.creatis.insa-lyon.fr/Challenge/myosaiq"> **MYOSAIQ**</a> (MYOcardial Segmentation with Automated Infarct Quantification)<br>
The full dataset is composed of 467 Late gadolinium enhanced magnetic resonance images from two different cohorts to quantify myocardial infarction (MI) lesions at different phases of the longitudinal evolution of the disease<br>
***Keyboard:*** MRI, Segmentation <br>

- <a href="https://www.ub.edu/mnms"> **M&Ms**</a> <br>
Multi-Centre, Multi-Vendor and Multi-Disease Cardiac Segmentation <br>
***Keyboard:***  Cardiac MRI (CMR)<br>
<a href="https://ieeexplore.ieee.org/document/9458279"> ![paper](src/paper.png)</a>

- <a href="https://www.ub.edu/mnms-2"> **M&Ms-2**</a> <br>
Multi-Disease, Multi-View & Multi-Center
Right Ventricular Segmentation in Cardiac MRI <br>
***Keyboard:***  Cardiac MRI (CMR)<br>
<a href="https://competitions.codalab.org/competitions/31559#results"> ![Leaderboard](src/leaderboard.png)</a> | <a href="https://ieeexplore.ieee.org/document/10103611"> ![paper](src/paper.png)</a>

- <a href="https://www.ocmr.info"> **OCMR**</a> <br>
Open-Access Multi-Coil k-Space Dataset for Cardiovascular Magnetic Resonance Imaging <br>
***Keyboard:*** MRI <br>
<a href="https://arxiv.org/abs/2008.03410"> ![paper](src/paper.png)</a>

- <a href="https://orcascore.grand-challenge.org"> **orCaScore**</a> <br>
Cardiac CT exams of 72 patients <br>
***Keyboard:*** CT scan <br>
<a href="https://orcascore.grand-challenge.org/evaluation/challenge/leaderboard"> ![Leaderboard](src/leaderboard.png)</a> | <a href="https://pubmed.ncbi.nlm.nih.gov/27147348"> ![paper](src/paper.png)</a>

- <a href="https://parse2022.grand-challenge.org"> **Parse2022**</a> (Pulmonary Artery Segmentation 2022) <br>
Our dataset contains 200 3D volumes with refined pulmonary artery label <br>
***Keyboard:*** CT Pulmonary Angiography (CTPA) <br>
<a href="https://parse2022.grand-challenge.org/evaluation/challenge/leaderboard"> ![Leaderboard](src/leaderboard.png)</a> | <a href="https://arxiv.org/abs/2304.03708"> ![paper](src/paper.png)</a>

- <a href="https://multicenteraorta.grand-challenge.org"> **SEG.A. 2023**</a> (Segmentation of the Aorta) <br>
***Keyboard:*** CTA (Computed tomography angiography), Labeled, Aorta <br>
<a href="https://multicenteraorta.grand-challenge.org/evaluation/preliminary-phase/leaderboard"> ![Leaderboard](src/leaderboard.png)</a> 



### Kidneys and Urinary Tract

- <a href="https://kipa22.grand-challenge.org"> **KiPA22**</a> (Kidney PArsing 2022) <br>
Multi-Structure Segmentation for Renal Cancer Treatment <br>
***Keyboard:*** Computed Tomography Angiography (CTA), Labeled <br>
<a href="https://kipa22.grand-challenge.org/evaluation/challenge/leaderboard"> ![Leaderboard](src/leaderboard.png)</a>

- <a href="https://kits19.grand-challenge.org/"> **KiTS19**</a> (Kidney Tumor Segmentation 2019) <br>
***Keyboard:*** CT scan, Cancer, Labeled <br>
<a href="https://kits19.grand-challenge.org/evaluation/challenge/leaderboard/"> ![Leaderboard](src/leaderboard.png)</a> | <a href="https://www.sciencedirect.com/science/article/abs/pii/S1361841520301857"> ![paper](src/paper.png)</a>

- <a href="https://kits-challenge.org/kits21"> **KiTS21**</a> (Kidney Tumor Segmentation 2021) <br>
***Keyboard:*** CT scan, Cancer, Labeled <br>
<a href="https://kits21.grand-challenge.org/evaluation/challenge/leaderboard/"> ![Leaderboard](src/leaderboard.png)</a> | <a href="https://arxiv.org/abs/2307.01984"> ![paper](src/paper.png)</a> | <a href="https://link.springer.com/chapter/10.1007/978-3-030-98385-7_13"> ![paper](src/paper.png)

- <a href="https://kits-challenge.org/kits23"> **KiTS23**</a> (Kidney Tumor Segmentation 2023) <br>
***Keyboard:*** CT scan, Cancer, Labeled <br>


### Liver

- <a href="https://www.ircad.fr/research/data-sets/liver-segmentation-3d-ircadb-01"> **3D-IRCADb-01**</a> (3D Image Reconstruction for Comparison of Algorithm Database) <br>
10 women and 10 men with hepatic tumours in 75% of cases. <br>
***Keyboard:*** 3D CT scan, Cancer, Labeled, Segmentation <br>

- <a href="https://atlas-challenge.u-bourgogne.fr"> **ATLAS**</a> (A Tumour and Liver Automatic Segmentation) <br>
60 Public images <br>
***Keyboard:*** MRI, Cancer, Labeled <br>
<a href="https://atlas-challenge.u-bourgogne.fr/leaderboard"> ![Leaderboard](src/leaderboard.png)</a> | <a href="https://www.mdpi.com/2306-5729/8/5/79"> ![paper](src/paper.png)</a> | <a href="https://www.nature.com/articles/s41598-024-53528-9"> ![paper](src/paper.png)</a>

- <a href="https://zenodo.org/records/7774566"> **Duke Liver DataSet**</a><br>
It provides over 2000 anonymized MRI image series acquired in routine liver MRI protocols across 105 subjects. <br>
***Keyboard:*** MRI, Cancer, Labeled <br>
<a href="https://ieeexplore.ieee.org/document/9242262"> ![paper](src/paper.png)</a>

- <a href="https://competitions.codalab.org/competitions/17094"> **LiTS**</a> (Liver Tumor Segmentation) <br>
***Keyboard:*** CT scan, Cancer, Labeled <br>
<a href="https://competitions.codalab.org/competitions/17094#results"> ![Leaderboard](src/leaderboard.png)</a> | <a href="https://arxiv.org/abs/1901.04056"> ![paper](src/paper.png)</a>

- <a href="https://p2ilf.grand-challenge.org"> **P2ILF**</a> (Preoperative to Intraoperative Laparoscopy Fusion) <br>
***Keyboard:*** Laparoscopic video images, Segmentation, Registration  <br>
<a href="https://p2ilf.grand-challenge.org/evaluation/challenge/leaderboard"> ![Leaderboard](src/leaderboard.png)</a>

- <a href="https://paip2019.grand-challenge.org"> **PAIP2019**</a> <br>
***Keyboard:*** Whole-slide images (WSIs), Cancer, Segmentation, Labeled, Hepatocellular Carcinoma (HCC) <br>
<a href="https://paip2019.grand-challenge.org/Leaderboard"> ![Leaderboard](src/leaderboard.png)</a>

- <a href="https://www.smir.ch/ShapeChallenge/Start2014"> **SHAPE 2014**</a><br>
The dataset is part of the training data from the "VISCERAL Organ Segmentation and Landmark Detection Challenge" <br>
***Keyboard:*** MRI, CT scan, Labeled, Segmentation <br>

- <a href="https://sliver07.grand-challenge.org"> **SLIVER07**</a> (Segmentation of the Liver Competition 2007) <br>
***Keyboard:*** 3D CT scan <br>
<a href="https://sliver07.grand-challenge.org/evaluation/challenge/leaderboard/"> ![Leaderboard](src/leaderboard.png)</a> | <a href="https://ieeexplore.ieee.org/document/4781564?isnumber=5175685&arnumber=4781564&count=18&index=11"> ![paper](src/paper.png)</a>

- <a href="https://wiki.cancerimagingarchive.net/pages/viewpage.action?pageId=6885436"> **TCGA-LIHC**</a> (The Cancer Genome Atlas Liver Hepatocellular Carcinoma) <br>
It has used in <a href='https://zenodo.org/records/8179129'> LiverHccSeg </a> <br>
***Keyboard:*** MRI, Cancer <br>



### Lungs

- <a href="https://wiki.cancerimagingarchive.net/pages/viewpage.action?pageId=21267414"> **4D Lung**</a> <br>
The images include four-dimensional (4D) fan beam (4D-FBCT) and 4D cone beam CT (4D-CBCT) <br>
***Keyboard:*** Cancer <br>
<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3647023"> ![paper](src/paper.png) The dataset is described</a> | <a href="https://pubmed.ncbi.nlm.nih.gov/22391105"> ![paper](src/paper.png)</a> 

- <a href="https://acdc-lunghp.grand-challenge.org/"> **ACDC-LungHP**</a> (Automatic Cancer Detection and Classification in Lung Histopathology) <br>
***Keyboard:*** Cancer, H&E staining, Pathology  <br>
<a href="https://acdc-lunghp.grand-challenge.org/evaluation/challenge/leaderboard/"> ![Leaderboard](src/leaderboard.png)</a> | <a href="https://ieeexplore.ieee.org/document/9265237"> ![paper](src/paper.png)</a> | <a href="http://arxiv.org/abs/1803.05471"> ![paper](src/paper.png)</a> 

- <a href="https://anode09.grand-challenge.org/"> **ANODE09**</a> (Automatic Nodule Detection 2009) <br>
Automatic detection of pulmonary nodules in chest <br>
***Keyboard:*** CT-scan <br>
<a href="https://anode09.grand-challenge.org/Results"> ![Leaderboard](src/leaderboard.png)</a> | <a href="https://www.sciencedirect.com/science/article/abs/pii/S1361841510000587"> ![paper](src/paper.png)</a> 

- <a href="https://atm22.grand-challenge.org"> **ATM22**</a> (Airway Tree Modeling) <br>
Dataset provides CT scans with detailed pulmonary airway annotation. <br>
***Keyboard:*** CT-scan, Labeled<br>
<a href="https://atm22.grand-challenge.org/evaluation/validation-phase-1-live-leaderboard/leaderboard"> ![Leaderboard](src/leaderboard.png)</a> | <a href="https://www.sciencedirect.com/science/article/abs/pii/S1361841523002177"> ![paper](src/paper.png)</a>

- <a href="https://brixia.github.io"> **BrixIA**</a><br>
COVID19 severity score assessment project and database. <br>
***Keyboard:*** Chest radiography (CXR), Labeled <br>
<a href="https://www.sciencedirect.com/science/article/pii/S136184152100092X"> ![paper](src/paper.png)</a>

- <a href="https://www.bsti.org.uk/training-and-education/covid-19-bsti-imaging-database"> **BSTI COVID19**</a> (British Society of Thoracic Imaging) <br>
***Keyboard:*** CT scan <br>

- <a href="https://www.kaggle.com/datasets/mohamedhanyyy/chest-ctscan-images"> **Chest CT-Scan images**</a><br>
CT-Scan images with different types of chest cancer <br>
***Keyboard:*** CT-scan, Labeled<br>

- <a href="https://cxr-covid19.grand-challenge.org"> **Chest XR COVID-19 detection**</a> <br>
The dataset contains 20,000+ images and 3 classes: COVID-19, Pneumonia and Normal (healthy). <br>
***Keyboard:*** X-ray, Labeled <br>

- <a href="https://www.nih.gov/news-events/news-releases/nih-clinical-center-provides-one-largest-publicly-available-chest-x-ray-datasets-scientific-community"> **ChestX-ray8**</a> (ChestXray-NIHCC) <br>
100,000 anonymized chest x-ray images <br>
***Keyboard:*** X-ray, Labeled <br>
<a href="https://arxiv.org/abs/1705.02315"> ![paper](src/paper.png)</a> 

- <a href="https://www.v7labs.com/open-datasets/chestx-ray14"> **ChestX-ray14**</a> (ChestXray-NIHCC) <br>
It is a dataset which comprises 112,120 frontal-view X-ray images of 30,805  unique patients with the text-mined fourteen common disease labels, mined from the text radiological reports via NLP techniques. It expands on ChestX-ray8 by adding six additional thorax diseases. <br>
***Keyboard:*** X-ray, Labeled <br>

- <a href="https://stanfordmlgroup.github.io/competitions/chexpert/"> **CheXpert**</a> <br>
A Large Chest X-Ray Dataset. <br>
***Keyboard:*** X-ray, Labeled <br>
<a href="https://arxiv.org/abs/1901.07031"> ![paper](src/paper.png)</a>

- <a href="https://covid-segmentation.grand-challenge.org"> **COVID-19-20**</a> <br>
COVID-19 Lung CT Lesion Segmentation <br>
***Keyboard:*** CT scan, Labeled <br>
<a href="https://covid-segmentation.grand-challenge.org/evaluation/challenge/leaderboard"> ![Leaderboard](src/leaderboard.png)</a> | <a href="https://www.sciencedirect.com/science/article/pii/S1361841522002353"> ![paper](src/paper.png)</a>

- <a href="https://www.cancerimagingarchive.net/collection/covid-19-ar"> **COVID-19-AR**</a> <br>
Chest Imaging with Clinical and Genomic Correlates Representing a Rural COVID-19 Positive Population <br>
<a href="https://www.nature.com/articles/s41597-020-00741-6"> ![paper](src/paper.png)</a>

- <a href="https://zenodo.org/records/3757476"> **COVID-19 CT Lung and Infection**</a> <br>
The dataset contains 20 labeled COVID-19 CT scans <br>
***Keyboard:*** Segmentation <br>

- <a href="https://www.kaggle.com/datasets/pranavraikokte/covid19-image-dataset"> **Covid-19 Image**</a> <br>
3 Way Classification - COVID-19, Viral Pneumonia, Normal <br>
***Keyboard:*** X ray, Labeled <br>

- <a href="https://data.uni-hannover.de/dataset/cov-19-img"> **COVID-19 Image Repository**</a> <br>
An anonymized data set of COVID-19 cases with a focus on radiological imaging <br>

- <a href="https://wiki.cancerimagingarchive.net/pages/viewpage.action?pageId=89096912"> **COVID-19-NY-SBU**</a> <br>
This collection of cases was acquired at Stony Brook University from patients who tested positive for COVID-19. <br>

- <a href="https://www.kaggle.com/datasets/tawsifurrahman/covid19-radiography-database"> **COVID-19 Radiography Database**</a> <br>
3616 COVID-19 Chest X-ray images and lung masks <br>
<a href="https://www.sciencedirect.com/science/article/pii/S001048252100113X"> ![paper](src/paper.png)</a> | <a href="https://ieeexplore.ieee.org/document/9144185"> ![paper](src/paper.png)</a>

- <a href="https://github.com/v7labs/covid-19-xray-dataset"> **COVID-19 xray**</a> <br>
This dataset contains 6500 images of AP/PA chest x-rays with pixel-level polygonal lung segmentations <br>

- <a href="https://github.com/ieee8023/covid-chestxray-dataset"> **COVID-ChestXRay**</a> <br>
An database of COVID-19 cases with chest X-ray or CT images <br>
***Keyboard:*** CT scan, X-ray <br>
<a href="https://arxiv.org/abs/2006.11988"> ![paper](src/paper.png)</a> | <a href="https://arxiv.org/abs/2004.05405"> ![paper](src/paper.png)</a>

- <a href="https://github.com/UCSD-AI4H/COVID-CT"> **COVID-CT**</a> <br>
It contains 349 COVID-19 CT images from 216 patients and 463 non-COVID-19 CTs<br>
***Keyboard:*** CT scan, Classification <br>
<a href="https://covid-ct.grand-challenge.org/Leaderboard"> ![Leaderboard](src/leaderboard.png)</a> | <a href="https://arxiv.org/abs/2003.13865"> ![paper](src/paper.png)</a> 

- <a href="https://github.com/ShahinSHH/COVID-CT-MD"> **COVID-CT-MD**</a><br>
The dataset contains volumetric chest CT scans of 169 patients positive for COVID-19 infection, 60 patients with Community Acquired Pneumonia, and 76 normal patients. <br>
***Keyboard:*** CT scan, Labeled <br>
<a href="https://www.nature.com/articles/s41597-021-00900-3"> ![paper](src/paper.png) Desription of the Dataset</a>

- <a href="https://github.com/mr7495/COVID-CTset"> **COVID-CTset**</a><br>
The dataset contains 63849 images from 377 patients <br>
***Keyboard:*** CT scan, Labeled <br>
<a href="https://www.sciencedirect.com/science/article/pii/S1746809421001853"> ![paper](src/paper.png) Desription of the Dataset</a>

- <a href="https://github.com/lindawangg/COVID-Net/blob/master/docs/COVIDx.md"> **COVIDx**</a> <br>
It is a collection of 8 datasets <br>
***Keyboard:*** CT scan, X-ray <br>
<a href="https://arxiv.org/abs/2003.09871"> ![paper](src/paper.png)</a>

- <a href="https://crass.grand-challenge.org"> **CRASS12**</a> (Chest Radiograph Anatomical Structure Segmentation) <br>
Automatic segmentation of anatomical structures in chest radiographs <br>
<a href="https://www.diagnijmegen.nl/publications/hoge12/?bibkey=Hoge12"> ![paper](src/paper.png)</a> 

- <a href="https://www.cancerimagingarchive.net/collection/ct-images-in-covid-19"> **CT Images in COVID-19**</a> <br>
A dataset from 632 patients with COVID-19 infections at initial point of care, and a dataset of 121 CTs from 29 patients with COVID-19 infections with serial / sequential CTs. <br>
<a href="https://www.nature.com/articles/s41467-020-17971-2"> ![paper](src/paper.png) A classification model derived</a> 

- <a href="https://veet.via.cornell.edu/lungdb.html"> **ELCAP**</a> (Early Lung Cancer Action Program) <br>
The database currently consists of an image set of 50 low-dose documented whole-lung CT scans for detection. <br>
***Keyboard:*** CT scan, Nodules, Labeled <br>

- <a href="https://empire10.grand-challenge.org"> **EMPIRE10**</a> (Evaluation of Methods for Pulmonary Image Registration 2010) <br>
***Keyboard:*** CT, Registration of thoracic <br>
<a href="https://pubmed.ncbi.nlm.nih.gov/21632295"> ![paper](src/paper.png)</a> 

- <a href="https://www.kaggle.com/datasets/hamdallak/the-iqothnccd-lung-cancer-dataset"> **IQ-OTH/NCCD**</a> (Iraq-Oncology Teaching Hospital/National Center for Cancer Diseases) <br>
The dataset contains a total of 1190 images representing CT scan slices of 110 cases. <br>
***Keyboard:*** CT scan, Cancer, Labeled <br>
<a href="https://www.kaggle.com/c/rsna-str-pulmonary-embolism-detection/leaderboard"> ![Leaderboard](src/leaderboard.png)</a> | <a href="https://pubmed.ncbi.nlm.nih.gov/33937862"> ![paper](src/paper.png)</a>

- <a href="http://db.jsrt.or.jp/eng.php"> **JSRT**</a> (Japanese Society of Radiological Technology) <br>
The database includes 154 conventional chest radiographs with a lung nodule and 93 radiographs without a nodule <br>
***Keyboard:*** X-ray <br>
<a href="https://ietresearch.onlinelibrary.wiley.com/doi/full/10.1049/iet-ipr.2019.0423"> ![paper](src/paper.png) Cited DB </a>  | <a href="https://arxiv.org/abs/1907.09375"> ![paper](src/paper.png) Cited DB</a>

- <a href="https://wiki.cancerimagingarchive.net/pages/viewpage.action?pageId=1966254"> **LIDC-IDRI**</a> (Lung Image Database Consortium (LIDC) and Image Database Resource Initiative (IDRI)) <br>
***Keyboard:*** CT scan, Cancer, Labeled <br>
<a href="https://aapm.onlinelibrary.wiley.com/doi/10.1118/1.3528204"> ![paper](src/paper.png)</a> 

- <a href="https://lndb.grand-challenge.org"> **LNDb**</a> (Lung Nodule Database) <br>
Lung nodule detection, segmentation and characterization as well as prediction of patient follow-up <br>
***Keyboard:*** Cancer, CT-scan <br>
<a href="https://lndb.grand-challenge.org/evaluation/challenge/leaderboard"> ![Leaderboard](src/leaderboard.png)</a> | <a href="https://pubmed.ncbi.nlm.nih.gov/33740739"> ![paper](src/paper.png) </a> 

- <a href="https://lola11.grand-challenge.org/"> **LOLA11**</a> (LObe and Lung Analysis 2011) <br>
Compare methods for (semi-)automatic segmentation of the lungs and lobes from chest <br>
***Keyboard:*** segmentation, CT-scan <br>
<a href="https://lola11.grand-challenge.org/evaluation/challenge/leaderboard/"> ![Leaderboard](src/leaderboard.png)</a>

- <a href="https://lumic.grand-challenge.org"> **LUMIC**</a> <br>
***Keyboard:*** CT-scan, registration, Labeled<br>
<a href="https://pubmed.ncbi.nlm.nih.gov/30888690"> ![paper](src/paper.png)</a> 

- <a href="https://luna16.grand-challenge.org"> **LUNA16**</a> (LUng Nodule Analysis 2016) <br>
Nodule location detection <br>
***Keyboard:*** Cancer, CT-scan <br>
<a href="https://luna16.grand-challenge.org/Results"> ![Leaderboard](src/leaderboard.png)</a> | <a href="https://www.sciencedirect.com/science/article/abs/pii/S1361841517301020"> ![paper](src/paper.png) Overview paper</a> 

- <a href="https://wiki.cancerimagingarchive.net/pages/viewpage.action?pageId=70224216"> **Lung-PET-CT-Dx**</a> <br>
A Large-Scale CT and PET/CT Dataset for Lung Cancer Diagnosis <br>
***Keyboard:*** Cancer, Labeled <br>

- <a href="https://mela.grand-challenge.org"> **MELA**</a> (Mediastinal Lesion Analysis) <br>
Detectition mediastinal lesions from 1100 CT scans, consisting of 770 CTs for training, 110 CTs for validation, and 220 CTs for testing. <br>
***Keyboard:*** CT Scan <br>
<a href="https://mela.grand-challenge.org/evaluation/challenge/leaderboard"> ![Leaderboard](src/leaderboard.png)</a>

- <a href="https://wiki.cancerimagingarchive.net/pages/viewpage.action?pageId=80969742"> **MIDRC-RICORD-1A**</a> (Medical Imaging Data Resource Center - RSNA International COVID-19 Open Radiology Database Release 1a)<br>
120 Chest CT Covid+ <br>
***Keyboard:*** CT Scan, Labeled <br>
<a href="https://pubs.rsna.org/doi/10.1148/radiol.2021203957"> ![paper](src/paper.png)</a>

- <a href="https://wiki.cancerimagingarchive.net/pages/viewpage.action?pageId=80969771"> **MIDRC-RICORD-1B**</a> (Medical Imaging Data Resource Center - RSNA International COVID-19 Open Radiology Database Release 1b)<br>
120 Chest CT Covid+ <br>
***Keyboard:*** CT Scan, Labeled <br>
<a href="https://pubs.rsna.org/doi/10.1148/radiol.2021203957"> ![paper](src/paper.png)</a>

- <a href="https://wiki.cancerimagingarchive.net/pages/viewpage.action?pageId=70230281"> **MIDRC-RICORD-1C**</a> (Medical Imaging Data Resource Center - RSNA International COVID-19 Open Radiology Database Release 1c)<br>
998 Chest X-rays Covid+ <br>
***Keyboard:*** X-rays, Labeled <br>
<a href="https://pubs.rsna.org/doi/10.1148/radiol.2021203957"> ![paper](src/paper.png)</a>

- <a href="https://physionet.org/content/mimic-cxr"> **MIMIC-CXR**</a> <br>
The dataset contains 377,110 images corresponding to 227,835 radiographic. <br>
***Keyboard:*** X-ray <br>
<a href="https://www.nature.com/articles/s41597-019-0322-0"> ![paper](src/paper.png)</a> | <a href="https://arxiv.org/abs/1901.07042"> ![paper](src/paper.png)</a>

- <a href="https://wiki.cancerimagingarchive.net/pages/viewpage.action?pageId=5800702"> **NLST**</a> (National Lung Screening Trial)<br>
26,254 low-dose CT scans <br>
***Keyboard:*** CT Scan, Labeled <br>
<a href="https://www.nejm.org/doi/10.1056/NEJMoa1102873"> ![paper](src/paper.png)</a>

- <a href="https://node21.grand-challenge.org"> **NODE21**</a> <br>
Detection and generation of lung nodules. <br>
***Keyboard:*** X-ray <br>
<a href="https://node21.grand-challenge.org/evaluation/challenge/leaderboard"> ![Leaderboard](src/leaderboard.png)</a> | <a href="https://arxiv.org/abs/2401.02192"> ![paper](src/paper.png)</a>

- <a href="https://mela.grand-challenge.org"> **NSCLC-Radiomics**</a> (Non-Small Cell Lung Cancer) <br>
This collection contains images from 422 patients.  <br>
***Keyboard:*** CT Scan, Labeled <br>

- <a href="https://bimcv.cipf.es/bimcv-projects/padchest"> **PadChest**</a> <br>
This dataset includes more than 160,000 images of 67,000 patients. <br>
***Keyboard:*** X-ray, Labeled <br>
<a href="https://www.sciencedirect.com/science/article/abs/pii/S1361841520301614"> ![paper](src/paper.png)</a>

- <a href="https://www.cancerimagingarchive.net/analysis-result/qin-lungct-seg"> **QIN Lung CT**</a> <br>
***Keyboard:*** Nodule, CT Scan, Segmentation <br>

- <a href="https://www.rsna.org/rsnai/ai-image-challenge/RSNA-Pneumonia-Detection-Challenge-2018"> **RSNA Pneumonia Detection**</a> (Radiological Society of North America 2018) <br>
30,000 frontal view chest radiographs <br>
***Keyboard:*** X-ray, Labeled <br>

- <a href="https://www.rsna.org/rsnai/ai-image-challenge/rsna-pe-detection-challenge-2020"> **RSNA Pulmonary Embolism**</a> (Radiological Society of North America 2020) <br>
Detect and characterize instances of pulmonary embolism (PE) on chest CT studies <br>
***Keyboard:*** CT scan, Labeled <br>
<a href="https://www.kaggle.com/c/rsna-str-pulmonary-embolism-detection/leaderboard"> ![Leaderboard](src/leaderboard.png)</a> | <a href="https://pubmed.ncbi.nlm.nih.gov/33937862"> ![paper](src/paper.png)</a>

- <a href="http://www.via.cornell.edu/databases/simbadb.html"> **SIMBA**</a> <br>
Chest Health Analysis System Public Lung Image Database.<br>
***Keyboard:*** CT scan, Labeled <br>

- <a href="https://stoic2021.grand-challenge.org"> **STOIC2021**</a> <br>
Study of Thoracic CT in COVID-19 <br>
***Keyboard:*** CT scan <br>
<a href="https://stoic2021.grand-challenge.org/evaluation/challenge/leaderboard"> ![Leaderboard](src/leaderboard.png)</a> | <a href="https://pubs.rsna.org/doi/10.1148/radiol.2021210384"> ![paper](src/paper.png)</a>

- <a href="https://wiki.cancerimagingarchive.net/pages/viewpage.action?pageId=6881474"> **TCGA-LUAD**</a> (The Cancer Genome Atlas Lung Adenocarcinoma) <br>
Data from 69 Participants <br>
***Keyboard:*** Multi-modality <br>

- <a href="https://vessel12.grand-challenge.org/"> **VESSEL12**</a> (VESsel SEgmentation in the Lung 2012) <br>
Automatic (and semi-automatic) segmentation of blood vessels in the lungs from CT images <br>
***Keyboard:*** CT-scan <br>
<a href="https://vessel12.grand-challenge.org/Results"> ![Leaderboard](src/leaderboard.png)</a> | <a href="https://www.sciencedirect.com/science/article/abs/pii/S136184151400111X"> ![paper](src/paper.png) Overview paper</a> 

- <a href="http://www.via.cornell.edu/databases/crpf.html"> **VIA/I-ELCAP**</a> <br>
The database contains a number of annotated CT image scans that highlight many of the key issues in measuring large lesions in the lung. <br>
***Keyboard:*** CT-scan <br>
<a href="https://pubmed.ncbi.nlm.nih.gov/19965010"> ![paper](src/paper.png) The dataset is described </a>

- <a href="https://wsss4luad.grand-challenge.org"> **WSSS4LUAD**</a> (Weakly-supervised Tissue Semantic Segmentation for Lung Adenocarcinoma) <br>
Segment tumor epithelial, tumor-associated stroma and normal tissue with only patch-level labels. <br>
***Keyboard:*** H&E stained Whole Slide Image (WSI), Cancer <br>
<a href="https://wsss4luad.grand-challenge.org/evaluation/challenge/leaderboard"> ![Leaderboard](src/leaderboard.png)</a> | <a href="https://arxiv.org/abs/2204.06455"> ![paper](src/paper.png)</a>



______

## Musculoskeletal System

### Bones

- <a href="https://ivdm3seg.weebly.com"> **IVDM3Seg**</a> <br>
Intervertebral Disc Localization and Segmentation from 3D Multi-modality MR (M3) Images <br>
***Keyboard:*** MRI <br>
<a href="https://ivdm3seg.weebly.com/results.html"> ![Leaderboard](src/leaderboard.png)</a>

- <a href="https://github.com/kc-santosh/medical-imaging-datasets"> **Fractured Limbs**</a><br>
5684 CT images (upper limbs: 2057 and lower limbs: 3627) to understand bone injurie. <br>
***Keyboard:*** CT scan, Labeled <br>
<a href="https://link.springer.com/article/10.1007/s10916-021-01724-9"> ![paper](src/paper.png)</a>

- <a href="https://stanfordmlgroup.github.io/competitions/mura"> **MURA**</a> (MUsculoskeletal RAdiographs) <br>
Large Dataset for Abnormality Detection in Musculoskeletal Radiographs <br>
***Keyboard:*** X-ray, Labeled<br>
<a href="https://arxiv.org/abs/1712.06957"> ![paper](src/paper.png)</a> 

- <a href="https://ribfrac.grand-challenge.org"> **RibFrac**</a> <br> 
A dataset for detect and classify around 5,000 rib fractures from 660 computed tomography (CT) scans <br>
***Keyboard:*** CT scan, Labeled <br>
<a href="https://ribfrac.grand-challenge.org/evaluation/challenge/leaderboard"> ![Leaderboard](src/leaderboard.png)</a>

- <a href="https://www.rsna.org/rsnai/ai-image-challenge/cervical-spine-fractures-ai-detection-challenge-2022"> **RSNA Cervical Spine Fracture**</a> (Radiological Society of North America 2022) <br>
Including approximately 3,000 CT <br>
***Keyboard:*** CT scan, Labeled<br>
<a href="https://www.kaggle.com/competitions/rsna-2022-cervical-spine-fracture-detection/leaderboard"> ![Leaderboard](src/leaderboard.png)</a>

- <a href="https://www.kaggle.com/datasets/kmader/rsna-bone-age"> **RSNA Bone Age**</a> (Radiological Society of North America 2017) <br>
Identify the age of a child from an X-ray of their hand <br>
***Keyboard:*** X-ray, Labeled<br>
<a href="https://pubmed.ncbi.nlm.nih.gov/30480490"> ![paper](src/paper.png)</a> | <a href="https://pubmed.ncbi.nlm.nih.gov/30615556"> ![paper](src/paper.png)</a> | <a href="https://pubmed.ncbi.nlm.nih.gov/29095675"> ![paper](src/paper.png)</a>

- <a href="https://spider.grand-challenge.org"> **SPIDER**</a> (SPIne Segmentation: Discs, vERtebrae, and spinal canal)<br>
A lumbar spine MR dataset with reference segmentations of vertebrae, intervertebral discs (IVDs), and spinal canal <br>
***Keyboard:*** MRI <br>
<a href="https://spider.grand-challenge.org/evaluation/challenge/leaderboard"> ![Leaderboard](src/leaderboard.png)</a> | <a href="https://arxiv.org/abs/2306.12217"> ![paper](src/paper.png)</a>

- <a href="http://spineweb.digitalimaginggroup.ca"> **SpineWeb**</a> <br>
16 spinal imaging datasets

- <a href="https://github.com/anjany/verse"> **VerSe**</a> <br> Large Scale Vertebrae Segmentation <br>
***Keyboard:*** CT scan, Segmentation <br>
<a href="https://verse2019.grand-challenge.org/evaluation/challenge/leaderboard"> ![Leaderboard](src/leaderboard.png)</a> | <a href="https://www.sciencedirect.com/science/article/abs/pii/S1361841521002127"> ![paper](src/paper.png)</a> | <a href="https://pubs.rsna.org/doi/10.1148/ryai.2020190138"> ![paper](src/paper.png)</a>


### Joints

- <a href="https://k2s.grand-challenge.org"> **K2S**</a> <br>
A dataset of high-resolution 3D knee MRI including raw k-space data and post-processing annotations with masks for tissue segmentation. <br>
***Keyboard:*** MRI, Labeled<br>

- <a href="https://www.kaggle.com/datasets/shashwatwork/knee-osteoarthritis-dataset-with-severity"> **Knee Osteoarthritis Dataset with Severity Grading**</a> <br>
***Keyboard:*** X-ray, Labeled<br>

- <a href="www.riteh.uniri.hr/~istajduh/projects/kneeMRI"> **kneeMRI**</a> <br>
The dataset consists of 917 12-bit grayscale volumes of either left or right knees. <br>
***Keyboard:*** MRI scans, Labeled<br>
<a href="https://pubmed.ncbi.nlm.nih.gov/28254071"> ![paper](src/paper.png)</a> 

- <a href="https://knoap2020.grand-challenge.org"> **KNOAP2020**</a> (KNee OsteoArthritis Prediction) <br>
***Keyboard:*** MRI scans, X-ray, Labeled<br>
<a href="https://www.oarsijournal.com/article/S1063-4584(22)00864-0/fulltext"> ![paper](src/paper.png)</a> 

- <a href="https://stanfordmlgroup.github.io/competitions/mrnet"> **MRNet**</a> <br>
Diagnosis of abnormalities from Knee MRs <br>
***Keyboard:*** MRI, Labeled<br>
<a href="https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.1002699"> ![paper](src/paper.png)</a> 

<!---
### Muscles
-->

_______

## Pelvis and Reproductive Organs

### Female Reproductive Organs

- <a href="https://github.com/cwwang1979/MICCAI_ATEC23challenge"> **ATEC23**</a> <br>
Automated prediction of treatment effectiveness in ovarian cancer using histopathological images <br>
***Keyboard:*** Whole Slide Images (WSIs), Cancer <br>
<a href="https://arxiv.org/abs/2310.12866"> ![paper](src/paper.png)</a>

- <a href="https://a-afma.grand-challenge.org"> **A-AFMA**</a> (Automatic amniotic fluid measurement and analysis) <br>
The goal is measurement of the maximum vertical pocket (MVP) <br>
***Keyboard:*** Ultrasound Video Clip <br>

- <a href="https://github.com/parham-ap/cytology_dataset"> **Cervix93**</a> <br>
A Cervical Cytology Dataset for Nucleus Detection and Image Classification and Methods for Cervical Nucleus Detection <br>
***Keyboard:*** Pap smear, Cancer, Labeled <br>
<a href="https://arxiv.org/abs/1811.09651"> ![paper](src/paper.png)</a>

- <a href="https://mde-lab.aegean.gr/index.php/downloads"> **DTU/HERLEV (PAP-SMEAR)**</a> <br>
***Keyboard:*** Pap smear, Labeled <br>
<a href="https://www.researchgate.net/publication/265873515_Pap-smear_Benchmark_Data_For_Pattern_Classification"> ![paper](src/paper.png) Benchmark</a>

- <a href="https://zenodo.org/records/7372187"> **ENDO-AID**</a> <br>
The dataset consists of 91 digital pathology whole-slide images (WSI) of endometrium carcinoma Pipelle biopsies, stained with hematoxylin and eosin (H&E). <br>
***Keyboard:*** Whole-slide images (WSI), Cancer <br>

- <a href="https://hc18.grand-challenge.org"> **HC18**</a> <br>
Measurement of fetal head circumference (HC)<br>
***Keyboard:*** Ultrasound imaging, Labeled <br>
<a href="https://hc18.grand-challenge.org/evaluation/challenge/leaderboard/"> ![Leaderboard](src/leaderboard.png)</a>

- <a href="https://www.kaggle.com/c/intel-mobileodt-cervical-cancer-screening/overview"> **Intel & MobileODT Cervical Cancer Screening**</a><br>
***Keyboard:*** Colposcopy, Classification, Cancer <br>

- <a href="https://figshare.com/articles/dataset/JNU-IFM/14371652"> **JNU-IFM**</a> <br>
An intrapartum transperineal ultrasound dataset of the Intelligent Fetal Monitoring <br>
***Keyboard:*** Ultrasound videos, Labeled <br>
<a href="https://www.sciencedirect.com/science/article/pii/S2352340922001160"> ![paper](src/paper.png)</a>

- <a href="https://data.mendeley.com/datasets/zddtpgzv63/4"> **Liquid based-cytology Pap smear**</a> <br>
The repository consists of a total of 963 LBC images <br>
***Keyboard:*** Pap Smear, Labeled <br>
<a href="https://www.sciencedirect.com/science/article/pii/S2352340920304832"> ![paper](src/paper.png)</a>

- <a href="https://ps-fh-aop-2023.grand-challenge.org"> **Ps-Fh-Aop-2023**</a> (Pubic Symphysis-Fetal Head Segmentation and Angle of Progression) <br>
***Keyboard:*** Ultrasound imaging, Labeled <br>
<a href="https://ps-fh-aop-2023.grand-challenge.org/evaluation/phase-two/leaderboard"> ![Leaderboard](src/leaderboard.png)</a>

- <a href="https://www.cs.uoi.gr/~marina/sipakmed.html"> **SIPaKMeD**</a> <br>
The database consists of 4049 images of isolated cells that have been manually cropped from 966 cluster cell images of Pap smear slides. <br>
***Keyboard:*** Pap smear, Labeled <br>
<a href="https://ieeexplore.ieee.org/abstract/document/8451588"> ![paper](src/paper.png)</a>

### Male Reproductive Organs

- <a href="https://aggc22.grand-challenge.org">**AGGC22**</a> (Automated Gleason Grading Challenge 2022) <br>
Dataset of prostatectomy and biopsy specimens with annotations  <br>
***Keyboard:*** H&E-stained whole slide image <br>
<a href="https://aggc22.grand-challenge.org/evaluation/challenge/leaderboard"> ![Leaderboard](src/leaderboard.png)</a> | <a href="https://www.researchgate.net/publication/363780482_Comprehensive_AI_Model_Development_for_Gleason_Grading_From_Scanning_Cloud-based_Annotation_to_Pathologist-AI_Interaction"> ![paper](src/paper.png)</a>

- <a href="https://auto-rtp.grand-challenge.org">**AUTO-RTP**</a> (Fully Automated Radiotherapy Treatment Planning) <br>
***Keyboard:*** Cancer<br>
<a href="https://auto-rtp.grand-challenge.org/evaluation/data-format-confirmation/leaderboard"> ![Leaderboard](src/leaderboard.png)</a>

- <a href="https://gleason2019.grand-challenge.org"> **Gleason 2019**</a> <br>
Gleason grading of prostate cancer in digital histopathology images <br>
***Keyboard:*** H&E-stained histopathology image, Cancer, Labeled <br>
<a href="https://gleason2019.grand-challenge.org/Results"> ![Leaderboard](src/leaderboard.png)</a>

- <a href="https://www.kaggle.com/c/prostate-cancer-grade-assessment"> **PANDA**</a> (Prostate cANcer graDe Assessment) <br>
Classifying the severity of prostate cancer from microscopy scans of prostate biopsy samples <br>
***Keyboard:*** whole-slide images (WSI), Cancer <br>
<a href="https://www.nature.com/articles/s41591-021-01620-2"> ![paper](src/paper.png)</a>

- <a href="https://pi-cai.grand-challenge.org/"> **PI-CAI**</a> (Prostate Imaging: Cancer AI) <br>
***Keyboard:*** Prostate, MRI, Cancer, Labeled <br>
<a href="https://pi-cai.grand-challenge.org/evaluation/open-development-phase/leaderboard/"> ![Leaderboard](src/leaderboard.png)</a>

- <a href="https://promise12.grand-challenge.org"> **PROMISE12**</a> (Prostate MR Image Segmentation 2012) <br>
Compare interactive and (semi)-automatic segmentation algorithms for MRI of the prostate <br>
***Keyboard:*** T2-weighted MRI, Labeled <br>
<a href="https://promise12.grand-challenge.org/evaluation/challenge/leaderboard"> ![Leaderboard](src/leaderboard.png)</a> | <a href="https://www.sciencedirect.com/science/article/abs/pii/S1361841513001734"> ![paper](src/paper.png) Overview paper</a>

- <a href="https://wiki.cancerimagingarchive.net/display/Public/QIN-PROSTATE-Repeatability"> **QIN-PROSTATE-Repeatability**</a> <br>
This is a dataset with multiparametric prostate MRI applied in a test-retest setting, allowing to evaluate repeatability of the MRI-based measurements in the prostate. <br>
***Keyboard:*** MRI, Labeled <br>
<a href="https://www.nature.com/articles/sdata2018281"> ![paper](src/paper.png)</a>


______
## Other Organs and Systems

### Lymph Nodes

- <a href="https://camelyon16.grand-challenge.org"> **CAMELYON16**</a> <br>
Detection of metastases in hematoxylin and eosin (H&E) stained whole-slide images of lymph node sections <br>
***Keyboard:*** Cancer, Digital pathology, Lymph node detection <br>
<a href="https://camelyon16.grand-challenge.org/Results"> ![Leaderboard](src/leaderboard.png)</a> | <a href="https://jamanetwork.com/journals/jama/article-abstract/2665774"> ![paper](src/paper.png)</a> | <a href="https://academic.oup.com/gigascience/article/7/6/giy065/5026175"> ![paper](src/paper.png)</a>

- <a href="https://camelyon17.grand-challenge.org"> **CAMELYON17**</a> <br>
Evaluate new and existing algorithms for automated detection and classification of breast cancer metastases in whole-slide images of histological lymph node sections <br>
***Keyboard:*** Cancer, Digital pathology, Lymph node detection <br>
<a href="https://camelyon17.grand-challenge.org/evaluation/challenge/leaderboard"> ![Leaderboard](src/leaderboard.png)</a> | <a href="https://ieeexplore.ieee.org/document/8447230"> ![paper](src/paper.png)</a> | <a href="https://academic.oup.com/gigascience/article/7/6/giy065/5026175"> ![paper](src/paper.png)</a>

- <a href="https://wiki.cancerimagingarchive.net/pages/viewpage.action?pageId=19726546"> **CT Lymph nodes**</a> <br>
90 CTs dataset of lymph nodes <br>
***Keyboard:*** CT scan, Lymph node detection

- <a href="https://lnq2023.grand-challenge.org"> **LNQ2023**</a> (Mediastinal Lymph Node Quantification) <br>
Segmentation of Heterogeneous CT Data <br>
***Keyboard:*** CT scan, Cancer  <br>
<a href="https://lnq2023.grand-challenge.org/evaluation/validation/leaderboard/"> ![Leaderboard](src/leaderboard.png)</a>

- <a href="https://huggingface.co/datasets/andreped/LyNoS"> **LyNoS**</a>  <br>
15 CTs with corresponding lymph nodes, azygos, esophagus, and subclavian carotid arteries  <br>
***Keyboard:*** CT scan, Segmentation <br>
<a href="https://www.tandfonline.com/doi/full/10.1080/21681163.2022.2043778"> ![paper](src/paper.png)</a>

- <a href="https://github.com/basveeling/pcam"> **PatchCamelyon**</a> <br>
Image classification dataset consists of 327.680 color images extracted from histopathologic scans of lymph node sections. <br>
***Keyboard:*** Labeled <br>
<a href="https://patchcamelyon.grand-challenge.org/evaluation/challenge/leaderboard"> ![Leaderboard](src/leaderboard.png)</a> | <a href="https://arxiv.org/abs/1806.03962"> ![paper](src/paper.png)</a>




### Skin

- <a href="https://licensing.edinburgh-innovations.ed.ac.uk/product/dermofit-image-library"> **Dermofit Image Library**</a><br>
1300 High quality skin lesion images. <br>
***Keyboard:*** Segmentation, Labeled<br>

- <a href="https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/DBW86T"> **HAM10000**</a> <br>
A collection of multi-source dermatoscopic images of common pigmented skin lesions <br>
***Keyboard:*** Dermatoscopic images <br>

- <a href="https://challenge.isic-archive.com/data"> **ISIC**</a> (International Skin Imaging Collaboration) <br>
It has multi versions. <br>
***Keyboard:*** Dermoscopic images <br>
<a href="https://arxiv.org/abs/1605.01397"> ![paper](src/paper.png)</a> | 
<a href="https://ieeexplore.ieee.org/document/8363547"> ![paper](src/paper.png)</a> | <a href="https://arxiv.org/abs/1902.03368"> ![paper](src/paper.png)</a>

- <a href="https://www.uco.es/grupos/ayrna/ieeetmi2015"> **Melanoma Dataset**</a> <br>
***Keyboard:*** Classification, Dermatoscopic images <br>
<a href="https://ieeexplore.ieee.org/document/7348708"> ![paper](src/paper.png)</a>

- <a href="https://www.fc.up.pt/addi/ph2%20database.html"> **PH<sup>2</sup>**</a> <br>
The database contains a total of 200 dermoscopic images of melanocytic lesions <br>
***Keyboard:*** Classification, Segmentation, Dermoscopic images, Labeled <br>
<a href="https://pubmed.ncbi.nlm.nih.gov/24110966"> ![paper](src/paper.png)</a>

- <a href="https://uwaterloo.ca/vision-image-processing-lab/research-demos/skin-cancer-detection"> **Skin Cancer Detection**</a><br>
This includes images extracted from the public databases DermIS and DermQuest, along with manual segmentations of the lesions. <br>
***Keyboard:*** Segmentation, Cancer<br>



______
## Multi Organs Datasets


- <a href="https://abdomenct-1k-fully-supervised-learning.grand-challenge.org"> **AbdomenCT-1K**</a> <br>
The dataset with more than 1000 (1K) abdominal organ scans. <br>
***Keyboard:*** *liver, kidney, spleen, and pancreas*, CT Scan, Segmentation, Labeled <br>
<a href="https://arxiv.org/abs/2010.14808"> ![paper](src/paper.png)</a>

- <a href="https://zenodo.org/records/7155725#.Y0OOCOxBztM"> **AMOS**</a> <br>
A large-scale abdominal multi-organ benchmark for versatile medical image segmentation <br>
***Keyboard:***  Multi-tissue (15 abdominal organs), MRI, CT scan<br>
<a href="https://amos22.grand-challenge.org/evaluation/amos-ct-regular-evaluation/leaderboard"> ![Leaderboard](src/leaderboard.png)</a>

- <a href="https://www.cancerimagingarchive.net/collection/fdg-pet-ct-lesions"> **AutoPET**</a><br>
A whole-body FDG-PET/CT dataset with manually annotated tumor lesions (FDG-PET-CT-Lesions) <br>
***Keyboard:*** PET - CT scan, Labeled <br>

- <a href="https://chaos.grand-challenge.org"> **CHAOS**</a> (Combined (CT-MR) Healthy Abdominal Organ Segmentation) <br>
There are 20 training and 20 testing cases in the CT dataset. MRI dataset contains 20 training and 20 testing cases with T1-Dual and T2 SPIR sequences. <br>
***Keyboard:*** *Liver, Kidneys, Spleen*, CT Scan, MRI, Labeled <br>
<a href="https://chaos.grand-challenge.org/evaluation/challenge/leaderboard"> ![Leaderboard](src/leaderboard.png)</a> | <a href="https://www.sciencedirect.com/science/article/abs/pii/S1361841520303145"> ![paper](src/paper.png)</a>

- <a href="https://ead2019.grand-challenge.org/"> **EAD 2019**</a> (Endoscopy artifact detection) <br>
Facilitating diagnosis and treatment of diseases in hollow organs. <br>
***Keyboard:***  Multi-tissue, Multi-modality, Video Endoscopy, Labeled <br>
<a href="https://ead2019.grand-challenge.org/evaluation/challenge/leaderboard"> ![Leaderboard](src/leaderboard.png)</a> | <a href="https://arxiv.org/abs/1905.03209"> ![paper](src/paper.png)</a>

- <a href="https://fastmri.med.nyu.edu"> **fastMRI**</a><br>
***Keyboard:*** *Knee, Brain, and Prostate*, MRI<br>
<a href="https://arxiv.org/abs/1811.08839"> ![paper](src/paper.png)</a> | <a href="https://pubs.rsna.org/doi/10.1148/ryai.2020190007"> ![paper](src/paper.png)</a> | <a href="https://arxiv.org/abs/2304.09254"> ![paper](src/paper.png)</a>

- <a href="https://fastpet-ld.grand-challenge.org"> **fastPET-LD**</a> (Fast PET-CT lesion detection) <br>
***Keyboard:*** Hot spots, PET - CT scan, Labeled, Detection <br>
<a href="https://fastpet-ld.grand-challenge.org/evaluation/challenge/leaderboard"> ![Leaderboard](src/leaderboard.png)</a>

- <a href="https://flare22.grand-challenge.org"> **FLARE 2022**</a> (Fast and Low-resource semi-supervised Abdominal oRgan sEgmentation) <br>
A small number of labeled cases (50) and a large number of unlabeled cases (2000) in the training set. <br>
***Keyboard:***  Multi-tissue (13 organs), CT scan, Labeled <br>
<a href="https://flare22.grand-challenge.org/evaluation/testing-dsc/leaderboard"> ![Leaderboard](src/leaderboard.png)</a> | <a href="https://arxiv.org/abs/2308.05862"> ![paper](src/paper.png)</a>

- <a href="https://flare.grand-challenge.org"> **FLARE21**</a> (Fast and Low GPU memory Abdominal oRgan sEgmentation) <br>
A abdominal CT organ dataset with 500 CT scans from 11 countries, including multi-center, multi-phase, multi-vendor, and multi-disease cases. <br>
***Keyboard:*** *Liver, Kidney, Spleen, and Pancreas*, CT scan, Cancer, Segmentation<br>
<a href="https://flare.grand-challenge.org/evaluation/challenge/leaderboard"> ![Leaderboard](src/leaderboard.png)</a> | <a href="https://www.sciencedirect.com/science/article/abs/pii/S1361841522002444"> ![paper](src/paper.png) Summary Paper</a>

- <a href="https://han-seg2023.grand-challenge.org"> **HaN-Seg**</a> (Head and Neck Segmentation) <br>
Images of 60 patients aged 34–79 years that were appointed for image-guided Radiotherapy in the HaN region <br>
***Keyboard:*** *30 organs-at-risk*, CT Scan, MRI, Labeled <br>
<a href="https://han-seg2023.grand-challenge.org/evaluation/challenge/leaderboard"> ![Leaderboard](src/leaderboard.png)</a> | <a href="https://aapm.onlinelibrary.wiley.com/doi/full/10.1002/mp.16197"> ![paper](src/paper.png)</a>

- <a href="https://hecktor.grand-challenge.org"> **HECKTOR**</a> (HEad and neCK TumOR segmentation and outcome prediction) <br>
The data were collected for a total of 883 cases consisting of FDG-PET/CT images and clinical information. <br>
***Keyboard:*** *Head, Neck, Lymph nodes*, FDG-PET/CT images, Cancer, Labeled <br>
<a href="https://hecktor.grand-challenge.org/evaluation/challenge/leaderboard"> ![Leaderboard](src/leaderboard.png)</a> | <a href="https://pubmed.ncbi.nlm.nih.gov/37195050"> ![paper](src/paper.png) Overview paper</a>

- <a href="https://academictorrents.com/details/7a638ed187a6180fd6e464b3666a6ea0499af4af"> **LC25000**</a> <br>
The dataset contains color 25,000 Lung and colon histopathological images <br>
***Keyboard:*** *Lung and Colon*, Cancer, Labeled <br>
<a href="https://arxiv.org/abs/1912.12142v1"> ![paper](src/paper.png)</a>

- <a href="https://lyon19.grand-challenge.org"> **LYON19**</a> <br>
The test set contains Region of Interests (ROIs) selected from whole-slide images (WSI) of immunohistochemistry (IHC) stained specimens <br>
***Keyboard:*** *breast, colon, prostate*, whole-slide images (WSI) <br>
<a href="https://lyon19.grand-challenge.org/evaluation/challenge/leaderboard"> ![Leaderboard](src/leaderboard.png)</a> | <a href="https://www.sciencedirect.com/science/article/abs/pii/S1361841519300829"> ![paper](src/paper.png)</a>

- <a href="https://medfm2023.grand-challenge.org"> **MedFMC**</a> <br>
Foundation Model Prompting for Medical Image Classification <br>
***Keyboard:*** *Thoracic and Colon*, Multli Modalities <br>
<a href="https://medfm2023.grand-challenge.org/evaluation/challenge-for-public-long-term/leaderboard"> ![Leaderboard](src/leaderboard.png)</a>

- <a href="https://medshapenet.ikim.nrw"> **MedShapeNet**</a> <br>
This dataset contains over 100,000 3D medical shapes, including bones, organs, vessels, muscles, etc., as well as surgical instruments. It has used in <a href='https://autoimplant.grand-challenge.org'> AutoImplant </a> <br>
<a href="https://proj-page.github.io/medshapenet_publications.html"> ![paper](src/paper.png)</a>

- <a href="http://mridata.org"> **MRIdata**</a> <br>
It is a list of magnetic resonance imaging raw k-space datasets. <br>
***Keyboard:*** MRI <br>

- <a href="https://lunit-io.github.io/research/ocelot_dataset"> **OCELOT**</a> <br>
A dataset purposely dedicated to the study of cell-tissue relationships for cell detection in histopathology <br>
***Keyboard:*** *Kidney, Head-neck, Prostate, Stomach, Endometrium, and Bladder*, Whole-slide images (WSIs) <br>
<a href="https://ocelot2023.grand-challenge.org/evaluation/challenge/leaderboard"> ![Leaderboard](src/leaderboard.png)</a> | <a href="https://arxiv.org/abs/2303.13110"> ![paper](src/paper.png)</a>

- <a href="https://data.mendeley.com/datasets/rscbjbr9sj/2"> **OCT and Chest X-Ray images**</a><br>
***Keyboard:*** *Eye and Chest*, OCT, X-ray, Classification, Labeled<br>
<a href="https://www.cell.com/cell/fulltext/S0092-8674(18)30154-5"> ![paper](src/paper.png)</a>

- <a href="https://paip2021.grand-challenge.org"> **PAIP2021**</a> <br>
Detection of Perineural Invasion in Multiple Organ Cancer <br>
***Keyboard:*** *Colon, Prostate and Pancreatobiliary tract*, Whole-slide images (WSIs), Cancer, Labeled <br>
<a href="https://paip2021.grand-challenge.org/evaluation/validation/leaderboard"> ![Leaderboard](src/leaderboard.png)</a>

- <a href="https://www.rsna.org/rsnai/ai-image-challenge/abdominal-trauma-detection-ai-challenge"> **RSNA Abdominal Trauma Detection**</a> (Radiological Society of North America 2023) <br>
Including more than 4,000 CT exams with various abdominal injuries and a roughly equal number of cases without injury. <br>
***Keyboard:*** *Liver, Spleen, Kidneys, and Bowel*, CT scan, Labeled<br>
<a href="https://www.kaggle.com/competitions/rsna-2023-abdominal-trauma-detection/leaderboard"> ![Leaderboard](src/leaderboard.png)</a>

- <a href="https://segrap2023.grand-challenge.org"> **SegRap2023**</a> <br>
A Benchmark of Organs-at-Risk and Gross Tumor Volume Segmentation for Radiotherapy Planning of Nasopharyngeal Carcinoma <br>
***Keyboard:*** *45 organs-at-risk*, CT Scan, Cancer <br>
<a href="https://segrap2023.grand-challenge.org/evaluation/challenge/leaderboard"> ![Leaderboard](src/leaderboard.png)</a> | <a href="https://arxiv.org/abs/2312.09576"> ![paper](src/paper.png)</a>

- <a href="https://structseg2019.grand-challenge.org"> **StructSeg2019**</a> <br>
Segmentation of organs-at-risk (OAR) and gross target volume (GTV) of tumors of two types of cancers, nasopharynx cancer and lung cancer, for radiation therapy planning. <br>
***Keyboard:*** *Head & neck, Lung*, CT scans, Cancer, Labeled <br>

- <a href="https://ultra-low-dose-pet.grand-challenge.org"> **Ultra-low Dose PET Imaging**</a> <br>
The dataset contains 1447 subjects of whole-body 18F-FDG PET imaging <br>
***Keyboard:*** Positron emission tomography (PET) <br>

- <a href="https://ultrasoundenhance2023.grand-challenge.org"> **USenhance 2023**</a> (Ultrasound Image Enhancement) <br>
***Keyboard:*** *Thyroid, Carotid artery, Breast, Liver, and Kidney*, Ultrasound imaging <br>
<a href="https://ultrasoundenhance2023.grand-challenge.org/evaluation/1st-validationresults-submission-only/leaderboard"> ![Leaderboard](src/leaderboard.png)</a>


__________________


