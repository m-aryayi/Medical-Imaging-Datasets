<h2> Awesome Public Medical Imaging Datasets </h2>


<img src="https://upload.wikimedia.org/wikipedia/commons/3/3e/Under_construction_icon-red.svg" alt="Under Construction" height="22"> ***Under construction: This list is being actively updated with additional datasets.***


## Table of Contents

- [Introduction](#introduction)
- [Head and Neck](#head-and-neck)
  - [Brain](#brain)
  - [Ears, Nose, Teeth, and Throat](#ears-nose-teeth-and-throat)
  - [Eyes](#eyes)
- [Chest and Abdomen](#chest-and-abdomen)
  - [Bowel](#bowel)
  - [Breast](#breast)
  - [Heart and Blood Vessels](#heart-and-blood-vessels)
  - [Kidneys and Urinary Tract](#kidneys-and-urinary-tract)
  - [Liver](#liver)
  - [Lungs](#lungs)
- [Musculoskeletal System](#musculoskeletal-system)
  - [Bones](#bones)
  - [Joints](#joints)
- [Pelvis and Reproductive Organs](#pelvis-and-reproductive-organs)
  - [Female Reproductive Organs](#female-reproductive-organs)
  - [Male Reproductive Organs](#male-reproductive-organs)
- [Other Organs and Systems](#other-organs-and-systems)
  - [Lymph Nodes](#lymph-nodes)
  - [Skin](#skin)
- [Multi Oragns Datasets](#multi-organs-datasets)
- [Notes and Contributions](#notes-and-contributions)

## Introduction

This repository is a collection of publicly available medical imaging datasets. It aims to provide a comprehensive and valuable resource for researchers, healthcare professionals, and developers working in the field of medical imaging analysis.

- ![Leaderboard](src/leaderboard.png) The link of leaderboard.
- ![paper](src/paper.png) The link of related papers.
- ![licence](src/CcLogo.png) The licence of the dataset.

![NumberOfDataSet](src/numberOfDatasets.png)

______

## Head and Neck

### Brain

- <a href="https://my.vanderbilt.edu/votem"> **3D VoTEM**</a> (3-D Validation of Tractography with Experimental MRI)<br>
It has three subset challenges.<br>
***Keyboard:*** Diffusion MRI, Labeled<br>

- <a href="https://academictorrents.com/details/5fc2f273123336ee34b9ea635ef8440377a42888"> **7-Tesla resting-state fMRI test-retest**</a><br>
22 participants were scanned during two sessions spaced one week apart.<br>
***Keyboard:*** High field fMRI, Labeled <br>
<a href="https://www.biorxiv.org/content/10.1101/008706v2"> ![paper](src/paper.png)</a><br>
![licence](src/CcLogo.png) CC0

- <a href="http://www.med.harvard.edu/AANLIB"> **AANLIB**</a><br>
Harward Atlas the Whole Brain <br>
***Keyboard:***  Multi-modality<br>
![licence](src/CcLogo.png) Commercial reproduction or multiple distribution of any kind is prohibited.

- <a href="https://nda.nih.gov/edit_collection.html?id=3104"> **ABCD Neurocognitive Prediction**</a><br>
T1-weighted MRI scans and fluid intelligence scores for children aged 9–10 year <br>
***Keyboard:***  MRI, Segmentation, Labeled  <br>
<a href="https://arxiv.org/abs/1905.10831"> ![paper](src/paper.png)</a>

- <a href="http://fcon_1000.projects.nitrc.org/indi/abide"> **ABIDE**</a> (Autism Brain Imaging Data Exchange) <br>
***Keyboard:*** Autism spectrum disorders (ASDs), MRI <br>
<a href="https://pubmed.ncbi.nlm.nih.gov/23774715"> ![paper](src/paper.png)</a><br>
![licence](src/CcLogo.png) CC BY-NC-SA 3.0

- <a href="http://fcon_1000.projects.nitrc.org/indi/ACPI/html/acpi_du_1.html"> **ACPI DU LaBar**</a> (Addiction Connectome Preprocessed Initiative)<br>
This dataset includes Scan Parameters, Demographic Information and Demographic Key<br>
![licence](src/CcLogo.png) Creative Commons License: Attribution - Non-Commercial

- <a href="http://fcon_1000.projects.nitrc.org/indi/ACPI/html/acpi_mta_1.html"> **ACPI MTA**</a> (Addiction Connectome Preprocessed Initiative)<br>
Multimodal Treatment of Attention Deficit Hyperactivity Disorder (MTA) - Preprocessed<br>
![licence](src/CcLogo.png) Creative Commons License: Attribution - Non-Commercial

- <a href="http://fcon_1000.projects.nitrc.org/indi/ACPI/html/acpi_nyu_1.html"> **ACPI NYU**</a> (Addiction Connectome Preprocessed Initiative)<br>
These data were collected to study functional and structural connectivity in cocaine addiction. This release contains R-fMRI and behavioral assessments and phenotypic information data from 29 cocaine-dependent individuals and 24 healthy comparison participants.<br>
![licence](src/CcLogo.png) Creative Commons License: Attribution - Non-Commercial

- <a href="http://fcon_1000.projects.nitrc.org/indi/adhd200"> **ADHD-200**</a> (Attention Deficit Hyperactivity Disorder) <br>
776 resting-state fMRI and anatomical datasets aggregated across 8 independent imaging sites. <br>
<a href="http://fcon_1000.projects.nitrc.org/indi/adhd200/results.html"> ![Leaderboard](src/leaderboard.png)</a> | <a href="https://www.sciencedirect.com/science/article/pii/S105381191630283X"> ![paper](src/paper.png)</a><br>
![licence](src/CcLogo.png) Consistent with the policies of the 1000 Functional Connectome Project

- <a href="https://adni.loni.usc.edu/data-samples/adni-data"> **ADNI**</a> (Alzheimer's Disease Neuroimaging Initiative) <br>
***Keyboard:*** Multi-modality <br>
<a href="https://www.neurology.org/doi/abs/10.1212/wnl.0b013e3181cb3e25"> ![paper](src/paper.png)</a>

- <a href="https://www.nitrc.org/projects/age-ility"> **Age-ility**</a><br>
This data set consists of 136 subjects <br>
***Keyboard:*** MRI, EEG <br>
<a href="https://www.sciencedirect.com/science/article/pii/S105381191500347X"> ![paper](src/paper.png)</a><br>
![licence](src/CcLogo.png) Attribution Non-Commercial Share Alike

- <a href="https://openneuro.org/datasets/ds001907/versions/3.1.0"> **ANT**</a><br>
It contains 46 healthy aging participants and participants with Parkinson's disease at two sessions each.<br>
***Keyboard:*** MRI <br>
![licence](src/CcLogo.png) CC0

- <a href="https://nilab-uva.github.io/AOMIC.github.io"> **AOMIC**</a> (the Amsterdam Open MRI Collection) <br>
It is a collection of three datasets with multimodal (3T) MRI data <br>
***Keyboard:*** MRI <br>
<a href="https://www.nature.com/articles/s41597-021-00870-6"> ![paper](src/paper.png) Dataset is described </a>

- <a href="http://fcon_1000.projects.nitrc.org/indi/retro/atlas_R1.html"> **ATLAS R1.1**</a> (Anatomical Tracings of Lesions After Stroke) <br>
An dataset of 229 T1-weighted MRI scans (n=220) with manually segmented lesions and metadata.<br>
<a href="https://www.nature.com/articles/sdata201811"> ![paper](src/paper.png)</a>

- <a href="https://atlas.grand-challenge.org"> **ATLAS R2.0**</a> (Anatomical Tracings of Lesions After Stroke) <br>
A larger dataset of T1w MRIs and manually segmented lesion masks <br>
***Keyboard:***  MRI, Segmentation, Labeled  <br>
<a href="https://atlas.grand-challenge.org/evaluation/lesion-segmentation-hidden-test-set/leaderboard/"> ![Leaderboard](src/leaderboard.png)</a> | <a href="https://www.nature.com/articles/s41597-022-01401-7"> ![paper](src/paper.png)</a>

- <a href="http://fcon_1000.projects.nitrc.org/indi/retro/BeijingEnhanced.html"> **Beijing Enhanced**</a><br>
These data include 180 healthy controls from a community sample. <br>
***Keyboard:*** resting state fMRI<br>
![licence](src/CcLogo.png) Creative Commons License: Attribution - Non-Commercial

- <a href="http://fcon_1000.projects.nitrc.org/indi/pro/BeijingShortTR.html"> **Beijing Short TR Sample**</a><br>
Data is obtained with a short TR (0.4 seconds) and a long TR (2.0 seconds).<br>
***Keyboard:*** Resting state fMRI<br>
![licence](src/CcLogo.png) Creative Commons License: Attribution - Non-Commercial

- <a href="http://fcon_1000.projects.nitrc.org/indi/retro/BeijingEOEC.html"> **BeijingEOEC**</a> (Eyes Open Eyes Closed)<br>
These data include 48 healthy controls from a community (student) sample.<br>\
***Keyboard:*** Resting state fMRI<br>
![licence](src/CcLogo.png) Creative Commons License: Attribution - Non-Commercial

- <a href="https://github.com/White65534/BHSD"> **BHSD**</a> (Brain Hemorrhage Segmentation Dataset)<br>
A 3D multi-class ICH dataset containing 192 volumes with pixel-level annotations and 2200 volumes with slice-level annotations across five categories of ICH.<br>
***Keyboard:*** Intracranial hemorrhage (ICH), CT scan, Labeled<br>
<a href="https://arxiv.org/abs/2308.11298"> ![paper](src/paper.png)</a>

- <a href="https://bigbrain.loris.ca/main.php"> **BigBrain**</a> <br>
Microscopic resolution 3D model of the human brain. <br>
***Keyboard:*** X-ray, Labeled <br>
![licence](src/CcLogo.png) CC BY-NC-SA 4.0

- <a href="https://bonbid-hie2023.grand-challenge.org"> **BONBID-HIE**</a> (BOston Neonatal Brain Injury Dataset for Hypoxic Ischemic Encephalopathy) <br>
***Keyboard:***  MRI, Segmentation, Labeled  <br>
<a href="https://bonbid-hie2023.grand-challenge.org/evaluation/development-stage/leaderboard"> ![Leaderboard](src/leaderboard.png)</a> | <a href="https://www.biorxiv.org/content/10.1101/2023.06.30.546841v1"> ![paper](src/paper.png)  Data Descriptor</a><br>
![licence](src/CcLogo.png) CC BY NC ND

- <a href="https://www.kaggle.com/datasets/ahmedhamada0/brain-tumor-detection"> **BR35H**</a><br>
Brain Tumor Detection <br>
***Keyboard:***  MRI, Detection, Classification, Labeled  <br>

- <a href="https://www.kaggle.com/datasets/sartajbhuvaji/brain-tumor-classification-mri"> **Brain Tumor Classification**</a> <br>
Classify MRI images into four classes <br>
***Keyboard:*** MRI, Labeled <br>

- <a href="https://www.kaggle.com/datasets/preetviradiya/brian-tumor-dataset"> **Brian Tumor Dataset**</a> <br>
This dataset consists of the scanned images of brain of patient diagnosed of brain tumour.<br>
***Keyboard:*** X-ray, Cancer, Labeled<br>
![licence](src/CcLogo.png) GPL 2 

- <a href="https://figshare.com/articles/dataset/brain_tumor_dataset/1512427"> **brain tumor dataset**</a><br>
Containing 3064 T1-weighted contrast-inhanced images from 233 patients with three kinds of brain tumor: meningioma, glioma, and pituitary tumor.<br>
***Keyboard:*** Cancer, MRI, Labeled <br>
<a href="https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0157112"> ![paper](src/paper.png)</a> | <a href="https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0140381"> ![paper](src/paper.png)</a><br>
![licence](src/CcLogo.png) CC BY 4.0

- <a href="https://www.cancerimagingarchive.net/collection/brain-tumor-progression"> **Brain-Tumor-Progression**</a><br>
Each patient had two MR exams acquired: within ninety days after completing chemi-radiation therapy and at the progression state which was based on the integration of the clinical performance and/or imaging outcomes.<br>
***Keyboard:*** Cancer, MRI, Labeled <br>
<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7392220"> ![paper](src/paper.png)</a>
![licence](src/CcLogo.png) TCIA Restricted

- <a href="https://aimi.stanford.edu/brainmetshare"> **BrainMetShare**</a> <br>
The dataset includes 156 whole brain MRI studies, including high-resolution, multi-modal pre- and post-contrast sequences in patients with at least 1 brain metastasis.<br>
***Keyboard:*** Detection, MRI, Segmentation, Labeled<br>
<a href="https://arxiv.org/abs/1903.07988"> ![paper](src/paper.png)</a><br>
![licence](src/CcLogo.png) Their Research Use Agreement, as well as to the Terms of Use of the Stanford University School of Medicine website

- <a href="https://brainptm-2021.grand-challenge.org"> **BrainPTM 2021**</a> (Brain Pre-surgical white matter Tractography Mapping) <br>
Data consists of 75 cases<br>
***Keyboard:*** MRI, Cancer, Segmentation, Labeled  <br>
<a href="https://brainptm-2021.grand-challenge.org/evaluation/challenge/leaderboard"> ![Leaderboard](src/leaderboard.png)</a>

- <a href="https://www.brainsimagebank.ac.uk"> **BRAINS**</a> (Brain Images of Normal Subjects) <br>
***Keyboard:*** MRI <br>
<a href="https://www.sciencedirect.com/science/article/pii/S1053811916000331"> ![paper](src/paper.png)</a>

- <a href="https://www.smir.ch/BRATS/Start2012"> **BRATS2012**</a> (Brain Tumor Segmentation) <br>
The tumor and edema regions have been manually delineated.<br>
***Keyboard:*** Multimodal MRI, Cancer, Labeled <br>
<a href="https://ieeexplore.ieee.org/document/6975210"> ![paper](src/paper.png)</a>

- <a href="https://www.smir.ch/BRATS/Start2013"> **BRATS2013**</a> (Brain Tumor Segmentation) <br>
A collection of 60 de-identified clinical cases.l2<br>
***Keyboard:*** Multiparametric, MRI, Cancer, Labeled <br>
<a href="https://ieeexplore.ieee.org/document/6975210"> ![paper](src/paper.png)</a>

- <a href="https://www.smir.ch/BRATS/Start2014"> **BRATS2014**</a> (Brain Tumor Segmentation) <br>
***Keyboard:*** MRI, Cancer, Labeled <br>
<a href="https://ieeexplore.ieee.org/document/6975210"> ![paper](src/paper.png)</a>

- <a href="https://www.smir.ch/BRATS/Start2015"> **BRATS2015**</a> (Brain Tumor Segmentation) <br>
***Keyboard:*** MRI, Cancer, Labeled <br>

- <a href="https://www.med.upenn.edu/sbia/brats2017/data.html"> **BRATS2017**</a> (Brain Tumor Segmentation) <br>
***Keyboard:*** MRI, Cancer, Labeled <br>

- <a href="https://www.med.upenn.edu/sbia/brats2018/data.html"> **BRATS2018**</a> (Brain Tumor Segmentation) <br>
The dataset utilizes multi-institutional pre-operative MRI scans and focuses on the segmentation of intrinsically heterogeneous brain tumors. Furthemore, it also focuses on the prediction of patient overall survival, via integrative analyses of radiomic features and machine learning algorithms. <br>
***Keyboard:*** MRI, Cancer, Labeled <br>

- <a href="https://www.med.upenn.edu/cbica/brats-2019"> **BRATS2019**</a> (Brain Tumor Segmentation) <br>
***Keyboard:*** MRI, Cancer, Labeled <br>
<a href="https://arxiv.org/abs/1811.02629"> ![paper](src/paper.png)</a>

- <a href="https://www.med.upenn.edu/cbica/brats2020"> **BRATS2020**</a> (Brain Tumor Segmentation) <br>
***Keyboard:*** MRI, Cancer, Labeled <br>
<a href="https://arxiv.org/abs/1811.02629"> ![paper](src/paper.png)</a>

- <a href="http://www.braintumorsegmentation.org"> **BRATS2021**</a> (Brain Tumor Segmentation) <br>
***Keyboard:*** MRI, Cancer, Labeled <br>
<a href="https://arxiv.org/abs/1811.02629"> ![paper](src/paper.png)</a>

- <a href="https://www.synapse.org/brats2022"> **BRATS2022**</a> (Brain Tumor Segmentation) <br>
***Keyboard:*** MRI, Cancer, Labeled <br>
<a href="https://www.synapse.org/#!Synapse:syn27046444/wiki/626321"> ![Leaderboard](src/leaderboard.png)</a>

- <a href="https://synapse.org/brats2023"> **BRATS2023**</a> (Brain Tumor Segmentation) <br>
This version addressing additional, populations, tumors (e.g., meningioma), clinical concerns, and technical considerations. <br>
***Keyboard:*** MRI, Cancer, Labeled <br>
<a href="https://www.synapse.org/#!Synapse:syn51156910/wiki/622343"> ![Leaderboard](src/leaderboard.png)</a>

- <a href="https://cada.grand-challenge.org"> **CADA**</a> (Cerebral Aneurysm Detection and Analysis) <br>
Data of patients with cerebral aneurysms without vasospasm were collected for diagnostic and treatment decision purposes.<br>
***Keyboard:*** X-ray rotational angiography (3DRA), Segmentation, Labeled  <br>
<a href="https://cada.grand-challenge.org/evaluation/challenge/leaderboard"> ![Leaderboard](src/leaderboard.png)</a> | <a href="https://www.sciencedirect.com/science/article/abs/pii/S1361841521003789"> ![paper](src/paper.png)</a><br>
![licence](src/CcLogo.png) CC BY-NC-ND 4.0

- <a href="https://caddementia.grand-challenge.org"> **CADDementia**</a> (Computer-Aided Diagnosis of Dementia) <br>
***Keyboard:*** Alzheimer's disease (AD), MRI  <br>
<a href="https://caddementia.grand-challenge.org/results_all"> ![Leaderboard](src/leaderboard.png)</a> | <a href="https://www.sciencedirect.com/science/article/abs/pii/S1053811915000737"> ![paper](src/paper.png)</a> | <a href="https://caddementia.grand-challenge.org/Publications"> ![paper](src/paper.png)</a><br>
![licence](src/CcLogo.png) The data of the evaluation framework may only be used for the evaluation of methods for computer-aided diagnosis dementia through this challenge.

- <a href="https://sites.google.com/view/calgary-campinas-dataset/home"> **Calgary-Campinas**</a> <br>
It is comprised of 359 datasets, approximately 60 subjects per vendor and magnetic field strength.<br>
***Keyboard:*** MRI, Segmentation, Labeled<br>
<a href="https://sites.google.com/view/calgary-campinas-dataset/publications-and-software"> ![paper](src/paper.png)</a> | <a href="https://www.sciencedirect.com/science/article/abs/pii/S1053811917306687"> ![paper](src/paper.png)</a>

- <a href="https://camcan-archive.mrc-cbu.cam.ac.uk/dataaccess"> **Cam-CAN**</a> (Cambridge Centre for Ageing and Neuroscience) <br>
Nearly 700 adults were scanned using structural Magnetic Resonance Imaging, functional MRI, magnetoencephalography, and completed multiple cognitive experiments. <br>
***Keyboard:*** lifespan, MRI, fMRI, MEG <br>
<a href="https://www.sciencedirect.com/science/article/pii/S1053811915008150"> ![paper](src/paper.png)</a> | <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4219118"> ![paper](src/paper.png)</a>

- <a href="https://cause07.grand-challenge.org"> **CAUSE07**</a> (Caudate Segmentation Evaluation 2007)<br>
***Keyboard:*** MRI<br>
![licence](src/CcLogo.png) CC0

- <a href="https://openneuro.org/datasets/ds002207/versions/1.0.0"> **CEREBRuM**</a> (Convolutional Encoder-decodeR for Fully Volumetric Fast sEgmentation of BRain MRI)<br>
<a href="https://arxiv.org/abs/1909.05085"> ![paper](src/paper.png)</a><br>
![licence](src/CcLogo.png) CC0

- <a href="https://openfmri.org/dataset/ds000174"> **Changes Associated with Heavy Cannabis Use**</a> <br>
T1-weighted structural MRI study of cannabis users at baseline and 3 years follow up.<br>
***Keyboard:*** MRI<br>
<a href="https://pubmed.ncbi.nlm.nih.gov/27224247"> ![paper](src/paper.png)</a><br>
![licence](src/CcLogo.png) CC BY-NC

- <a href="http://fcon_1000.projects.nitrc.org/indi/retro/ClevelandCCF.html"> **Cleveland CCF**</a><br>
It includes 31 control adults (11M/20F; ages: 24-60). In addition to the resting state scan this sample includes physiological measurements (heart rate and breathing) obtained during the resting state scan.<br>
***Keyboard:*** Resting state fMRI (R-fMRI)<br>
![licence](src/CcLogo.png) Creative Commons License: Attribution - Non-Commercial

- <a href="http://fcon_1000.projects.nitrc.org/indi/cmi_healthy_brain_network"> **CMI-HBN**</a> (Child Mind Institute Healthy Brain Network) <br>
Data from 10,000 children and adolescents (ages 5-21). <br>
***Keyboard:*** Neuroimaging, MRI, EEG <br>
<a href="https://www.nature.com/articles/sdata2017181"> ![paper](src/paper.png) Data Descriptor</a> 

- <a href="http://fcon_1000.projects.nitrc.org/indi/retro/cobre.html"> **COBRE**</a> (Center for Biomedical Research Excellence)<br>
functional MR data from 72 patients with Schizophrenia and 75 healthy controls (ages ranging from 18 to 65 in each group)<br>
***Keyboard:*** fMRI <br>
![licence](src/CcLogo.png) Attribution - Non-Commercial

- <a href="https://physionet.org/content/ct-ich"> **Computed Tomography Images for Intracranial Hemorrhage Detection and Segmentation**</a><br>
A dataset of 82 CT scans was collected, including 36 scans for patients diagnosed with intracranial hemorrhage (ICH).<br>
***Keyboard:*** CT scan, Labeled<br>
<a href="https://www.mdpi.com/2306-5729/5/1/14"> ![paper](src/paper.png)</a><br>
![licence](src/CcLogo.png) PhysioNet Restricted Health Data License 1.5.0

- <a href="http://fcon_1000.projects.nitrc.org/indi/CoRR/html"> **CoRR**</a> (Consortium for Reliability and Reproducibility) <br>
It has aggregated 1,629 typical individuals resting state fMRI data. <br>
***Keyboard:*** Resting state fMRI (rfMRI) <br>
<a href="https://www.nature.com/articles/sdata201449"> ![paper](src/paper.png)</a>

- <a href="https://www.cancerimagingarchive.net/collection/cptac-gbm"> **CPTAC-GBM**</a> (Clinical Proteomic Tumor Analysis Consortium Glioblastoma Multiforme)<br>
***Keyboard:*** Multi-modality, Cancer <br>
![licence](src/CcLogo.png) CC BY 3.0 - TCIA Restricted

- <a href="http://headctstudy.qure.ai"> **CQ500**</a> <br>
A dataset of 491 scans with 193,317 slices <br>
***Keyboard:*** CT Scan <br>
<a href="https://arxiv.org/abs/1803.05854"> ![paper](src/paper.png)</a>

- <a href="https://openneuro.org/datasets/ds002236/versions/1.1.1"> **Cross-Sectional Multidomain Lexical Processing**</a><br>
This dataset explores the neural mechanisms and development of lexical processing through task based fMRI of rhyming, spelling, and semantic judgement tasks in both the auditory and visual modalities.<br>
***Keyboard:*** fMRI <br>
<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6957861"> ![paper](src/paper.png)</a><br>
![licence](src/CcLogo.png) CC0

- <a href="https://crossmoda.grand-challenge.org"> **crossMoDA 2021**</a> (Cross-Modality Domain Adaptation) <br>
The goal is to segment two key brain structures involved in the follow-up and treatment planning of vestibular schwannoma (VS): the tumour and the cochlea<br>
***Keyboard:*** MRI, Segmentation <br>
<a href="https://crossmoda.grand-challenge.org/evaluation/challenge/leaderboard"> ![Leaderboard](src/leaderboard.png)</a> | <a href="https://www.sciencedirect.com/science/article/pii/S1361841522002560"> ![paper](src/paper.png)</a>

- <a href="https://crossmoda2022.grand-challenge.org"> **crossMoDA 2022**</a> (Cross-Modality Domain Adaptation) <br>
The goal is to segment two key brain structures involved in the follow-up and treatment planning of vestibular schwannoma (VS): the tumour and the cochlea, and to automatically classify hrT2 images with VS according to the Koos grade<br>
***Keyboard:*** MRI, Segmentation <br>
<a href="https://crossmoda2022.grand-challenge.org/evaluation/challenge/leaderboard"> ![Leaderboard](src/leaderboard.png)</a>

- <a href="https://www.synapse.org/#!Synapse:syn51236108/wiki/621615"> **crossMoDA 2023**</a> (Cross-Modality Domain Adaptation) <br>
The 2023 edition extends the segmentation task by including multi-institutional, heterogenous data acquired for routine surveillance purposes and introduces a sub-segmentation for the tumour (intra- and extra-meatal components) thereby leading to a 3 class problem. <br>
***Keyboard:*** MRI, Segmentation <br>

- <a href="http://fcon_1000.projects.nitrc.org/indi/retro/CUNMET.html"> **CUNMET**</a> (Clínica Universidad de Navarra Methylphenidate)<br>
Examination of the neural correlates of differential treatment response to stimulants (methylphenidate and lisdexamfetamine) in boys and girls with ADHD treated in a naturalistic context.<br>
***Keyboard:*** MRI, Resting state fMRI, Perfusion/arterial spin labeling (ASL)<br>

- <a href="https://www.ncbi.nlm.nih.gov/projects/gap/cgi-bin/study.cgi?study_id=phs000607.v3.p2"> **dbGaP**</a> (Genotypes and Phenotype)<br>
Study about Neurodevelopmental Genomics: Trajectories of Complex Phenotypes<br>
***Keyboard:*** MRI, Multimodal Neuroimaging <br>
<a href="https://www.sciencedirect.com/science/article/abs/pii/S1053811915002529"> ![paper](src/paper.png)</a> | <a href="https://www.sciencedirect.com/science/article/abs/pii/S1053811913008331"> ![paper](src/paper.png)</a>

- <a href="https://www.cancerimagingarchive.net/collection/dfci-bch-bwh-peds-hgg"> **DFCI-BCH-BWH-PEDs-HGG**</a> <br>
MR imaging of pediatric subjects with high-grade gliomas. It is a subset of the BraTS-PEDs 2023 challenge<br>
***Keyboard:*** Cancer <br>
![licence](src/CcLogo.png) CC BY 4.0

- <a href="http://fcon_1000.projects.nitrc.org/indi/retro/dlbs.html"> **DLBS**</a> (Dallas Lifespan Brain Study)<br>
350 healthy adults, aged 20-89 who are thoroughly characterized in terms of cognition, brain structure and brain function across the adult lifespan<br>
***Keyboard:*** MRI, PET, Cognitive Data <br>
![licence](src/CcLogo.png) Attribution - Non-Commercial

- <a href="https://xnat.bmia.nl/data/archive/projects/egd"> **EGD**</a> (Erasmus Glioma Database)<br>
It is a collection of 774 patients with glioma.<br>
***Keyboard:*** MRI, Cancer<br>

- <a href="https://rdr.ucl.ac.uk/articles/dataset/EPISURG_a_dataset_of_postoperative_magnetic_resonance_images_MRI_for_quantitative_analysis_of_resection_neurosurgery_for_refractory_epilepsy/9996158"> **EPISURG**</a> <br>
A dataset of postoperative MRI images for quantitative analysis of resection neurosurgery for refractory epilepsy. <br>
<a href="https://link.springer.com/chapter/10.1007/978-3-030-59716-0_12"> ![paper](src/paper.png)</a><br>
![licence](src/CcLogo.png) CC BY-NC-SA 4.0

- <a href="https://feta.grand-challenge.org"> **FeTA**</a> (Fetal Tissue Annotation) <br>
A dataset of manually segmented pathological and non-pathological fetal magnetic resonance brain volume reconstructions across a range of gestational ages into different tissue categories <br>
***Keyboard:*** MRI, Labeled, Segmentation <br>
<a href="https://www.nature.com/articles/s41597-021-00946-3"> ![paper](src/paper.png)</a>

- <a href="http://fcon_1000.projects.nitrc.org/indi/retro/find_stanford.html"> **FIND Lab**</a> ( Functional Imaging in Neuropsychiatric Disorders)<br>
This dataset is comprised of 13 subjects, ages 18-29, 8 female, with both strutural and functional MRI. The functional paradigms collected are as Episodic Memory, Music, Subtraction<br>
<a href="https://pubmed.ncbi.nlm.nih.gov/21616982"> ![paper](src/paper.png)</a><br>
![licence](src/CcLogo.png) Creative Commons License: Attribution - Non-Commercial

- <a href="http://niftyweb.cs.ucl.ac.uk/program.php?p=CHALLENGE"> **GMSC**</a> (Grey matter segmentation challenge)<br>
***Keyboard:*** MRI, Labeled<br>
<a href="https://www.sciencedirect.com/science/article/pii/S1053811917302185"> ![paper](src/paper.png)</a><br>
![licence](src/CcLogo.png) Data is intended for research and educational purposes only

- <a href="https://zenodo.org/records/1206163"> **Gray matter segmentation at 7T MRI**</a> <br>
The dataset consist of 7 Tesla MRI anatomical images of living human brains and hand labeled cortical gray matter images. <br>
***Keyboard:*** High field MRI, Labeled, Segmentation <br>
<a href="https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0198335"> ![paper](src/paper.png)</a><br>
![licence](src/CcLogo.png) CC BY 4.0

- <a href="https://www.neuroinfo.org/gsp"> **GSP**</a> (Genomics Superstruct Project) <br>
Personality and cognitive measures were obtained on a subset of participants. Each dataset contains a T1-weighted structural MRI scan and either one (n=1,570) or two (n=1,139) resting state functional MRI scans. <br>
***Keyboard:*** MRI <br>
<a href="https://www.nature.com/articles/sdata201531"> ![paper](src/paper.png)</a>

- <a href="http://hardi.epfl.ch/static/events/2012_ISBI"> **HARDI 2012**</a><br>
***Keyboard:*** Diffusion MRI<br>
<a href="https://ieeexplore.ieee.org/document/6630106"> ![paper](src/paper.png)</a>

- <a href="http://hardi.epfl.ch/static/events/2013_ISBI"> **HARDI 2013**</a> <br>
It focuses on the effect of the local reconstruction accuracy on the quality of connectivity reconstruction. <br>
***Keyboard:*** Diffusion MRI <br>

- <a href="http://fcon_1000.projects.nitrc.org/indi/hbn_ssi"> **HBN-SSI**</a> (Healthy Brain Network Serial Scanning Initiative)<br>
The primary goal is to assess and compare test-retest reliabilities for full-brain connectivity patterns derived from functional MRI data obtained during different scan conditions.<br>

- <a href="http://www.humanconnectomeproject.org"> **HCP**</a> (Human Connectome Project)<br>
***Keyboard:*** MRI<br>
<a href="https://onlinelibrary.wiley.com/doi/full/10.1002/brb3.1647"> ![paper](src/paper.png)</a>

- <a href="https://www.kaggle.com/datasets/felipekitamura/head-ct-hemorrhage"> **Head CT - hemorrhage**</a><br>
This dataset contains 100 normal head CT slices and 100 other with hemorrhage. No distinction between kinds of hemorrhage. <br>
***Keyboard:*** CT scan, Labeled <br>
![licence](src/CcLogo.png) CC0: Public Domain

- <a href="https://www.kaggle.com/datasets/andrewmvd/hippocampus-segmentation-in-mri-images"> **Hippocampus Segmentation**</a><br>
This dataset contains T1-weighted MR images of 50 subjects, 40 of whom are patients with temporal lobe epilepsy and 10 are nonepileptic subjects. <br>
***Keyboard:*** MRI, Labeled <br>
<a href="https://pubmed.ncbi.nlm.nih.gov/21286946"> ![paper](src/paper.png)</a><br>
![licence](src/CcLogo.png) The dataset is free to use for research and education.

- <a href="https://www.nitrc.org/projects/ibsr/"> **IBSR**</a> (Internet Brain Segmentation Repository)  <br>
Manually-guided expert segmentation results along with magnetic resonance brain image data  <br>
***Keyboard:*** MRI, Labeled <br>
![licence](src/CcLogo.png) Free For Non-Commercial Use Only

- <a href="https://instance.grand-challenge.org"> **INSTANCE2022**</a> (INtracranial
hemorrhage SegmenTAtioN ChallengE) <br>
A training set of 100 cases with ground-truth and a validation set with 30 cases without ground-truth labels.<br>
***Keyboard:*** Intracranial hemorrhage (ICH), CT Scan, Labeled  <br>
<a href="https://instance.grand-challenge.org/evaluation/challenge/leaderboard"> ![Leaderboard](src/leaderboard.png)</a> | <a href="https://arxiv.org/abs/2301.03281"> ![paper](src/paper.png)</a>

- <a href="https://iseg2017.web.unc.edu"> **iSeg2017**</a> <br>
6 month old Infant Brain Segmentation<br>
***Keyboard:*** MRI, Labeled  <br>
<a href="https://iseg2017.web.unc.edu/rules/results"> ![Leaderboard](src/leaderboard.png)</a> | <a href="https://ieeexplore.ieee.org/document/8654000"> ![paper](src/paper.png)</a>

- <a href="https://iseg2019.web.unc.edu"> **iSeg2019**</a> <br>
6 month old Infant Brain Segmentation<br>
***Keyboard:*** MRI, Labeled  <br>
<a href="https://iseg2019.web.unc.edu/evaluation-results"> ![Leaderboard](src/leaderboard.png)</a> | <a href="https://ieeexplore.ieee.org/document/9339962"> ![paper](src/paper.png)</a>

- <a href="http://www.isles-challenge.org"> **ISLES**</a> (Ischemic Stroke Lesion Segmentation) <br>
It has multi versions in 2015 to 2018 <br>
***Keyboard:*** MRI <br>
<a href="https://pubmed.ncbi.nlm.nih.gov/33957774"> ![paper](src/paper.png)</a>

- <a href="https://isles22.grand-challenge.org"> **ISLES'22**</a> (Ischemic Stroke Lesion Segmentation) <br>
Multimodal MRI infarct segmentation in acute and sub-acute stroke<br>
***Keyboard:*** MRI <br>
<a href="https://isles22.grand-challenge.org/evaluation/preliminary-docker-evaluation/leaderboard"> ![Leaderboard](src/leaderboard.png)</a>

- <a href="https://brain-development.org/ixi-dataset"> **IXI**</a><br>
This dataset have been collected nearly 600 MR images from normal, healthy subjects.<br>
***Keyboard:*** MRI<br>
![licence](src/CcLogo.png) CC BY-SA 3.0

- <a href="https://www.cancerimagingarchive.net/collection/lgg-1p19qdeletion"> **LGG-1p19qDeletion**</a><br>
It performed in 159 subjects with Low Grade Gliomas. <br>
***Keyboard:*** MRI, Segmentation, Labeled<br>
<a href="https://link.springer.com/article/10.1007/s10278-017-9984-3"> ![paper](src/paper.png)</a><br>
![licence](src/CcLogo.png) TCIA Restricted - CC BY 3.0

- <a href="https://openneuro.org/datasets/ds001486"> **Longitudinal Neuroimaging on Arithmetic Processing**</a><br>
Brain Correlates of Math Development in Children. <br>
***Keyboard:*** MRI <br>
<a href="https://www.nature.com/articles/sdata201940"> ![paper](src/paper.png)</a><br>
![licence](src/CcLogo.png) CC0

- <a href="https://openneuro.org/datasets/ds001894"> **Longitudinal Neuroimaging on Multisensory Lexical Processing**</a><br>
Longitudinal Brain Correlates of Multisensory Lexical Processing in Children. <br>
***Keyboard:*** MRI <br>
<a href="https://www.nature.com/articles/s41597-019-0338-5"> ![paper](src/paper.png)</a><br>
![licence](src/CcLogo.png) CC0

- <a href="https://zenodo.org/records/7523691"> **M4Raw**</a><br>
A multi-contrast, multi-repetition, multi-channel MRI k-space dataset for low-field MRI research. <br>
***Keyboard:*** 0.3 Tesla MRI <br>
<a href="https://www.nature.com/articles/s41597-023-02181-4"> ![paper](src/paper.png)</a><br>
![licence](src/CcLogo.png) CC BY 4.0

- <a href="https://openneuro.org/datasets/ds000239"> **Maclaren test-retest brain volume**</a><br>
The dataset comprises three participants, each of whom was scanned 40 times.<br>
***Keyboard:*** MRI<br>
<a href="https://www.nature.com/articles/sdata201437"> ![paper](src/paper.png)</a><br>
![licence](src/CcLogo.png) CC0

- <a href="https://www.massive-data.org/massive-data"> **MASSIVE**</a> (Multiple Acquisitions for Standardization of Structural Imaging Validation and Evaluation)<br>
The database consist of 8000 diffusion-weighted volumes and ten 3D FLAIR, T1-, and T2-weighted datasets of a single healthy subject. <br>
***Keyboard:*** diffusion MRI <br>
<a href="https://pubmed.ncbi.nlm.nih.gov/27173617"> ![paper](src/paper.png)</a>

- <a href="https://my.vanderbilt.edu/memento"> **MEMENTO**</a> (Mri whitE Matter rEcoNstrucTiOn)<br>
The aim is evaluating and advancing the state of the microstructural modeling field.<br>
***Keyboard:*** Diffusion MRI<br>

- <a href="https://portal.conp.ca/dataset?id=projects/mica-mics"> **MICA-MICs**</a> (Microstructure-Informed Connectomics)<br>
The dataset provides raw and fully processed multimodal neuroimaging data acquired in 50 healthy control participants at a filed strength of 3T. <br>
***Keyboard:*** multimodal MRI <br>
<a href="https://www.nature.com/articles/s41597-022-01682-y"> ![paper](src/paper.png)</a><br>
![licence](src/CcLogo.png) CC0

- <a href="https://mindboggle.info/data.html"> **Mindboggle**</a>  <br>
Manually labeled human brain image data. <br>
***Keyboard:*** MRI, Labeled <br>
<a href="https://www.frontiersin.org/articles/10.3389/fnins.2012.00171/full"> ![paper](src/paper.png)</a><br>
![licence](src/CcLogo.png) CC BY 4.0

- <a href="https://www.ucl.ac.uk/drc/research-clinical-trials/minimal-interval-resonance-imaging-alzheimers-disease-miriad"> **MIRIAD**</a> (Minimal Interval Resonance Imaging in Alzheimer's Disease) <br>
Dataset is a series of longitudinal volumetric T1 MRI scans of 46 mild–moderate Alzheimer's subjects and 23 controls. <br>
***Keyboard:*** Alzheimer's disease (AD), MRI <br>
<a href="https://www.sciencedirect.com/science/article/pii/S105381191201230X"> ![paper](src/paper.png) Overview </a><br>
![licence](src/CcLogo.png) BIRN Data License

- <a href="https://www.nitrc.org/projects/multimodal"> **MMRR**</a> (Multi-Modal MRI Reproducibility Resource)<br>
Scan-rescan imaging sessions on 21 healthy volunteers. <br>
***Keyboard:*** MRI, resting state fMRI <br>
<a href="https://www.sciencedirect.com/science/article/abs/pii/S1053811910015259"> ![paper](src/paper.png)</a>

- <a href="https://openneuro.org/datasets/ds000221"> **MPILMBB**</a> (MPI-Leipzig Mind-Brain-Body)<br>
A functional connectome phenotyping dataset including cognitive state and personality measures. <br>
***Keyboard:*** MRI, Cognitive Data <br>
<a href="https://www.nature.com/articles/sdata2018307"> ![paper](src/paper.png)</a><br>
![licence](src/CcLogo.png) CC0

- <a href="http://fcon_1000.projects.nitrc.org/indi/retro/MPI_LEMON.html"> **MPI-LEMON**</a><br>
It presents a dataset of 228 healthy participants comprising a young and an elderly group acquired cross-sectionally to study mind-body-emotion interactions.<br>
***Keyboard:*** MRI, EEG<br>
<a href="https://pubmed.ncbi.nlm.nih.gov/30747911"> ![paper](src/paper.png)</a>

- <a href="https://mrbrains13.isi.uu.nl"> **MRBrainS13**</a> <br>
Evaluation Framework for Brain Image Segmentation in 3T MRI Scans<br>
<a href="https://onlinelibrary.wiley.com/doi/10.1155/2015/813696"> ![paper](src/paper.png)</a>

- <a href="https://mrbrains18.isi.uu.nl/"> **MRBrainS18**</a> <br>
The purpose is to directly compare methods for segmentation of gray matter, white matter, cerebrospinal fluid, and other structures on 3T MRI scans of the brain, and to assess the effect of (large) pathologies on segmentation and volumetry.<br>
<a href="https://mrbrains18.isi.uu.nl/results/index.html"> ![Leaderboard](src/leaderboard.png)</a>

- <a href="https://www.kaggle.com/datasets/jboysen/mri-and-alzheimers"> **MRI and Alzheimers**</a><br>
Magnetic Resonance Imaging Comparisons of Demented and Nondemented Adults<br>
***Keyboard:*** Alzheimer's Disease (AD), Labeled<br>

- <a href="https://www.kaggle.com/datasets/sabermalek/mrihs"> **MRI Hippocampus Segmentation**</a> <br>
All images are for people suffering from Alzheimer's.<br>
***Keyboard:*** MRI, Segmentation, Alzheimer's Detection<br>
![licence](src/CcLogo.png) CC BY-NC-SA 4.0

- <a href="https://iacl.ece.jhu.edu/index.php/MSChallenge"> **MS**</a> (Multiple sclerosis) <br>
82 data sets had the white matter lesions associated with multiple sclerosis delineated by two human expert raters. <br>
***Keyboard:*** MRI, Labeled, Segmentation <br>
<a href="https://pubmed.ncbi.nlm.nih.gov/28087490">![paper](src/paper.png)</a> | <a href="https://pubmed.ncbi.nlm.nih.gov/28491937"> ![paper](src/paper.png)</a>

- <a href="https://openneuro.org/datasets/ds000224"> **MSC**</a> (Midnight Scan Club)<br>
This dataset focused on the precise characterization of ten individual subjects via collection of large amounts of per-individual data.<br>
***Keyboard:*** Resting-state fMRI, MRI, Neuropsychological testing<br>
<a href="https://www.cell.com/neuron/fulltext/S0896-6273(17)30613-X"> ![paper](src/paper.png)</a><br>
![licence](src/CcLogo.png) CC0

- <a href="https://www.nitrc.org/projects/msseg"> **MSSeg 2008**</a><br>
The goal is to compare algorithms to segment the multiple sclerosis (MS) lesions.<br>
***Keyboard:*** MRI, Segmentation<br>

- <a href="https://portal.fli-iam.irisa.fr/msseg-challenge"> **MSSEG 2016**</a><br>
A total of 100 multiple sclerosis patients<br>
***Keyboard:*** MRI, Segmentation<br>
<a href="https://www.nature.com/articles/s41598-018-31911-7"> ![paper](src/paper.png)</a>

- <a href="https://www.smir.ch/MTOP/Start2016"> **MTOP2016**</a> (Mild Traumatic Brain Injury Outcome Prediction) <br>
***Keyboard:*** MRI, Labeled <br>

- <a href="https://figshare.com/articles/dataset/Multicenter_dataset_of_multishell_diffusion_magnetic_resonance_imaging_in_healthy_traveling_adults_with_identical_setting/8851955"> **Multi-shell diffusion MRI**</a><br>
It was collected from three traveling subjects with identical acquisition setting in ten imaging centers. <br>
***Keyboard:*** MRI <br>
<a href="https://www.nature.com/articles/s41597-020-0493-8"> ![paper](src/paper.png)</a><br>
![licence](src/CcLogo.png) CC BY 4.0

- <a href="http://fcon_1000.projects.nitrc.org/indi/pro/wchsu_li_index.html"> **Multimodal MRI of chess players**</a><br>
It is a MRI dataset of 29 professional Chinese chess players.<br>
![licence](src/CcLogo.png) Creative Commons License: Attribution - Non-Commercial

- <a href="http://fcon_1000.projects.nitrc.org/indi/retro/Narratives.html"> **Narratives**</a><br>
fMRI data for evaluating models of naturalistic language comprehension. <br>
***Keyboard:*** fMRI, Labeled <br>
![licence](src/CcLogo.png) CC0

- <a href="http://fcon_1000.projects.nitrc.org/indi/retro/nat_view.html"> **Naturalistic Viewing**</a><br>
The dataset represents simultaneously collected electroencephalography (EEG) and function magnetic resonance imaging (fMRI) recordings obtained from 22 individuals between the ages of 23 and 51 years-old.<br>
<a href="https://www.biorxiv.org/content/10.1101/2022.11.23.517540v2"> ![paper](src/paper.png)</a><br>
![licence](src/CcLogo.png) CC BY 4.0

- <a href="http://fcon_1000.projects.nitrc.org/indi/retro/NEO2012.html"> **NEO2012**</a><br>
The dataset consists of male and female adults, all healthy controls with no psychiatric history used in the 2011 PLoS ONE study.<br>
<a href="https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0027633"> ![paper](src/paper.png)</a><br>
![licence](src/CcLogo.png) Creative Commons License: Attribution - Non-Commercial

- <a href="http://www.neuromorphometrics.com/?page_id=23"> **NeuAtlas Labeled Brain Scans**</a><br>
***Keyboard:*** MRI, Labeled, Segmentation <br>

- <a href="fcon_1000.projects.nitrc.org/indi/retro/Power2012.html"> **NeuroImage article by Power et al.**</a><br>
The dataset consists of children, adolescents, and adults, all of which are controls with no diagnosis.<br>
***Keyboard:*** MRI<br>
<a href="https://pubmed.ncbi.nlm.nih.gov/22019881"> ![paper](src/paper.png)</a><br>
![licence](src/CcLogo.png) Creative Commons License: Attribution - Non-Commercial

- <a href="https://openneuro.org/datasets/ds001021"> **NKI-RS**</a> (Nathan Kline Institute-Rockland Sample)<br>
NKI-RS is an ongoing, institutionally centered endeavor aimed at creating a large-scale (N > 1000), deeply phenotyped, community-ascertained, lifespan sample (ages 6–85 years old) with advanced neuroimaging and genetics. <br>
***Keyboard:*** MRI<br>
<a href="https://www.frontiersin.org/journals/neuroscience/articles/10.3389/fnins.2012.00152/full"> ![paper](src/paper.png)</a>

- <a href="http://fcon_1000.projects.nitrc.org/indi/retro/NorthShoreLIJ.html"> **North Shore - LIJ**</a><br>
It includes 6 patients with medically intractable epilepsy that underwent implantation of intracranial electrodes for seizure onset localization prior to resective neurosurgery.<br>
***Keyboard:*** Resting state fMRI (R-fMRI)<br>
<a href="https://www.pnas.org/doi/10.1073/pnas.1019750108"> ![paper](src/paper.png)</a><br>
![licence](src/CcLogo.png) Creative Commons License: Attribution - Non-Commercial

- <a href="http://www.naturalscenesdataset.org"> **NSD**</a> (Natural Scenes Dataset) <br>
High-resolution fMRI responses to tens of thousands of richly annotated natural scenes <br>
***Keyboard:*** fMRI, Labeled <br>
<a href="https://www.nature.com/articles/s41593-021-00962-x">![paper](src/paper.png) Description of the dataset</a>

- <a href="http://fcon_1000.projects.nitrc.org/indi/pro/nyu.html"> **NYUIQ**</a><br>
It consists of datasets from 49 psychiatrically neurotypical adults, with age, gender and intelligence quotient (IQ) information provided.<br>
***Keyboard:*** T1 weighted MRI, Resting state fMRI scans (R-fMRI)<br>
![licence](src/CcLogo.png) Creative Commons License: Attribution - Non-Commercial

- <a href="https://oasis-brains.org"> **OASIS**</a> (Open Access Series of Imaging Studies) <br>
It has multi versions. <br>
***Keyboard:*** Multi modality, Neuroimaging <br>
<a href="https://direct.mit.edu/jocn/article-abstract/19/9/1498/4427/Open-Access-Series-of-Imaging-Studies-OASIS-Cross">![paper](src/paper.png)</a> | <a href="https://direct.mit.edu/jocn/article/22/12/2677/4983/Open-Access-Series-of-Imaging-Studies-Longitudinal"> ![paper](src/paper.png)</a> | <a href="https://www.medrxiv.org/content/10.1101/2019.12.13.19014902v1"> ![paper](src/paper.png)</a> | <a href="https://www.sciencedirect.com/science/article/pii/S2213158220300851"> ![paper](src/paper.png)</a>

- <a href="http://fcon_1000.projects.nitrc.org/indi/retro/parkinsons.html"> **Parkinson's Disease Datasets**</a><br>
The data are comprised of 27 PD patients and 16 age-matched normal controls in the Neurocon dataset, and 20 PD patients and 20 age-matched controls in the Tao Wu dataset. Both sets contain T1 and resting-state scans.<br>
<a href="https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0188196"> ![paper](src/paper.png)</a><br>
![licence](src/CcLogo.png) CC BY-NC-SA

- <a href="https://zenodo.org/records/5749645"> **PERFORM**</a><br>
Functional Magnetic Resonance Imaging (fMRI), electroencephalography (EEG), sleep and nutrition assessments were performed on one male control subject.<br>

- <a href="https://www.nitrc.org/projects/ping"> **PING**</a> (Pediatric Imaging, Neurocognition, and Genetics)<br>
The study includes 1400 children between the ages of 3 and 20 years so that links between genetic variation and developing patterns of brain connectivity can be examined. <br>
***Keyboard:*** MRI<br>
<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4628902"> ![paper](src/paper.png)</a>

- <a href="https://www.ppmi-info.org"> **PPMI**</a> (Parkinson’s Progression Markers Initiative)<br>
Data from Parkinson’s Disease, Prodromal Cohort, and Healthy Controls. <br>
<a href="https://www.ppmi-info.org/publications-and-presentations"> ![paper](src/paper.png)</a>

- <a href="https://f1000research.com/articles/6-93/v2"> **Prenatal brain**</a><br>
It was collected from three traveling subjects with identical acquisition setting in ten imaging centers. <br>
***Keyboard:*** fetal MRI, Segmentation <br>
![licence](src/CcLogo.png) CC0 1.0

- <a href="https://openpreventad.loris.ca"> **PREVENT-AD**</a> (Pre-symptomatic Evaluation of Experimental or Novel Treatments for Alzheimer Disease) <br>
***Keyboard:*** MRI, Labeled <br>
<a href="https://pubmed.ncbi.nlm.nih.gov/33964608">![paper](src/paper.png)</a> | <a href="https://pubmed.ncbi.nlm.nih.gov/32474466"> ![paper](src/paper.png)</a> | <a href="https://pubmed.ncbi.nlm.nih.gov/34192666"> ![paper](src/paper.png)</a>

- <a href="http://fcon_1000.projects.nitrc.org/indi/pro/Quiron-Valencia.html"> **Quiron-Valencia**</a><br>
The first release includes data for 45 participants. Each participant has an anatomical as well as a resting state fMRI scan.<br>
***Keyboard:*** Resting state fMRI (R-fMRI)<br>
![licence](src/CcLogo.png) Creative Commons License: Attribution - Non-Commercial

- <a href="https://realnoisemri.grand-challenge.org"> **RealNoiseMRI**</a> <br>
Evaluating the performance of markerless prospective motion correction and selective reacquisition in a general clinical protocol <br>
***Keyboard:*** MRI <br>
![licence](src/CcLogo.png) CC0

- <a href="https://www.cancerimagingarchive.net/collection/rembrandt"> **REMBRANDT**</a><br>
It contains data generated through the Glioma Molecular Diagnostic Initiative from 874 glioma specimens comprising approximately 566 gene expression arrays, 834 copy number arrays, and 13,472 clinical phenotype data points. <br>
***Keyboard:*** MRI<br>
![licence](src/CcLogo.png) TCIA Restricted - CC BY 3.0

- <a href="https://archive.norstore.no/pages/public/datasetDetail.jsf?id=10.11582/2017.00004"> **RESECT**</a> (REtroSpective Evaluation of Cerebral Tumors)  <br>
A clinical database of pre-oper, ative MRI and intra-operative ultrasound in low-grade glioma surgeries <br>
***Keyboard:*** Cancer, Registration, Labeled <br>
<a href="https://aapm.onlinelibrary.wiley.com/doi/full/10.1002/mp.12268"> ![paper](src/paper.png)</a><br>
![licence](src/CcLogo.png) CC BY 4.0

- <a href="https://www.cancerimagingarchive.net/collection/rider-neuro-mri"> **RIDER NEURO MRI**</a> (Reference Image Database to Evaluate Therapy Response)<br>
It contains data on 19 patients with recurrent glioblastoma who underwent repeat imaging sets.<br>
***Keyboard:*** Cancer<br>
![licence](src/CcLogo.png) TCIA Restricted - CC BY 3.0

- <a href="https://www.rsna.org/rsnai/ai-image-challenge/brain-tumor-ai-challenge-2021"> **RSNA Brain Tumor**</a> (Radiological Society of North America 2021) <br>
A dataset for brain tumor segmentation and radiogenomic classification <br>
***Keyboard:*** MRI, Labeled <br>

- <a href="https://www.rsna.org/rsnai/ai-image-challenge/rsna-intracranial-hemorrhage-detection-challenge-2019"> **RSNA Intracranial Hemorrhage Detection**</a> (Radiological Society of North America 2019) <br>
A dataset of more than 25,000 annotated cranial CT exams <br>
***Keyboard:*** CT scan, Labeled<br>
<a href="https://pubmed.ncbi.nlm.nih.gov/33937827"> ![paper](src/paper.png)</a>

- <a href="http://fcon_1000.projects.nitrc.org/indi/retro/sald.html"> **SALD**</a> (Southwest University Adult Lifespan Dataset)<br>
494 healthy adults (age range: 19-80 years; Males=187) were recruited and completed two multi-modal MRI scan sessions. <br>
***Keyboard:*** MRI, resting-state functional MRI (rs-fMRI)<br>
<a href="https://www.biorxiv.org/content/10.1101/177279v2"> ![paper](src/paper.png) Detailed description </a><br>
![licence](src/CcLogo.png) Creative Commons License: Attribution - Non-Commercial

- <a href="https://openneuro.org/datasets/ds001378/versions/00003"> **SCA2 Diffusion Tensor Imaging**</a><br>
Nine SCA2 (Spinocerebellar ataxia type II) patients and 16 age-matched healthy controls, were examined twice on the same 1.5T MRI scanner<br>
<a href="https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0200258"> ![paper](src/paper.png)</a><br>
![licence](src/CcLogo.png) CC-BY 4.0

- <a href="https://shifts.grand-challenge.org"> **Shifts Challenge 2022**</a><br>
White Matter Multiple Sclerosis (MS) lesion segmentation in 3D Magnetic Resonance Imaging (MRI) of the brain <br>
***Keyboard:*** MRI <br>
<a href="https://shifts.grand-challenge.org/evaluation/ms-lesion-segmentation-phase-i/leaderboard"> ![Leaderboard](src/leaderboard.png)</a>

- <a href="http://fcon_1000.projects.nitrc.org/indi/retro/SIMON.html"> **SIMON**</a> (Single Individual volunteer for Multiple Observations across Networks)<br>
A sample of convenience of one healthy male aged between 29 and 46 years old, scanned in 73 sessions at multiple sites and with various scanner models.<br>
***Keyboard:*** MRI<br>
![licence](src/CcLogo.png) CC BY-SA

- <a href="https://stanfordaimi.azurewebsites.net/datasets/3de8cef8-0626-4c5d-ac47-ed0fed22ac99"> **SinoCT**</a><br>
This dataset contains over 9,000 head CT scans, each labeled as normal or abnormal. Each scan contains a reconstructed image and a corresponding sinogram.<br>
***Keyboard:*** Labeled <br>
<a href="https://pubs.rsna.org/doi/full/10.1148/ryai.2021200229"> ![paper](src/paper.png)</a><br>
![licence](src/CcLogo.png) Stanford university dataset research use aggrement

- <a href="https://slcn.grand-challenge.org"> **SLCN**</a> (Surface Learning for Clinical Neuroimaging)  <br>
Part of the <a href="http://www.developingconnectome.org"> dHCP</a> (Developing Human Connectome Project) <br>
***Keyboard:*** MRI <br>
<a href="https://slcn.grand-challenge.org/evaluation/preliminary-phase/leaderboard"> ![Leaderboard](src/leaderboard.png)</a>

- <a href="https://www.studyforrest.org"> **StudyForrest**</a> <br>
A Collection of datasets <br>
<a href="https://www.studyforrest.org/publications.html"> ![paper](src/paper.png) List of publications</a><br>
![licence](src/CcLogo.png) ODC Public Domain Dedication and Licence (PDDL)

- <a href="https://github.com/Jianningli/SciData"> **Synthetic skull bone defects**</a> <br>
For automatic patient-specific craniofacial implant design <br>
***Keyboard:*** CT scan <br>
<a href="https://www.nature.com/articles/s41597-021-00806-0"> ![paper](src/paper.png)</a><br>
![licence](src/CcLogo.png) CC BY 4.0

- <a href="https://surfer.nmr.mgh.harvard.edu/docs/synthstrip"> **SynthStrip**</a> <br>
***Keyboard:*** Multi-modality, Labeled, Segmentation <br>
<a href="https://www.sciencedirect.com/science/article/pii/S1053811922005900"> ![paper](src/paper.png)</a>

- <a href="http://hiresmri.ovgu.de"> **T1-weighted with 250 μm resolution**</a><br>
T1-weighted in vivo human whole brain MRI dataset with an ultrahigh isotropic resolution of 250 μm.<br>
***Keyboard:*** MRI, High field MRI<br>
<a href="https://www.nature.com/articles/sdata201732"> ![paper](src/paper.png)</a>

- <a href="https://tadpole.grand-challenge.org"> **TADPOLE**</a> (The Alzheimer's Disease Prediction Of Longitudinal Evolution)<br>
In collaboration with ADNI <br>
***Keyboard:*** MRI, Labeled <br>
<a href="https://tadpole.grand-challenge.org/Results"> ![Leaderboard](src/leaderboard.png)</a>

- <a href="https://www.cancerimagingarchive.net/collection/tcga-lgg"> **TCGA-LGG**</a> (The Cancer Genome Atlas Low Grade Glioma)<br>
Data from 199 subjects.<br>
***Keyboard:*** Multi-Modality<br>
<a href="https://www.sciencedirect.com/science/article/pii/S0010482519301520"> ![paper](src/paper.png)</a><br>
![licence](src/CcLogo.png) TCIA Restricted

- <a href="http://fcon_1000.projects.nitrc.org/indi/pro/Berlin.html"> **The Neuro Bureau - Berlin: Mind & Brain**</a><br>
It represents a community sample including individuals ranging in age from 18 to 60 years old. Each participant copmleted at least two 7.5-minute resting state scans.<br>
***Keyboard:*** Resting state fMRI (R-fMRI)<br>
![licence](src/CcLogo.png) Creative Commons License: Attribution - Non-Commercial

- <a href="https://topcow23.grand-challenge.org"> **TopCoW**</a> <br>
Topology-Aware Anatomical Segmentation of the Circle of Willis <br>
***Keyboard:*** Magnetic Resonance Angiography (MRA) and Computed Tomography Angiography (CTA) <br>
<a href="https://topcow23.grand-challenge.org/evaluation/validation-cta-multiclass/leaderboard"> ![Leaderboard](src/leaderboard.png)</a> | <a href="https://arxiv.org/abs/2312.17670"> ![paper](src/paper.png)</a><br>
![licence](src/CcLogo.png) CC BY-NC

- <a href="http://fcon_1000.projects.nitrc.org/indi/pro/unam_barrios_hypnosis_index.html"> **UNAM Hynosis**</a> (Universidad Nacional Autónoma de México)<br>
Resting state of the static hypnotic state.<br>
***Keyboard:*** Resting state fMRI scans (rs-fMRI)<br>
<a href="https://pubmed.ncbi.nlm.nih.gov/37786280"> ![paper](src/paper.png)</a><br>
![licence](src/CcLogo.png) Creative Commons License: Attribution - Non-Commercial

- <a href="https://www.cancerimagingarchive.net/collection/upenn-gbm"> **UPenn-GBM**</a> (University of Pennsylvania glioblastoma)<br>
Multi-parametric magnetic resonance imaging scans for de novo Glioblastoma patients.<br>
***Keyboard:*** Cancer, mpMRI, Segmentation, Labeled<br>
<a href="https://www.nature.com/articles/s41597-022-01560-7"> ![paper](src/paper.png)</a><br>
![licence](src/CcLogo.png) CC BY 4.0

- <a href="https://valdo.grand-challenge.org"> **VALDO**</a> (VAscular Lesions DetectiOn)  <br>
***Keyboard:*** MRI, cerebral small vessel disease (CSVD), Labeled  <br>
<a href="https://zenodo.org/records/4600654"> ![paper](src/paper.png)</a>

- <a href="http://fcon_1000.projects.nitrc.org/indi/pro/VirginiaTech.html"> **Virginia Tech**</a><br>
The Virginia Tech Carillon Research Institute sample is a collection of past and present scans obtained from psychiatrically screened individuals ranging in age from 18 to 65 years old. The initial release consists of datasets from 25 healthy (community sample) adults, with age, sex, education level, and ethnicity provided.<br>
***Keyboard:*** T1 weighted MRI, Resting state fMRI scans (R-fMRI)<br>
![licence](src/CcLogo.png) Creative Commons License: Attribution - Non-Commercial

- <a href="https://dataverse.nl/dataset.xhtml?persistentId=doi:10.34894/AECRSD"> **WMH**</a> (White Matter Hyperintensity)<br>
***Keyboard:*** MRI, Segmentation<br>
<a href="https://pubmed.ncbi.nlm.nih.gov/30908194"> ![paper](src/paper.png)</a><br>
![licence](src/CcLogo.png) CC-BY-NC-4.0



### Ears, Nose, Teeth, and Throat

- <a href="https://github.com/abenhamadou/3DTeethSeg22_challenge"> **3DTeethSeg22**</a> <br>
A total of 1800 3D intra-oral scan for 900 patients covering their upper and lower jaws separately.<br>
***Keyboard:***  Labeeld, Segmentation <br>
<a href="https://arxiv.org/abs/2305.18277"> ![paper](src/paper.png)</a> | <a href="https://arxiv.org/abs/2210.06094"> ![paper](src/paper.png)</a><br>
![licence](src/CcLogo.png) CC BY-NC-ND 4.0

- <a href="https://cl-detection2023.grand-challenge.org"> **Cl-Detection 2023**</a><br>
Cephalometric Landmark (CL) Detection in Lateral X-ray Images.<br>
***Keyboard:*** Labeled <br>
<a href="https://cl-detection2023.grand-challenge.org/evaluation/challenge/leaderboard"> ![Leaderboard](src/leaderboard.png)</a>

- <a href="https://github.com/liangjiubujiu/CTooth"> **CTooth**</a> <br>
The gathered data set consists of 5803 CBCT slices in total, out of which 4243 contain tooth annotations.<br>
***Keyboard:*** 3D dental CBCT, Segmentation, Labeled <br>
<a href="https://arxiv.org/abs/2208.01643"> ![paper](src/paper.png)</a> | <a href="https://arxiv.org/abs/2206.08778"> ![paper](src/paper.png)</a><br>
![licence](src/CcLogo.png) CC BY 4.0

- <a href="https://www.kaggle.com/datasets/dasmehdixtr/ddti-thyroid-ultrasound-images"> **DDTI**</a> <br>
Thyroid Ultrasound Images to Classify Benign&Malign Cases.<br>
***Keyboard:*** Labeled <br>

- <a href="https://dentex.grand-challenge.org"> **DENTEX**</a> <br>
Dental Enumeration and Diagnosis on Panoramic X-rays <br>
***Keyboard:*** X-rays, Labeled <br>
<a href="https://dentex.grand-challenge.org/evaluation/challenge/leaderboard"> ![Leaderboard](src/leaderboard.png)</a> | <a href="https://arxiv.org/abs/2305.19112"> ![paper](src/paper.png)</a> | <a href="https://arxiv.org/abs/2303.06500"> ![paper](src/paper.png)</a><br>
![licence](src/CcLogo.png) CC BY-SA 4.0

- <a href="https://zenodo.org/records/1473724"> **OpenEar**</a> <br>
A library consisting of eight three-dimensional models of the human temporal bone. <br>
***Keyboard:***  Cone Beam Computed Tomography (CBCT) <br>
<a href="https://www.nature.com/articles/sdata2018297"> ![paper](src/paper.png)</a><br>
![licence](src/CcLogo.png) CC BY 4.0

- <a href="https://data.mendeley.com/datasets/hxt48yk462"> **Panoramic Dental X-rays**</a> <br>
This dataset consists of anonymized and deidentified panoramic dental X-rays of 116 patients.<br>
***Keyboard:***  Labeeld, Segmentation <br>
<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4652330"> ![paper](src/paper.png)</a> <br>
![licence](src/CcLogo.png) CC BY NC 3.0

- <a href="https://zenodo.org/records/4457648#.ZDAKbexByWA"> **Panoramic radiography database**</a><br>
This database contains 598 panoramic radiographs. <br>
***Keyboard:*** X-ray<br>
<a href="https://www.mdpi.com/1424-8220/21/9/3110"> ![paper](src/paper.png)</a><br>
![licence](src/CcLogo.png) CC BY 4.0

- <a href="https://www.cs.cit.tum.de/camp/publications/segthy-dataset"> **SegThy**</a><br>
Thyroid and Neck Segmentation. <br>
***Keyboard:*** MRI, Ultrasound <br>
![licence](src/CcLogo.png) CC BY

- <a href="https://tianchi.aliyun.com/competition/entrance/532086"> **STS-2D**</a> (Semi-supervised Tooth Segmentation)<br>
The training dataset consists of 4000 panoramic images of teeth. <br>
***Keyboard:*** Panoramic X-ray, Labeled <br>
<a href="https://tianchi.aliyun.com/competition/entrance/532086/rankingList"> ![Leaderboard](src/leaderboard.png)</a><br>
![licence](src/CcLogo.png) Any individual or company is prohibited from using it for commercial purposes.

- <a href="https://tianchi.aliyun.com/competition/entrance/532087"> **STS-3D**</a> (Semi-supervised Tooth Segmentation)<br>
Training dataset consists of 312 CT scans, containing about 62400 slices. <br>
***Keyboard:*** Cone Beam Computed Tomography (CT scan), Labeled <br>
<a href="https://tianchi.aliyun.com/competition/entrance/532087/rankingList"> ![Leaderboard](src/leaderboard.png)</a><br>
![licence](src/CcLogo.png) Any individual or company is prohibited from using it for commercial purposes.

- <a href="https://www.cancerimagingarchive.net/collection/tcga-thca"> **TCGA-THCA**</a> (The Cancer Genome Atlas Thyroid Cancer)<br>
Data from 6 subjects and 2780 images<br>
***Keyboard:*** CT scan <br>
![licence](src/CcLogo.png) CC BY 3.0

- <a href="https://humansintheloop.org/resources/datasets/teeth-segmentation-dataset"> **Teeth Segmentation Dataset**</a> <br>
The dataset consists of 598 images from other dataset with a total of 15,318 polygons, where each tooth is segmented manually with a different class. <br>
***Keyboard:*** Panoramic X-ray, Segmentation, Labeled <br>
![licence](src/CcLogo.png) CC0 1.0

- <a href="https://stanfordaimi.azurewebsites.net/datasets/a72f2b02-7b53-4c5d-963c-d7253220bfd5"> **Thyroid Ultrasound Cine-clip**</a> <br>
Data is collected from 167 patients with biopsy-confirmed thyroid nodules (n=192).<br>
***Keyboard:*** Ultrasound cine-clip images, Labeeld, Segmentation <br>
![licence](src/CcLogo.png) Stanford university dataset research use aggrement

- <a href="https://tn-scui2020.grand-challenge.org"> **TN-SCUI2020**</a> (Thyroid Nodule Segmentation and Classification in Ultrasound Images) <br>
A dataset of thyroid nodule with over 4,500 patient <br>
***Keyboard:***  Ultrasound Image, Thyroid <br>
<a href="https://tn-scui2020.grand-challenge.org/evaluation/challenge/leaderboard"> ![Leaderboard](src/leaderboard.png)</a><br>
![licence](src/CcLogo.png) The publish right of this dataset is limited to the purpose of this challenge only

- <a href="https://ditto.ing.unimore.it/toothfairy"> **ToothFairy**</a> <br>
A dataset of dental scans obtained by 3D CBCT <br>
***Keyboard:***  Cone Beam Computed Tomography (CBCT), Segmentation <br>
<a href="https://toothfairy.grand-challenge.org/evaluation/challenge/leaderboard"> ![Leaderboard](src/leaderboard.png)</a> | <a href="https://link.springer.com/chapter/10.1007/978-3-031-43148-7_44"> ![paper](src/paper.png)</a>

- <a href="https://www.cancerimagingarchive.net/collection/vestibular-schwannoma-seg"> **Vestibular Schwannoma SEG**</a> <br>
242 consecutive patients with vestibular schwannoma (VS) undergoing Gamma Knife stereotactic radiosurgery (GK SRS). <br>
***Keyboard:*** MRI, Segmentation, Labeled<br>
<a href="https://thejns.org/view/journals/j-neurosurg/134/1/article-p171.xml"> ![paper](src/paper.png)</a> | <a href="https://www.nature.com/articles/s41597-021-01064-w"> ![paper](src/paper.png)</a><br>
![licence](src/CcLogo.png) CC BY 4.0



### Eyes

- <a href="https://amd.grand-challenge.org"> **ADAM**</a> <br>
Diagnosis of Age-related Macular degeneration (AMD) and segmentation of lesions in fundus photos from AMD patients <br>
***Keyboard:*** Labeled  <br>
<a href="https://amd.grand-challenge.org/evaluation/challenge/leaderboard/"> ![Leaderboard](src/leaderboard.png)</a> | <a href="https://ieeexplore.ieee.org/document/9768802"> ![paper](src/paper.png)</a>

- <a href="https://age.grand-challenge.org"> **AGE**</a> (Angle closure Glaucoma Evaluation) <br>
A dataset of 4800 annotated AS-OCT images<br>
***Keyboard:*** OCT <br>
<a href="https://age.grand-challenge.org/evaluation/challenge/leaderboard"> ![Leaderboard](src/leaderboard.png)</a> | <a href="https://pubmed.ncbi.nlm.nih.gov/31036585"> ![paper](src/paper.png) Clinical Background</a> | <a href="https://www.sciencedirect.com/science/article/abs/pii/S1361841520301626"> ![paper](src/paper.png)</a>

- <a href="https://airogs.grand-challenge.org"> **AIROGS**</a> (Artificial Intelligence for RObust Glaucoma Screening) <br>
This dataset includes around 113,000 images from about 60,000 patients<br>
***Keyboard:*** Fundus Images <br>
<a href="https://airogs.grand-challenge.org/evaluation/preliminary-test-phase-1/leaderboard"> ![Leaderboard](src/leaderboard.png)</a> | <a href="https://ieeexplore.ieee.org/abstract/document/10253652"> ![paper](src/paper.png) Summary Paper</a><br>
![licence](src/CcLogo.png) CC BY-NC-ND 4.0

- <a href="https://www.kaggle.com/c/aptos2019-blindness-detection/overview"> **APTOS 2019**</a> (Asia Pacific Tele-Ophthalmology Society) <br>
***Keyboard:*** Fundus photography, Diabetic retinopathy<br>
<a href="https://www.kaggle.com/c/aptos2019-blindness-detection/leaderboard"> ![Leaderboard](src/leaderboard.png)</a>

- <a href="https://cataracts.grand-challenge.org"> **CATARACTS**</a> <br>
Surgical tool detection in 50 videos of cataract surgeries<br>
***Keyboard:*** Video, Labeled  <br>
<a href="https://cataracts.grand-challenge.org/Results"> ![Leaderboard](src/leaderboard.png)</a> | <a href="https://www.sciencedirect.com/science/article/abs/pii/S136184151830865X"> ![paper](src/paper.png)</a><br>
![licence](src/CcLogo.png) CC BY 4.0

- <a href="https://blogs.kingston.ac.uk/retinal/chasedb1"> **CHASE-DB1**</a> <br>
***Keyboard:*** Retinal, Labeled <br>

- <a href="https://github.com/nkicsl/DDR-dataset"> **DDR**</a><br>
13,673 fundus images from 9598 patients.<br>
***Keyboard:*** Diabetic retinopathy (DR), Segmentation, Detection<br>
<a href="https://www.sciencedirect.com/science/article/abs/pii/S0020025519305377"> ![paper](src/paper.png)</a>

- <a href="https://drac22.grand-challenge.org"> **DRAC 2022**</a> (Diabetic Retinopathy Analysis Challenge) <br>
A ultra-wide optical coherence tomography angiography (UW-OCTA) dataset addressing three primary clinical tasks: DR lesion segmentation, image quality assessment, and DR grading.<br>
***Keyboard:*** Diabetic retinopathy, Segmentation, Classification<br>
<a href="https://drac22.grand-challenge.org/evaluation/challenge/leaderboard"> ![Leaderboard](src/leaderboard.png)</a> | <a href="https://arxiv.org/abs/2304.02389"> ![paper](src/paper.png)</a> | <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4593632"> ![paper](src/paper.png)</a>

- <a href="https://ipg.fer.hr/ipg/resources/image_database"> **DRiDB**</a> (Diabetic Retinopathy Image Dataset)<br>
***Keyboard:*** Fundus Images, Diabetic retinopathy<br>
<a href="https://ieeexplore.ieee.org/document/6703830"> ![paper](src/paper.png)</a><br>
![licence](src/CcLogo.png) The data included in the dataset can be used, free of charge, for research and educational purposes. Copy, redistribution, and any unauthorized commercial use is prohibited.

- <a href="https://drive.grand-challenge.org"> **DRIVE**</a> (Digital Retinal Images for Vessel Extraction) <br>
***Keyboard:*** Retinal, Segmentation <br>
<a href="https://drive.grand-challenge.org/evaluation/challenge/leaderboard"> ![Leaderboard](src/leaderboard.png)</a> 

- <a href="https://www.adcis.net/en/third-party/e-ophtha"> **E-ophtha**</a><br>
***Keyboard:*** Diabetic retinopathy (DR), Color fundus images, Labeled<br>

- <a href="https://www.kaggle.com/c/diabetic-retinopathy-detection/overview"> **EyePACS Diabetic Retinopathy Detection**</a> <br>
***Keyboard:*** Retina Images, Labeled<br>
<a href="https://www.kaggle.com/c/diabetic-retinopathy-detection/leaderboard"> ![Leaderboard](src/leaderboard.png)</a>

- <a href="https://projects.ics.forth.gr/cvrl/fire"> **FIRE**</a> (Fundus Image Registration Dataset) <br>
***Keyboard:*** Retinal, Labeled

- <a href="https://aistudio.baidu.com/competition/detail/90/0/introduction"> **GAMMA**</a> <br>
The dataset consists of 2D fundus images and 3D optical coherence tomography (OCT) images of 300 patients. The dataset was annotated with glaucoma grade in every sample, and macular fovea coordinates as well as optic disc/cup segmentation mask in the fundus image. <br>
***Keyboard:*** OCT images <br>
<a href="https://aistudio.baidu.com/competition/detail/90/0/leaderboard"> ![Leaderboard](src/leaderboard.png)</a> | <a href="https://arxiv.org/abs/2202.06511"> ![paper](src/paper.png)</a>

- <a href="https://www5.cs.fau.de/research/data/fundus-images"> **HRF**</a> (High-Resolution Fundus)<br>
The database contains 15 images of healthy patients, 15 images of patients with diabetic retinopathy and 15 images of glaucomatous patients. <br>
***Keyboard:*** Fundus Images, Segmentation, Labaled<br>
<a href="https://www.hindawi.com/journals/ijbi/2013/154860"> ![paper](src/paper.png)</a>

- <a href="https://idrid.grand-challenge.org/"> **IDRiD**</a> (Indian Diabetic Retinopathy Image Dataset) <br>
<a href="https://www.sciencedirect.com/science/article/abs/pii/S1361841519301033?via%3Dihub"> ![paper](src/paper.png) First Results and Analysis</a>  | <a href="https://www.mdpi.com/2306-5729/3/3/25"> ![paper](src/paper.png) Data Descriptor</a><br>
![licence](src/CcLogo.png) CC BY 4.0

- <a href="https://justraigs.grand-challenge.org"> **JustRAIGS**</a> (Justified Referral in AI Glaucoma Screening) <br>
The dataset is divided into a training subset with 101,442 gradable fundus images, spanning both referable and no referable glaucomatous cases, and a test subset comprising 9,741 fundus images. <br>
***Keyboard:*** Fundus Images, Labeled  <br>
<a href="https://justraigs.grand-challenge.org/evaluation/development-phase/leaderboard"> ![Leaderboard](src/leaderboard.png)</a> | <a href="https://www.sciencedirect.com/science/article/pii/S2666914523000325"> ![paper](src/paper.png)</a><br>
![licence](src/CcLogo.png) CC BY-NC-SA

- <a href="https://github.com/SaharAlmahfouzNasser/MeDAL-Retina"> **MeDAL Retina Dataset**</a><br>
***Keyboard:*** Retinal, Labeled <br>
<a href="https://arxiv.org/pdf/2307.10698.pdf"> ![paper](src/paper.png) Comprehensive details</a><br>
![licence](src/CcLogo.png) CC BY 4.0

- <a href="https://blogs.kingston.ac.uk/retinal/messidor-ma-groundturth"> **Messidor MA Groundturth**</a><br>
Microaneurysm (MA) detection in 20 retinal images <br>
***Keyboard:*** Retinal, Labeled <br>
<a href="https://ieeexplore.ieee.org/abstract/document/7820998"> ![paper](src/paper.png)</a> | <a href="https://www.sciencedirect.com/science/article/pii/S2352914817300229"> ![paper](src/paper.png)</a>

- <a href="https://ieee-dataport.org/open-access/octa-500"> **OCTA-500**</a> <br>
It contains OCTA imaging under two fields of view (FOVs) from 500 subjects. <br>
***Keyboard:*** Optical coherence tomography angiography (OCTA), Segmentation, Labeled<br>
<a href="https://arxiv.org/abs/2012.07261"> ![paper](src/paper.png)</a><br>
![licence](src/CcLogo.png) CC BY 4.0

- <a href="https://odir2019.grand-challenge.org"> **ODIR 2019**</a> (Ocular Disease Intelligent Recognition) <br>
A database of 5000 patients with age, color fundus photographs from left and right eyes <br>
***Keyboard:*** Labeled<br>
<a href="https://odir2019.grand-challenge.org/evaluation/challenge/leaderboard"> ![Leaderboard](src/leaderboard.png)</a>

- <a href="https://palm.grand-challenge.org"> **PALM**</a> <br>
Investigation and development of algorithms associated with the diagnosis of Pathological Myopia (PM) and segmentation of lesions in fundus photos from PM patients. <br>
***Keyboard:*** Labeled <br>
<a href="https://palm.grand-challenge.org/evaluation/challenge/leaderboard"> ![Leaderboard](src/leaderboard.png)</a>

- <a href="https://ieee-dataport.org/open-access/prime-fp20-ultra-widefield-fundus-photography-vessel-segmentation-dataset"> **PRIME-FP20**</a><br>
It provides 15 high-resolution ultra-widefield (UWF) fundus photography (FP) images<br>
***Keyboard:*** Retinal vessel, Segmentation, Labeled <br>
<a href="https://ieeexplore.ieee.org/document/9208757"> ![paper](src/paper.png)</a><br>
![licence](src/CcLogo.png) CC BY 4.0

- <a href="https://ravir.grand-challenge.org"> **RAVIR**</a> <br>
A Dataset and Methodology for the Semantic Segmentation and Quantitative Analysis of Retinal Arteries and Veins in Infrared Reflectance Imaging <br>
<a href="https://ravir.grand-challenge.org/evaluation/challenge/leaderboard"> ![Leaderboard](src/leaderboard.png)</a> | <a href="https://ieeexplore.ieee.org/abstract/document/9744459"> ![paper](src/paper.png)</a> | <a href="https://escholarship.org/uc/item/4r63v2bd"> ![paper](src/paper.png)</a><br>
![licence](src/CcLogo.png) CC BY-NC-SA 4.0

- <a href="https://refuge.grand-challenge.org"> **REFUGE**</a> (Retinal Fundus Glaucoma) <br>
A data set of 1200 fundus images with ground truth segmentations and clinical glaucoma labels <br>
***Keyboard:*** Segmentation, Classification, Labeled <br>
<a href="https://refuge.grand-challenge.org/evaluation/challenge/leaderboard/"> ![Leaderboard](src/leaderboard.png)</a> | <a href="https://www.sciencedirect.com/science/article/abs/pii/S1361841519301100"> ![paper](src/paper.png)</a> | <a href="https://www.nature.com/articles/s41746-020-00329-9"> ![paper](src/paper.png)</a>

- <a href="https://retouch.grand-challenge.org"> **RETOUCH**</a> (Retinal OCT Fluid Challenge) <br>
Detect and segment various types of fluids on a common dataset of optical coherence tomography (OCT) volumes representing different retinal diseases, acquired with devices from different manufacturers. <br>
***Keyboard:*** OCT images <br>
<a href="https://retouch.grand-challenge.org/Results"> ![Leaderboard](src/leaderboard.png)</a> | <a href="https://ieeexplore.ieee.org/document/8653407"> ![paper](src/paper.png)</a><br>
![licence](src/CcLogo.png) The data shared in this challenge is strictly limited to research purpose only, any commercial use is prohibited.

- <a href="https://riadd.grand-challenge.org"> **RFMiD**</a> (Retinal Fundus Multi-Disease Image Dataset) <br>
It consists of 3200 fundus images<br>
***Keyboard:*** Fundus Images, Classification <br>
<a href="https://riadd.grand-challenge.org/evaluation/challenge/leaderboard"> ![Leaderboard](src/leaderboard.png)</a> | <a href="https://www.mdpi.com/2306-5729/6/2/14"> ![paper](src/paper.png) Data Descriptor</a> 

- <a href="https://deepblue.lib.umich.edu/data/concern/data_sets/3b591905z"> **RIGA**</a> (Retinal fundus images for glaucoma analysis)<br>
It is derived from three sources for a total of 750 images. The optic cup and disc boundaries for each image was marked and annotated. <br>
***Keyboard:*** Fundus images, Labeled<br>
<a href="https://doi.org/10.1117/12.2293584"> ![paper](src/paper.png)</a><br>
![licence](src/CcLogo.png) CC BY-NC 4.0

- <a href="http://webeye.ophth.uiowa.edu/ROC"> **ROC**</a> (Retinopathy Online Challenge) <br>
50 training images and 50 test images <br>
***Keyboard:*** Diabetic retinopathy, Fundus Images, Labeled <br>
<a href="https://ieeexplore.ieee.org/document/5282586"> ![paper](src/paper.png) Overview</a> 

- <a href="https://rocc.grand-challenge.org"> **ROCC**</a> (Retinal OCT Classification Challenge) <br>
A dataset of OCT volumes, acquired with Topcon SD-OCT devices <br>
***Keyboard:*** OCT images, Diabetic retinopathy <br>

- <a href="https://imed.nimte.ac.cn/dataofrose.html"> **ROSE**</a> (Retinal OCT-Angiography Vessel SEgmentation)<br>
It includes two subsets: ROSE-1 and ROSE-2. <br>
<a href="https://arxiv.org/abs/2007.05201"> ![paper](src/paper.png)</a><br>
![licence](src/CcLogo.png) CC BY 4.0

- <a href="https://www.kaggle.com/datasets/paultimothymooney/chiu-2015"> **Segmentation of OCT images**</a><br>
Images for segmentation of optical coherence tomography images with diabetic macular edema (DME). <br>
***Keyboard:*** OCT images<br>
<a href="https://opg.optica.org/boe/fulltext.cfm?uri=boe-6-4-1172"> ![paper](src/paper.png)</a>

- <a href="https://aistudio.baidu.com/competition/detail/1101/0/introduction"> **STAGE**</a> (Structural-Functional Transition in Glaucoma Assessment) <br>
400 OCT data and corresponding Visual Field test reports with Mean Deviation (MD) values, sensitivity maps and pattern deviation probability map labels. <br>
***Keyboard:*** OCT images <br>
<a href="https://aistudio.baidu.com/competition/detail/1101/0/leaderboard"> ![Leaderboard](src/leaderboard.png)</a>

- <a href="https://cecas.clemson.edu/~ahoover/stare"> **STARE**</a> (STructured Analysis of the Retina) <br>
***Keyboard:*** Labeled <br>

- <a href="https://blogs.kingston.ac.uk/retinal/uk-biobank"> **UK Biobank**</a> <br>
2 sets of manual segmentations for 20 UK Biobank retinal images <br>
***Keyboard:*** Retinal, Labeled <br>
<a href="https://ieeexplore.ieee.org/abstract/document/8310108"> ![paper](src/paper.png)</a>

- <a href="https://auckland.figshare.com/articles/journal_contribution/UoA-DR_Database_Info/5985208/5"> **UoA-DR**</a> (University of Auckland Diabetic Retinopathy)<br>
This database consists of 200 retinal images mostly affected with diabetic retinopathy. <br>
***Keyboard:*** Segmentation, Labeled<br>
<a href="https://dl.acm.org/doi/10.1145/3163080.3163087"> ![paper](src/paper.png)</a><br>
![licence](src/CcLogo.png) CC0 1.0



______

## Chest and Abdomen

### Bowel

- <a href="https://polyp.grand-challenge.org/AsuMayo"> **ASU-Mayo**</a><br>
Containing 19,400 frames and a total of 5,200 polyp instances from 10 unique polyps.<br>
***Keyboard:*** Colonoscopy videos, Segmentation, Labeled <br>
<a href="https://ieeexplore.ieee.org/document/7294676"> ![paper](src/paper.png)</a><br>
![licence](src/CcLogo.png) Contact provider

- <a href="https://www.cancerimagingarchive.net/collection/cmb-crc"> **CMB-CRC**</a> (Cancer Moonshot Biobank - Colorectal Cancer)<br>
***Keyboard:*** Multi-modality, Cancer <br>
![licence](src/CcLogo.png) CC BY 4.0 - TCIA Restricted

- <a href="https://zenodo.org/records/53169#.W6HwwP4zbOQ"> **Collection of textures in colorectal cancer histology**</a><br>
***Keyboard:*** Labeled, Mulyi tissue<br>
<a href="https://www.nature.com/articles/srep27988"> ![paper](src/paper.png)</a><br>
![licence](src/CcLogo.png) CC BY 4.0

- <a href="https://conic-challenge.grand-challenge.org"> **CoNIC**</a> (Colon Nuclei Identification and Counting) <br>
***Keyboard:*** whole-slide images (WSI), Nuclear segmentation and classification <br>
<a href="https://conic-challenge.grand-challenge.org/evaluation/challenge/leaderboard"> ![Leaderboard](src/leaderboard.png)</a> | <a href="https://arxiv.org/abs/2111.14485"> ![paper](src/paper.png)</a> 

- <a href="https://www.cancerimagingarchive.net/collection/cptac-coad"> **CPTAC-COAD**</a> (Clinical Proteomic Tumor Analysis Consortium Colon Adenocarcinoma)<br>
***Keyboard:*** Histopathology, Cancer <br>
![licence](src/CcLogo.png) CC BY 3.0

- <a href="http://vi.cvc.uab.es/colon-qa/cvccolondb"> **CVC colon DB**</a><br>
It contains 15 short colonoscopy sequences.<br>
***Keyboard:*** Colonoscopy video, Segmentation, Classification <br>
<a href="https://www.sciencedirect.com/science/article/pii/S0031320312001185"> ![paper](src/paper.png)</a>

- <a href="https://digestpath2019.grand-challenge.org"> **Digestpath2019**</a> (Digestive-System Pathological 2019)<br>
Colonoscopy tissue segmentation and classification and Signet ring cell detection dataset  <br>
***Keyboard:*** Whole slide image (WSI), Cancer, Labeled <br>
<a href="https://www.sciencedirect.com/science/article/abs/pii/S1361841522001323"> ![paper](src/paper.png)</a> 

- <a href="https://ieee-dataport.org/competitions/endoscopy-disease-detection-and-segmentation-edd2020"> **EDD2020**</a> (Endoscopy Disease Detection)<br>
Annotated data consists of 5 different disease classes.<br>
***Keyboard:*** Video, Segmentation, Detection, Labeled <br>
<a href="https://www.sciencedirect.com/science/article/pii/S1361841521000487"> ![paper](src/paper.png)</a><br>
![licence](src/CcLogo.png) CC BY 4.0

- <a href="https://www.gastrointestinalatlas.com/english/english.html"> **El Salvador atlas of Gastrointestinal**</a><br>
It displays 5154 video clips.<br>
***Keyboard:*** Video Endoscopy <br>
<a href="https://www.omicsonline.org/proceedings/el-salvador-atlas-of-gastrointestinal-video-endoscopy-online-academic-site-as-a-learning-resource-102299.html"> ![paper](src/paper.png)</a>

- <a href="https://endocv2021.grand-challenge.org"> **EndoCV2021**</a> (Endoscopy Computer Vision 2021)<br>
Addressing generalisability in polyp detection and segmentation <br>
***Keyboard:*** Colonoscopy, Labeled <br>

- <a href="https://github.com/simula/hyper-kvasir"> **HyperKvasir**</a><br>
The dataset contains 110,079 images and 373 videos where it captures anatomical landmarks and pathological and normal findings.<br>
***Keyboard:*** Gastrointestinal tract, Labeled, Segmentation <br>
<a href="https://www.nature.com/articles/s41597-020-00622-y"> ![paper](src/paper.png)</a><br>
![licence](src/CcLogo.png) The data is released fully open for research and educational purposes.

- <a href="https://github.com/simula/kvasir-capsule"> **Kvasir-Capsule**</a><br>
The dataset consists of 117 videos which can be used to extract a total of 4,741,504 image frames.<br>
***Keyboard:*** Video capsule endoscopy (VCE) , Labeled <br>
<a href="https://www.nature.com/articles/s41597-021-00920-z"> ![paper](src/paper.png)</a><br>
![licence](src/CcLogo.png) The data is released fully open for research and educational purposes.

- <a href="https://datasets.simula.no/kvasir-seg"> **Kvasir-SEG**</a><br>
It contains 1000 images.<br>
***Keyboard:*** Gastrointestinal polyp, Labeled, Segmentation, Colonoscopy <br>
<a href="https://arxiv.org/abs/1911.07069"> ![paper](src/paper.png)</a><br>
![licence](src/CcLogo.png) The use of the dataset is restricted for research and educational purposes.

- <a href="https://paip2020.grand-challenge.org"> **PAIP2020**</a> <br>
Classification of molecular subtypes in colorectal cancer for whole-slide image analyses <br>
<a href="https://paip2020.grand-challenge.org/evaluation/validation/leaderboard/"> ![Leaderboard](src/leaderboard.png)</a><br>
![licence](src/CcLogo.png) CC BY-NC 4.0

- <a href="https://2023paip.grand-challenge.org"> **PAIP2023**</a> <br>
Tumor cellularity prediction in pancreatic cancer (supervised learning) and colon cancer (transfer learning) <br>
<a href="https://2023paip.grand-challenge.org/evaluation/challenge/leaderboard"> ![Leaderboard](src/leaderboard.png)</a><br>
![licence](src/CcLogo.png) CC BY-NC 4.0

- <a href="https://www.synapse.org/Synapse:syn26376615/wiki/613312"> **PolypGen**</a><br>
This dataset is composed of a total of 8037 frames including both single and sequence frames.<br>
***Keyboard:*** Detection, Segmentation, Video <br>
<a href="https://www.nature.com/articles/s41597-023-01981-y"> ![paper](src/paper.png)</a><br>
![licence](src/CcLogo.png) CC BY 4.0

- <a href="https://www.cancerimagingarchive.net/collection/tcga-coad"> **TCGA-COAD**</a> (The Cancer Genome Atlas Colon Adenocarcinoma)<br>
Data from 25 subjects.<br>
***Keyboard:*** CT scan<br>
![licence](src/CcLogo.png) CC BY 3.0

- <a href="https://www.cancerimagingarchive.net/collection/tcga-read"> **TCGA-READ**</a> (The Cancer Genome Atlas Rectum Adenocarcinoma)<br>
Data from 3 subjects and 1,796 images.<br>
***Keyboard:*** MRI, CT scan<br>
![licence](src/CcLogo.png) CC BY 3.0

- <a href="https://wiki.cancerimagingarchive.net/pages/viewpage.action?pageId=3539213"> **The National CT Colonography Trial (ACRIN 6664)**</a> <br>
A collection contains 825 cases of CT colonography imaging with accompanying spreadsheets that provide polyp descriptions and their location within the colon segments. <br>
<a href="https://www.nejm.org/doi/full/10.1056/NEJMoa0800996"> ![paper](src/paper.png)</a> <br>
![licence](src/CcLogo.png) CC BY 3.0



### Breast

- <a href="https://wiki.cancerimagingarchive.net/pages/viewpage.action?pageId=30671268"> **ACRIN-FLT-Breast (ACRIN 6688)**</a> <br>
Examination both pre-therapy and post-therapy <br>
***Keyboard:*** 18F-FLT PET imaging, CT Scan, Cancer <br>
![licence](src/CcLogo.png) CC BY 3.0

- <a href="https://acrobat.grand-challenge.org"> **ACROBAT**</a> (AutomatiC Registration Of Breast cAncer Tissue) <br>
Consisting of 4212 WSIs from 1153 patients <br>
***Keyboard:*** whole-slide images (WSI), Cancer <br>
<a href="https://acrobat.grand-challenge.org/evaluation/model-development/leaderboard"> ![Leaderboard](src/leaderboard.png)</a> | <a href="http://arxiv.org/abs/2211.13621"> ![paper](src/paper.png)</a> 

- <a href="https://www.cancerimagingarchive.net/collection/advanced-mri-breast-lesions"> **Advanced-MRI-Breast-Lesions**</a> <br>
Standard and Delayed Contrast-Enhanced MRI of Malignant and Benign Breast Lesions with Histological and Clinical Supporting Data <br>
***Keyboard:*** Segmentation, Cancer <br>
![licence](src/CcLogo.png) CC BY 4.0

- <a href="https://iciar2018-challenge.grand-challenge.org"> **BACH**</a> (BreAst Cancer Histology) <br>
***Keyboard:*** Biopsy, Cancer <br>
<a href="https://iciar2018-challenge.grand-challenge.org/evaluation/part-a/leaderboard/"> ![Leaderboard](src/leaderboard.png)</a> | <a href="https://www.sciencedirect.com/science/article/abs/pii/S1361841518307941"> ![paper](src/paper.png)</a><br>
![licence](src/CcLogo.png) CC BY-NC-ND

- <a href="https://bci.grand-challenge.org"> **BCI**</a> (Breast Cancer Immunohistochemical) <br>
***Keyboard:*** hematoxylin and eosin (HE) stained images, Image Generation, Labeled <br>
<a href="https://bci.grand-challenge.org/evaluation/challenge/leaderboard"> ![Leaderboard](src/leaderboard.png)</a> | <a href="https://arxiv.org/abs/2204.11425"> ![paper](src/paper.png)</a>

- <a href="https://bcnb.grand-challenge.org"> **BCNB**</a> (Breast Cancer Core-Needle Biopsy) <br>
A dataset of Early Breast Cancer Core-Needle Biopsy WSI, which includes core-needle biopsy whole slide images of early breast cancer patients and the corresponding clinical data.  <br>
***Keyboard:***  Whole-Slide Images (WSIs), Labeled <br>
<a href="https://pubmed.ncbi.nlm.nih.gov/34722313"> ![paper](src/paper.png)</a>

- <a href="https://github.com/PathologyDataScience/BCSS"> **BCSS**</a> (Breast Cancer Semantic Segmentation) <br>
The dataset contains over 20,000 segmentation annotations of tissue region from breast cancer images from TCGA. <br>
***Keyboard:***  Cancer, Labeled <br>
<a href="https://academic.oup.com/bioinformatics/article/35/18/3461/5307750"> ![paper](src/paper.png)</a><br>
![licence](src/CcLogo.png) CC0 1.0 Universal (CC0 1.0)

- <a href="https://web.inf.ufpr.br/vri/databases/breast-cancer-histopathological-database-breakhis"> **BreakHis**</a> (Breast Cancer Histopathological) <br>
A dataset of 7909 breast cancer histopathology images acquired on 82 patients <br>
***Keyboard:*** Cancer, Labeled <br>
<a href="https://ieeexplore.ieee.org/document/7312934"> ![paper](src/paper.png)</a><br>
![licence](src/CcLogo.png) The Database may be used for non-commercial research

- <a href="https://www.kaggle.com/datasets/sabermalek/bcfpp"> **Breast Cancer CT**</a> <br>
***Keyboard:*** CT Scan, Labeled, Cancer <br>
![licence](src/CcLogo.png) CC BY-NC-SA 4.0

- <a href="https://www.cancerimagingarchive.net/collection/breast-cancer-screening-dbt"> **Breast-Cancer-Screening-DBT**</a> (Digital Breast Tomosynthesis) <br>
It contains 22,032 reconstructed DBT volumes belonging to 5,610 studies from 5,060 patients. <br>
***Keyboard:*** Mammography, Cancer <br>
<a href="https://arxiv.org/abs/2011.07995"> ![paper](src/paper.png)</a><br>
![licence](src/CcLogo.png) CC BY-NC 4.0

- <a href="https://www.cancerimagingarchive.net/collection/breast-diagnosis"> **BREAST-DIAGNOSIS**</a> <br>
It contains cases that are high-risk normals, DCIS, fibroids and lobular carcinomas.<br>
***Keyboard:*** Cancer <br>
![licence](src/CcLogo.png) CC BY 3.0

- <a href="https://www.cancerimagingarchive.net/collection/breast-mri-nact-pilot"> **Breast-MRI-NACT-Pilot**</a> <br>
Single site breast DCE-MRI data and segmentations from patients undergoing neoadjuvant chemotherapy<br>
***Keyboard:*** Labeled, Cancer <br>
![licence](src/CcLogo.png) CC BY 3.0

- <a href="https://breastpathq.grand-challenge.org/"> **BreastPathQ**</a> <br>
Development of quantitative biomarkers for the determination of cancer cellularity from whole slide images (WSI) of breast cancer hematoxylin and eosin (H&E) stained pathological slides <br>
***Keyboard:*** Cancer, Haematoxylin and eosin (H&E) stained slides <br>
<a href="https://breastpathq.grand-challenge.org/evaluation/challenge/leaderboard"> ![Leaderboard](src/leaderboard.png)</a>

- <a href="http://cvprip.cs.usu.edu/busbench"> **BUSIS**</a> (Breast Ultrasound Image Segmentation)<br>
***Keyboard:*** Ultrasound image, Labeled, Cancer <br>
<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9025635"> ![paper](src/paper.png)</a>

- <a href="https://wiki.cancerimagingarchive.net/pages/viewpage.action?pageId=22516629"> **CBIS-DDSM**</a> (Curated Breast Imaging Subset of Digital Database for Screening Mammography) <br>
The DDSM is a database of 2,620 scanned film mammography studies. It contains normal, benign, and malignant cases with verified pathology information. <br>
***Keyboard:***  Cancer, Labeled <br>
<a href="https://www.nature.com/articles/sdata2017177"> ![paper](src/paper.png)</a><br>
![licence](src/CcLogo.png) CC BY 3.0

- <a href="https://visual.ic.uff.br/dmi"> **DMR-IR**</a><br>
***Keyboard:*** Cancer, Thermography image<br>

- <a href="https://wiki.cancerimagingarchive.net/pages/viewpage.action?pageId=70226903"> **Duke Breast Cancer MRI**</a> <br>
Dynamic contrast-enhanced magnetic resonance images of breast cancer patients with tumor locations. <br>
***Keyboard:*** Cancer, Labeled <br>
<a href="https://www.nature.com/articles/s41416-018-0185-8"> ![paper](src/paper.png)</a><br>
![licence](src/CcLogo.png) CC BY-NC 4.0

- <a href="https://ecdp2020.grand-challenge.org"> **HEROHE**</a> (HER2 on hematoxylin and eosin) <br>
The dataset consists of annotated, whole-slide images dataset (509), specifically collected for predicting human epidermal growth factor receptor 2 (HER2) status <br>
***Keyboard:*** whole-slide images (WSI), Cancer <br>
<a href="https://www.mdpi.com/2313-433X/8/8/213"> ![paper](src/paper.png)</a><br>
![licence](src/CcLogo.png) CC BY-NC-ND 3.0

- <a href="https://www.kaggle.com/datasets/martholi/inbreast"> **INbreast**</a> <br>
The database has a total of 115 cases (410 images) from which 90 cases are from women with both breasts affected and 25 cases are from mastectomy patients. <br>
***Keyboard:*** Mammography, Cancer <br>
<a href="https://pubmed.ncbi.nlm.nih.gov/22078258"> ![paper](src/paper.png)</a>

- <a href="https://www.cancerimagingarchive.net/collection/ispy1"> **ISPY1 - Trial**</a> (Investigation of Serial Studies to Predict Your Therapeutic Response with Imaging and moLecular Analysis) <br>
***Keyboard:***  MRI, Cancer, Segmentation <br>
<a href="https://pubs.rsna.org/doi/10.1148/radiol.2015150013"> ![paper](src/paper.png)</a><br>
![licence](src/CcLogo.png) CC BY 3.0

- <a href="https://www.cancerimagingarchive.net/collection/ispy2"> **ISPY2 - Trial**</a> (Investigation of Serial Studies to Predict Your Therapeutic Response with Imaging and moLecular Analysis) <br>
***Keyboard:***  MRI, Cancer, Segmentation <br>
<a href="https://www.nature.com/articles/s41523-020-00203-7"> ![paper](src/paper.png)</a><br>
![licence](src/CcLogo.png) CC BY 4.0

- <a href="https://www.kaggle.com/datasets/kmader/mias-mammography"> **MIAS**</a> <br>
***Keyboard:*** Mammography, Cancer, Labeled <br>
![licence](src/CcLogo.png) For research purposes
ONLY

- <a href="https://imig.science/midog2021"> **MIDOG 2021**</a> (Mitosis Domain Generalization 2021) <br>
Detect mitotic figures (cells undergoing cell division) from histopathology images (object detection) <br>
***Keyboard:*** Whole-Slide Images (WSI), Cancer, Labeled <br>
<a href="https://midog2021.grand-challenge.org/evaluation/challenge/leaderboard"> ![Leaderboard](src/leaderboard.png)</a> | <a href="https://www.sciencedirect.com/science/article/abs/pii/S1361841522003279"> ![paper](src/paper.png)</a> <br>
![licence](src/CcLogo.png) CC BY-NC-ND

- <a href="https://imig.science/midog"> **MIDOG 2022**</a> (Mitosis Domain Generalization 2022) <br>
Detect mitotic figures (cells undergoing cell division) from histopathology images (object detection) <br>
***Keyboard:*** Whole-Slide Images (WSI), Cancer, Labeled <br>
<a href="https://midog2022.grand-challenge.org/evaluation/challenge/leaderboard"> ![Leaderboard](src/leaderboard.png)</a> | <a href="https://arxiv.org/abs/2309.15589"> ![paper](src/paper.png)</a><br>
![licence](src/CcLogo.png) CC BY-NC-ND

- <a href="https://www.kaggle.com/datasets/cheddad/miniddsm2"> **Mini-DDSM**</a> (Digital Database for Screening Mammography) <br>
This is the light-weight version of the popular DDSM. <br>
***Keyboard:*** Mammography, Cancer <br>
<a href="https://dl.acm.org/doi/abs/10.1145/3441369.3441370"> ![paper](src/paper.png)</a><br>
![licence](src/CcLogo.png) CC BY-ND 4.0

- <a href="https://mitos-atypia-14.grand-challenge.org"> **MITOS-ATYPIA-14**</a> <br>
It is made up of two parts: Detection of mitosis on the one hand, and evaluation of nuclear atypia score on the other hand. <br>
***Keyboard:*** Cancer, Haematoxylin and eosin (H&E) stained slides <br>
<a href="https://mitos-atypia-14.grand-challenge.org/Results2"> ![Leaderboard](src/leaderboard.png)</a>

- <a href="https://sites.google.com/view/nucls"> **NuCLS**</a> <br>
The datasets contain over 220000 labeled nuclei from breast cancer images from TCGA <br>
***Keyboard:***  Cancer, Labeled <br>
<a href="https://arxiv.org/abs/2102.09099"> ![paper](src/paper.png)</a><br>
![licence](src/CcLogo.png) CC0 1.0 license

- <a href="https://www.cancerimagingarchive.net/collection/post-nat-brca"> **Post-NAT-BRCA**</a><br>
Assessment of Residual Breast Cancer Cellularity after Neoadjuvant Chemotherapy using Digital Pathology<br>
***Keyboard:*** Histopathology<br>
<a href="https://onlinelibrary.wiley.com/doi/10.1002/cyto.a.23244"> ![paper](src/paper.png)</a><br>
![licence](src/CcLogo.png) CC BY 3.0

- <a href="https://wiki.cancerimagingarchive.net/display/Public/QIN-Breast"> **QIN-Breast**</a> <br>
This collection contains longitudinal PET/CT and quantitative MR images collected for the purpose of studying treatment assessment in breast cancer in the neoadjuvant setting. <br>
***Keyboard:*** PET/CT, MRI, Cancer <br>
![licence](src/CcLogo.png) CC BY 3.0 

- <a href="https://wiki.cancerimagingarchive.net/display/Public/QIN-BREAST-02"> **QIN-Breast-02**</a> <br>
This data is from a multi-site, multi-parametric quantitative MRI study of adult (18+ years old) females diagnosed with invasive breast cancer. <br>
***Keyboard:*** Cancer <br>
![licence](src/CcLogo.png) TCIA Limited CC0 1.0 license - CC BY 3.0

- <a href="https://wiki.cancerimagingarchive.net/display/Public/RIDER+Breast+MRI"> **RIDER Breast MRI**</a> (Reference Image Database to Evaluate Therapy Response) <br>
RIDER is a targeted data collection used to generate an initial consensus on how to harmonize data collection and analysis for quantitative imaging methods applied to measure the response to drug or radiation therapy. <br>
***Keyboard:***  Cancer <br>
![licence](src/CcLogo.png) CC BY 3.0 

- <a href="https://www.rsna.org/rsnai/ai-image-challenge/screening-mammography-breast-cancer-detection-ai-challenge"> **RSNA Screening Mammography Breast Cancer Detection**</a> (Radiological Society of North America 2023) <br>
***Keyboard:*** Radiographic breast images, Labeled<br>
<a href="https://www.kaggle.com/competitions/rsna-breast-cancer-detection/leaderboard"> ![Leaderboard](src/leaderboard.png)</a>

- <a href="https://www.cancerimagingarchive.net/collection/sln-breast"> **SLN-Breast**</a><br>
Breast Metastases to Axillary Lymph Nodes<br>
***Keyboard:*** Histopathology, Cancer<br>
<a href="https://www.nature.com/articles/s41591-019-0508-1"> ![paper](src/paper.png)</a><br>
![licence](src/CcLogo.png) CC BY 3.0

- <a href="https://www.cancerimagingarchive.net/collection/tcga-brca"> **TCGA-BRCA**</a> (The Cancer Genome Atlas Breast Invasive Carcinoma)<br>
Data from 139 subjects.<br>
***Keyboard:*** MRI, Cancer<br>
![licence](src/CcLogo.png) CC BY 3.0 

- <a href="https://tdsc-abus2023.grand-challenge.org"> **TDSC-ABUS2023**</a> (Tumor Detection, Segmentation and Classification Challenge on Automated 3D Breast Ultrasound 2023) <br>
***Keyboard:*** Ultrasound, Cancer, Labeled <br>
<a href="https://tdsc-abus2023.grand-challenge.org/evaluation/challenge/leaderboard"> ![Leaderboard](src/leaderboard.png)</a>

- <a href="https://tiger.grand-challenge.org"> **TIGER**</a> (Tumor InfiltratinG lymphocytes in breast cancER) <br>
***Keyboard:***  H&E Whole-Slide Images (WSI), Cancer, Detecion, Segmentation <br>
<a href="https://tiger.grand-challenge.org/evaluation/segmentation-and-detection-public-test/leaderboard"> ![Leaderboard](src/leaderboard.png)</a><br>
![licence](src/CcLogo.png) CC BY-NC 4.0

- <a href="https://tupac.grand-challenge.org"> **TUPAC**</a> (Tumor Proliferation Assessment Challenge) <br>
The dataset consisted of 500 training and 321 testing breast cancer histopathology WSIs. <br>
***Keyboard:***  Whole-Slide Images, Cancer <br>
<a href="https://pubmed.ncbi.nlm.nih.gov/30861443"> ![paper](src/paper.png)</a>



### Heart and Blood Vessels

- <a href="https://www.creatis.insa-lyon.fr/Challenge/acdc"> **ACDC**</a> (Automated Cardiac Diagnosis Challenge) <br>
The dataset contains data from 150 multi-equipments CMRI recordings with reference measurements and classification from two medical experts. <br>
***Keyboard:***  Cardiac MRI (CMR), Segmentation <br>
<a href="https://www.creatis.insa-lyon.fr/Challenge/acdc/results.html"> ![Leaderboard](src/leaderboard.png)</a> | <a href="https://pubmed.ncbi.nlm.nih.gov/29994302"> ![paper](src/paper.png)</a>

- <a href="https://www.cardiacatlas.org/amrg-cardiac-atlas"> **AMRG Cardiac Atlas**</a><br>
There are 4 protocols used to create the cardiac atlas: T1-Weighted Images, True FISP Cines, MR tagging and contrast MRI. <br>

- <a href="https://data.mendeley.com/datasets/ydrm75xywg/1"> **Angiographic dataset for stenosis detection**</a><br>
All patients had angiographically and/or functionally confirmed one-vessel coronary artery disease.<br>
<a href="https://www.nature.com/articles/s41598-021-87174-2"> ![paper](src/paper.png)</a>
<br>
![licence](src/CcLogo.png) CC BY 4.0

- <a href="https://arcade.grand-challenge.org"> **ARCADE**</a> <br>
Automatic Region-based Coronary Artery Disease Diagnostics Using X-Ray Angiography Images <br>
***Keyboard:***  X-ray coronary angiography, Labeled <br>
<a href="https://arcade.grand-challenge.org/evaluation/phase_1_segmentation_detection/leaderboard"> ![Leaderboard](src/leaderboard.png)</a> | <a href="https://www.nature.com/articles/s41597-023-02871-z"> ![paper](src/paper.png)</a>

- <a href="https://asoca.grand-challenge.org"> **ASOCA**</a> (Automated Segmentation of Coronary Arteries) <br>
A set of Cardiac Computed Tomography Angiography (CCTA) with contrast agent showing the coronary arteries <br>
***Keyboard:***  CCTA, Labeled <br>
<a href="https://asoca.grand-challenge.org/evaluation/challenge/leaderboard"> ![Leaderboard](src/leaderboard.png)</a>

- <a href="https://www.cardiacatlas.org/atriaseg2018-challenge"> **Atria Segmentaion 2018**</a><br>
A total of 154 3D MRIs from patients with Atrial fibrillation (AF) are used.<br>
***Keyboard:*** Labeled <br>
<a href="https://www.sciencedirect.com/science/article/abs/pii/S1361841520301961"> ![paper](src/paper.png)</a>

- <a href="https://camus.creatis.insa-lyon.fr/challenge"> **CAMUS**</a> (Cardiac Acquisitions for Multi-structure Ultrasound Segmentation) <br>
The dataset consists of clinical exams from 500 patients<br>
***Keyboard:***  2D echocardiographic images <br>
<a href="https://www.creatis.insa-lyon.fr/Challenge/camus/results.html"> ![Leaderboard](src/leaderboard.png)</a> | <a href="https://pubmed.ncbi.nlm.nih.gov/30802851"> ![paper](src/paper.png)</a>

- <a href="https://www.kaggle.com/datasets/xiaoweixumedicalai/cardiacudc-dataset"> **CardiacUDA**</a> (Unsupervised Domain Adaption) <br>
***Keyboard:*** Echocardiogram Videos <br>
<a href="https://arxiv.org/abs/2309.11145"> ![paper](src/paper.png)</a><br>
![licence](src/CcLogo.png) Apache 2.0

- <a href="https://vessel-wall-segmentation.grand-challenge.org"> **Carotid Artery Vessel Wall**</a> <br>
***Keyboard:*** Segmentation, Labeled <br>

- <a href="https://www5.cs.fau.de/research/software/cavarev"> **CAVAREV**</a> (CArdiac VAsculature Reconstruction EValuation)<br>
The goal is to enable an easy and objective comparison of different dynamic reconstruction algorithms.<br>

- <a href="https://figshare.com/articles/dataset/CDEMRIS_fibrosis_scar_challenge_data_2012/4214532"> **cDEMRIS**</a> (Cardiac Delayed Enhancement Segmentation Challenge)<br>
The dataset includes Late Gadolinium enhancement (LGE) cardiovascular magnetic resonance imaging used to visualise regions of fibrosis and scarring in the left atrium (LA) myocardium.<br>
***Keyboard:*** Cardiac MRI (CMR), Segmentation <br>
<a href="https://jcmr-online.biomedcentral.com/articles/10.1186/1532-429X-15-105"> ![paper](src/paper.png)</a><br>
![licence](src/CcLogo.png) CC BY 4.0

- <a href="https://www.creatis.insa-lyon.fr/Challenge/CETUS/"> **CETUS**</a> (Challenge on Endocardial Three-dimensional Ultrasound Segmentation) <br>
The dataset is composed of 45 sequences of 3D ultrasound volumes of one cardiac cycle from 45 patients to compare left ventricle segmentation methods for both End Diastolic and End Systolic phase instances.<br>
***Keyboard:***  Ultrasound imaging, Segmentation <br>
<a href="https://www.creatis.insa-lyon.fr/Challenge/CETUS/results.html"> ![Leaderboard](src/leaderboard.png)</a>

- <a href="https://capchd.ucsd.edu"> **CHD**</a> (Congenital Heart Disease)<br>
Physiologic clinical data, and computational models from adults and children with various congenital heart defects.<br>
***Keyboard:*** MRI <br>
<a href="https://www.nature.com/articles/s41598-023-28358-w"> ![paper](src/paper.png)</a> | <a href="https://pubmed.ncbi.nlm.nih.gov/36849960"> ![paper](src/paper.png)</a>

- <a href="https://stanfordaimi.azurewebsites.net/datasets/e8ca74dc-8dd4-4340-815a-60b41f6cb2aa"> **COCA**</a><br>
Coronary Calcium and chest CT’s.<br>
***Keyboard:*** Segmentation<br>
![licence](src/CcLogo.png) Stanford university dataset research use aggrement

- <a href="https://vessel-wall-segmentation-2022.grand-challenge.org"> **COSMOS**</a> (CarOtid vessel wall SegMentation and atherosclerOsis diagnosiS) <br>
***Keyboard:***  3D-VISTA (volume isotropic turbo spin echo acquisition) images <br>
<a href="https://vessel-wall-segmentation-2022.grand-challenge.org/evaluation/validation/leaderboard"> ![Leaderboard](src/leaderboard.png)</a>

- <a href="http://cmr.miccai.cloud"> **CMRxMotion**</a><br>
Extreme Cardiac MRI Analysis under Respiratory Motion <br>
<a href="http://cmr.miccai.cloud/validation-leaderboard"> ![Leaderboard](src/leaderboard.png)</a>

- <a href="https://cmrxrecon.github.io/Home.html"> **CMRxRecon**</a><br>
It aims to establish a platform for fast CMR image reconstruction<br>
***Keyboard:*** 3T MRI, Segmentation, Labeled <br>

- <a href="https://cmrxrecon.github.io/2024/Home.html"> **CMRxUniversalRecon**</a><br>
Also known as CMRxRecon2024<br>
***Keyboard:*** Cardiac MRI Reconstruction<br>

- <a href="https://stanfordaimi.azurewebsites.net/datasets/12c02840-2e13-42a2-b4ef-f682472d4694"> **CT Pulmonary Angiography**</a><br>
A collection of CT pulmonary angiography (CTPA) for patients susceptible to Pulmonary Embolism (PE). In addition to slice-level PE labels, labels for PE location, RV/LV ratio, and PE type are provided. <br>
***Keyboard:*** Labeled<br>
![licence](src/CcLogo.png) Stanford university dataset research use aggrement

- <a href="https://www.cardiacatlas.org/determine"> **DETERMINE**</a> (Defibrillators to Reduce Risk by Magnetic Resonance Imaging Evaluation)<br>
It consists of MR images and some 3D left ventricular models derived semi-automatically.<br>

- <a href="https://echonet.github.io/dynamic/index.html"> **EchoNet-Dynamic**</a><br>
A Cardiac Motion Video Data Resource for Medical Machine Learning includes 10,030 labeled echocardiogram videos <br>
***Keyboard:*** Echocardiography, Labeled <br>
<a href="https://www.semanticscholar.org/paper/EchoNet-Dynamic%3A-a-Large-New-Cardiac-Motion-Video-Ouyang-He/44bfcf2409c0826584c7c409b6a2fcf8c9910c88"> ![paper](src/paper.png)</a>

- <a href="https://echonet.github.io/lvh"> **EchoNet-LVH**</a><br>
A Parasternal Long Axis Echocardiography Video Data Resource <br>
***Keyboard:*** Echocardiography, Labeled <br>
<a href="https://jamanetwork.com/journals/jamacardiology/fullarticle/2789370"> ![paper](src/paper.png)</a>

- <a href="https://echonet.github.io/pediatric"> **EchoNet-Pediatric**</a><br>
A Pediatric data resource includes 7,643 labeled echocardiogram videos <br>
***Keyboard:*** Echocardiography, Labeled <br>
<a href="https://pubmed.ncbi.nlm.nih.gov/36754100"> ![paper](src/paper.png)</a>

- <a href="https://emidec.com"> **EMIDEC**</a> (automatic Evaluation of Myocardial Infarction from Delayed-Enhancement Cardiac MRI)<br>
The database consists of 150 exams divided into 50 cases with normal MRI after injection of a contrast agent and 100 cases with myocardial infarction.<br>
***Keyboard:*** Segmentation, Classification<br>
<a href="https://emidec.com/leaderboard"> ![Leaderboard](src/leaderboard.png)</a> | <a href="https://www.sciencedirect.com/science/article/abs/pii/S1361841522000792"> ![paper](src/paper.png)</a> | <a href="https://emidec.com/accepted-papers"> ![paper](src/paper.png)</a><br>
![licence](src/CcLogo.png) CC BY-NC-SA 4.0

- <a href="https://www.kaggle.com/datasets/aysendegerli/hmcqu-dataset"> **HMC-QU**</a><br>
The dataset includes a collection of apical 4-chamber (A4C) and apical 2-chamber (A2C) view 2D echocardiography.<br>
***Keyboard:*** Myocardial Infarction, Detection, Segmentation, Labeled <br>
<a href="https://www.sciencedirect.com/science/article/pii/S1746809423008819"> ![paper](src/paper.png)</a><br>
![licence](src/CcLogo.png) Attribution-NonCommercial-ShareAlike 3.0 IGO (CC BY-NC-SA 3.0 IGO)

- <a href="https://www.kaggle.com/datasets/xiaoweixumedicalai/imagealcapa"> **ImageALCAPA**</a> (Anomalous left coronary artery from pulmonary artery) <br>
30 3D CTA images. <br>
***Keyboard:*** CTA (Computed tomography angiography), Labeled, Segmentation  <br>
<a href="https://www.sciencedirect.com/science/article/abs/pii/S0895611123001052"> ![paper](src/paper.png)</a><br>
![licence](src/CcLogo.png) Apache 2.0

- <a href="https://www.kaggle.com/datasets/xiaoweixumedicalai/imagecas"> **ImageCAS**</a> (Coronary Artery Segmentation) <br>
A Dataset and for Coronary Artery Segmentation based on CT. <br>
***Keyboard:*** CTA (Computed tomography angiography), Segmentation  <br>
<a href="https://ieeexplore.ieee.org/document/9994951"> ![paper](src/paper.png)</a><br>
![licence](src/CcLogo.png) Apache 2.0

- <a href="https://www.kaggle.com/datasets/xiaoweixumedicalai/imagechd"> **ImageCHD**</a> (Congenital Heart Disease) <br>
A 3D CT Image Dataset for classification of Congenital Heart Disease. <br>
***Keyboard:*** CT scan, Labeled <br>
<a href="https://arxiv.org/abs/2101.10799"> ![paper](src/paper.png)</a> <br>
![licence](src/CcLogo.png) Apache 2.0

- <a href="https://www.kaggle.com/datasets/xiaoweixumedicalai/imagetbad"> **ImageTBAD**</a> <br>
A 3D CT Image Dataset for Automatic Segmentation of of Type-B Aortic Dissection. <br>
***Keyboard:*** CTA (Computed tomography angiography), Labeled, Aorta <br>
<a href="https://www.frontiersin.org/articles/10.3389/fphys.2021.732711/full"> ![paper](src/paper.png)</a> <br>
![licence](src/CcLogo.png) Apache 2.0

- <a href="https://github.com/catactg/lasc"> **LASC'13**</a> (Left Atrial Segmentation Challenge 2013)<br>
The benchmark consists of 30 CT and 30 MRI datasets. <br>
***Keyboard:*** Labeled <br>
<a href="https://ieeexplore.ieee.org/document/7029623"> ![paper](src/paper.png)</a><br>
![licence](src/CcLogo.png) CC BY 4.0

- <a href="https://zmiclab.github.io/projects/lascarqs22"> **LAScarQS**</a> (Left Atrial and Scar Quantification & Segmentation)<br>
It provides 194 LGE MRIs from patients suffering atrial fibrillation (AF). <br>
***Keyboard:*** Labeled <br>
<a href="https://zmiclab.github.io/projects/lascarqs22/result.html"> ![paper](src/paper.png)</a><br>
![licence](src/CcLogo.png) CC BY NC ND

- <a href="https://figshare.com/articles/figure/Left_ventricular_LV_scar_dataset/4214622"> **LivScar**</a><br>
The image database consists of 30 Late Gadolinium enhancement cardiovascular magnetic resonance images of both humans and pigs that were acquired from two separate imaging centres.<br>
***Keyboard:*** Cardiac MRI (CMR), Segmentation <br>
<a href="https://www.sciencedirect.com/science/article/pii/S1361841516000050"> ![paper](src/paper.png)</a><br>
![licence](src/CcLogo.png) CC BY 4.0

- <a href="https://www.cardiacatlas.org/lv-landmark-detection-challenge"> **LV Landmark Detection Challenge**</a><br>
This challenge uses the same data set as in the LV Segmentation Challenge with manually annotated landmark positions were placed in the training data set as annotation data.<br>
***Keyboard:*** MRI, Labeled<br>

- <a href="https://www.cardiacatlas.org/lv-segmentation-challenge"> **LV Segmentation Challenge**</a><br>
This challenge was aimed to establish a set of ground truth or consensus segmentation derived from participants.<br>
***Keyboard:*** MRI<br>

- <a href="https://www.cardiacatlas.org/lv-statistical-shape-challenge"> **LV Statistical Shape Challenge**</a><br>
The training dataset will comprise one hundred (100) cases with myocardial infarction and an additional one hundred (100) asymptomatic cases from the DETERMINE and MESA datasets respectively.<br>
***Keyboard:*** MRI<br>

- <a href="https://lvquan19.github.io"> **LVQuan19**</a> (Left Ventricle Full Quantification)<br>
A dataset with processed SAX MR sequences of 86 subjects.<br>
<a href="https://link.springer.com/book/10.1007/978-3-030-12029-0"> ![paper](src/paper.png)</a>

- <a href="https://www.ub.edu/mnms"> **M&Ms**</a> <br>
Multi-Centre, Multi-Vendor and Multi-Disease Cardiac Segmentation <br>
***Keyboard:***  Cardiac MRI (CMR)<br>
<a href="https://ieeexplore.ieee.org/document/9458279"> ![paper](src/paper.png)</a>

- <a href="https://www.ub.edu/mnms-2"> **M&Ms-2**</a> <br>
Multi-Disease, Multi-View & Multi-Center
Right Ventricular Segmentation in Cardiac MRI <br>
***Keyboard:***  Cardiac MRI (CMR)<br>
<a href="https://competitions.codalab.org/competitions/31559#results"> ![Leaderboard](src/leaderboard.png)</a> | <a href="https://ieeexplore.ieee.org/document/10103611"> ![paper](src/paper.png)</a>

- <a href="https://codalab.lisn.upsaclay.fr/competitions/18516"> **MBAS24**</a> (Multi-class Bi-Atrial  2024)<br>
Concluding 70 3D LGE-MRI scans for training, 30 for validation, and an additional 100 designated for the final test phase.<br>
![licence](src/CcLogo.png) CC BY NC ND

- <a href="https://www.cardiacatlas.org/mesa"> **MESA**</a> (Multi-Ethnic Study of Atherosclerosis)<br>
It aims to investigate the manifestation of subclinical to clinical cardiovascular disease before signs and symptoms develop.<br>
***Keyboard:*** MRI<br>

- <a href="https://www.cardiacatlas.org/mitea"> **MITEA**</a> (MR-Informed Three-dimensional Echocardiography Analysis)<br>
The dataset consists of annotated 3D echocardiography (3DE) data using labels derived from paired CMR scans acquired in a mixed cohort of 134 human subjects (82 healthy controls and 52 patients with acquired cardiac disease).<br>
<a href="https://www.frontiersin.org/journals/cardiovascular-medicine/articles/10.3389/fcvm.2022.1016703/full"> ![paper](src/paper.png)</a>

- <a href="https://zmiclab.github.io/zxh/0/mmwhs"> **MM-WHS**</a> (Multi-Modality Whole Heart Segmentation)<br>
It provides multi-modality cardiac images acquired in real clinical environment. <br>
***Keyboard:*** Anonymized clinical MRI and CT scan, Labeled <br>
<a href="https://ieeexplore.ieee.org/document/8458220"> ![paper](src/paper.png)</a> | <a href="https://ieeexplore.ieee.org/document/9921323"> ![paper](src/paper.png)</a>

- <a href="https://www.cardiacatlas.org/motion-correction-challenge"> **Motion Correction Challenge**</a><br>
The dataset consists of 10 cases. <br>
***Keyboard:*** MRI, Labeled <br>
<a href="https://ieeexplore.ieee.org/document/7542127"> ![paper](src/paper.png)</a>

- <a href="https://zmiclab.github.io/zxh/0/mscmrseg19"> **MS-CMRSeg**</a> (Multi-sequence Cardiac MR Segmentation) <br>
Data from 45 patients. <br>
***Keyboard:*** Cardiac MRI (CMR), Segmentation, Labeled <br>
<a href="https://ieeexplore.ieee.org/document/8458220"> ![paper](src/paper.png)</a>

- <a href="https://zmiclab.github.io/zxh/0/myops20"> **MyoPS 2020**</a><br>
Myocardial pathology segmentation combining multi-sequence cardiac magnetic resonance (CMR)<br>
<a href="https://www.sciencedirect.com/science/article/pii/S136184152200322X"> ![paper](src/paper.png)</a>

- <a href="https://www.creatis.insa-lyon.fr/Challenge/myosaiq"> **MYOSAIQ**</a> (MYOcardial Segmentation with Automated Infarct Quantification)<br>
The full dataset is composed of 467 Late gadolinium enhanced magnetic resonance images from two different cohorts to quantify myocardial infarction (MI) lesions at different phases of the longitudinal evolution of the disease<br>
***Keyboard:*** MRI, Segmentation <br>

- <a href="https://www.ocmr.info"> **OCMR**</a> <br>
Open-Access Multi-Coil k-Space Dataset for Cardiovascular Magnetic Resonance Imaging <br>
***Keyboard:*** MRI <br>
<a href="https://arxiv.org/abs/2008.03410"> ![paper](src/paper.png)</a>

- <a href="https://orcascore.grand-challenge.org"> **orCaScore**</a> <br>
Cardiac CT exams of 72 patients <br>
***Keyboard:*** CT scan <br>
<a href="https://orcascore.grand-challenge.org/evaluation/challenge/leaderboard"> ![Leaderboard](src/leaderboard.png)</a> | <a href="https://pubmed.ncbi.nlm.nih.gov/27147348"> ![paper](src/paper.png)</a>

- <a href="https://parse2022.grand-challenge.org"> **Parse2022**</a> (Pulmonary Artery Segmentation 2022) <br>
Our dataset contains 200 3D volumes with refined pulmonary artery label <br>
***Keyboard:*** CT Pulmonary Angiography (CTPA) <br>
<a href="https://parse2022.grand-challenge.org/evaluation/challenge/leaderboard"> ![Leaderboard](src/leaderboard.png)</a> | <a href="https://arxiv.org/abs/2304.03708"> ![paper](src/paper.png)</a>

- <a href="https://stanfordaimi.azurewebsites.net/datasets/3a7548a4-8f65-4ab7-85fa-3d68c9efc1bd"> **RadFusion**</a><br>
The dataset collected data from 1794 patients susceptible to pulmonary embolism. It consists of Chest CT, patient demographics and medical history.<br>
***Keyboard:*** CT scan, Labeled <br>
<a href="https://arxiv.org/abs/2111.11665"> ![paper](src/paper.png)</a><br>
![licence](src/CcLogo.png) Stanford university dataset research use aggrement

- <a href="https://rvsc.projets.litislab.fr"> **RVSC**</a> (Right Ventricle Segmentation Challenge)<br>
***Keyboard:*** Cardiac cine MRI <br>
<a href="https://www.sciencedirect.com/science/article/abs/pii/S1361841514001509"> ![paper](src/paper.png)</a>

- <a href="https://www.cardiacatlas.org/sunnybrook-cardiac-data"> **SCD**</a> (Sunnybrook Cardiac Data) <br>
The dataset consist of 45 cine-MRI images from a mixed of patients and pathologies: healthy, hypertrophy, heart failure with infarction and heart failure without infarction.<br>
***Keyboard:*** Segmentation, Labeled <br>
<a href="https://midasjournal.org/browse/publication/658"> ![paper](src/paper.png)</a><br>
![licence](src/CcLogo.png) Public Domain (CC0 1.0 Universal)

- <a href="https://www.cardiacatlas.org/scmr-consensus-contours"> **SCMR Consensus Contours**</a> (Society for Cardiovascular Magnetic Resonance) <br>
This dataset is designed to have the most reliable ground truth myocardial contours from short-axis MRI with multiple pathologies (1 healthy and 3 cardiac disease).<br>
***Keyboard:*** Segmentation, Labeled <br>
<a href="https://jcmr-online.biomedcentral.com/articles/10.1186/s12968-015-0170-9"> ![paper](src/paper.png)</a>

- <a href="https://www.kaggle.com/competitions/second-annual-data-science-bowl"> **Second Annual Data Science Bowl**</a><br>
***Keyboard:*** cardiac MRI, Registration<br>
<a href="https://www.kaggle.com/competitions/second-annual-data-science-bowl/leaderboard"> ![Leaderboard](src/leaderboard.png)</a> 

- <a href="https://multicenteraorta.grand-challenge.org"> **SEG.A. 2023**</a> (Segmentation of the Aorta) <br>
***Keyboard:*** CTA (Computed tomography angiography), Labeled, Aorta <br>
<a href="https://multicenteraorta.grand-challenge.org/evaluation/preliminary-phase/leaderboard"> ![Leaderboard](src/leaderboard.png)</a> 

- <a href="https://www.doc.ic.ac.uk/~rkarim/la_lv_framework/wall/index.html"> **SLAWT**</a> (Segmentation of Left Atrial Wall for Thickness) <br>
The image database consisted of cardiac CT (n=10) and MRI (n=10) of healthy and diseased subjects.<br>
***Keyboard:*** CT scan, MRI, Segmentation, Labeled <br>
<a href="https://www.sciencedirect.com/science/article/pii/S1361841518306431"> ![paper](src/paper.png)</a>



### Kidneys and Urinary Tract

- <a href="https://www.cancerimagingarchive.net/collection/cptac-ccrcc"> **CPTAC-CCRCC**</a> (The Clinical Proteomic Tumor Analysis Consortium Clear Cell Renal Cell Carcinoma)<br>
Data from 262 subjects.<br>
***Keyboard:*** Multi-modality<br>
![licence](src/CcLogo.png) CC BY 3.0 

- <a href="https://kipa22.grand-challenge.org"> **KiPA22**</a> (Kidney PArsing 2022) <br>
Multi-Structure Segmentation for Renal Cancer Treatment <br>
***Keyboard:*** Computed Tomography Angiography (CTA), Labeled <br>
<a href="https://kipa22.grand-challenge.org/evaluation/challenge/leaderboard"> ![Leaderboard](src/leaderboard.png)</a>

- <a href="https://kits19.grand-challenge.org/"> **KiTS19**</a> (Kidney Tumor Segmentation 2019) <br>
***Keyboard:*** CT scan, Cancer, Labeled <br>
<a href="https://kits19.grand-challenge.org/evaluation/challenge/leaderboard/"> ![Leaderboard](src/leaderboard.png)</a> | <a href="https://www.sciencedirect.com/science/article/abs/pii/S1361841520301857"> ![paper](src/paper.png)</a><br>
![licence](src/CcLogo.png) CC BY-NC-SA 4.0

- <a href="https://kits-challenge.org/kits21"> **KiTS21**</a> (Kidney Tumor Segmentation 2021) <br>
***Keyboard:*** CT scan, Cancer, Labeled <br>
<a href="https://kits21.grand-challenge.org/evaluation/challenge/leaderboard/"> ![Leaderboard](src/leaderboard.png)</a> | <a href="https://arxiv.org/abs/2307.01984"> ![paper](src/paper.png)</a> | <a href="https://link.springer.com/chapter/10.1007/978-3-030-98385-7_13"> ![paper](src/paper.png)

- <a href="https://kits-challenge.org/kits23"> **KiTS23**</a> (Kidney Tumor Segmentation 2023) <br>
***Keyboard:*** CT scan, Cancer, Labeled <br>

- <a href="https://www.cancerimagingarchive.net/collection/tcga-blca"> **TCGA-BLCA**</a> (The Cancer Genome Atlas Urothelial Bladder Carcinoma)<br>
Data from 120 subjects and 111,781 images<br>
***Keyboard:*** Multi-modality <br>
![licence](src/CcLogo.png) CC BY 3.0 

- <a href="https://www.cancerimagingarchive.net/collection/tcga-kich"> **TCGA-KICH**</a> (The Cancer Genome Atlas Kidney Chromophobe)<br>
Data from 15 subjects.<br>
***Keyboard:*** MRI, CT scan<br>
![licence](src/CcLogo.png) CC BY 3.0 

- <a href="https://www.cancerimagingarchive.net/collection/tcga-kirc"> **TCGA-KIRC**</a> (The Cancer Genome Atlas Kidney Renal Clear Cell Carcinoma)<br>
Data from 267 subjects.<br>
***Keyboard:*** Multi-modality<br>
![licence](src/CcLogo.png) CC BY 3.0 

- <a href="https://www.cancerimagingarchive.net/collection/tcga-kirp"> **TCGA-KIRP**</a> (The Cancer Genome Atlas Cervical KIdney Renal Papillary cell carcinoma)<br>
Data from 33 subjects.<br>
***Keyboard:*** Multi-modality<br>
![licence](src/CcLogo.png) CC BY 3.0 

- <a href="https://rodare.hzdr.de/record/2473"> **Urinary tract infections**</a><br>
A dataset containing 300 images and 3,562 manually annotated urinary cells labelled into seven classes of clinically significant urinary content. <br>
***Keyboard:*** Segmentation , Labeled <br>
<a href="https://www.nature.com/articles/s41597-024-02975-0"> ![paper](src/paper.png)</a> <br>
![licence](src/CcLogo.png) CC BY 4.0



### Liver

- <a href="https://www.ircad.fr/research/data-sets/liver-segmentation-3d-ircadb-01"> **3D-IRCADb-01**</a> (3D Image Reconstruction for Comparison of Algorithm Database) <br>
10 women and 10 men with hepatic tumours in 75% of cases. <br>
***Keyboard:*** 3D CT scan, Cancer, Labeled, Segmentation <br>
![licence](src/CcLogo.png) CC BY-NC-ND 4.0

- <a href="https://atlas-challenge.u-bourgogne.fr"> **ATLAS**</a> (A Tumour and Liver Automatic Segmentation) <br>
60 Public images <br>
***Keyboard:*** MRI, Cancer, Labeled <br>
<a href="https://atlas-challenge.u-bourgogne.fr/leaderboard"> ![Leaderboard](src/leaderboard.png)</a> | <a href="https://www.mdpi.com/2306-5729/8/5/79"> ![paper](src/paper.png)</a> | <a href="https://www.nature.com/articles/s41598-024-53528-9"> ![paper](src/paper.png)</a>

- <a href="https://clust.ethz.ch"> **CLUST**</a> (Challenge on Liver Ultrasound Tracking)<br>
It has two versions <br>
<a href="https://clust.ethz.ch/results.html"> ![Leaderboard](src/leaderboard.png)</a> | <a href="https://clust.ethz.ch/publications.html"> ![paper](src/paper.png)</a>

- <a href="https://www.cancerimagingarchive.net/collection/colorectal-liver-metastases"> **Colorectal Liver Metastases**</a><br>
This collection consists of images for 197 patients with Colorectal Liver Metastases (CRLM). <br>
***Keyboard:*** CT scan, Cancer, Segmentation, Labeled<br>
<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10847495"> ![paper](src/paper.png)</a><br>
![licence](src/CcLogo.png) CC BY 4.0 

- <a href="https://zenodo.org/records/7774566"> **Duke Liver DataSet**</a><br>
It provides over 2000 anonymized MRI image series acquired in routine liver MRI protocols across 105 subjects. <br>
***Keyboard:*** MRI, Cancer, Labeled <br>
<a href="https://ieeexplore.ieee.org/document/9242262"> ![paper](src/paper.png)</a><br>
![licence](src/CcLogo.png) CC-BY-NC-ND-4.0

- <a href="https://www.cancerimagingarchive.net/collection/hcc-tace-seg"> **HCC-TACE-Seg**</a><br>
Multimodality annotated Hepatocellular carcinoma (HCC) cases with and without advanced imaging segmentation. <br>
***Keyboard:*** CT scan, Cancer, Segmentation, Labeled<br>
<a href="https://www.nature.com/articles/s41597-023-01928-3"> ![paper](src/paper.png)</a><br>
![licence](src/CcLogo.png) CC BY 4.0

- <a href="https://competitions.codalab.org/competitions/17094"> **LiTS**</a> (Liver Tumor Segmentation) <br>
***Keyboard:*** CT scan, Cancer, Labeled <br>
<a href="https://competitions.codalab.org/competitions/17094#results"> ![Leaderboard](src/leaderboard.png)</a> | <a href="https://arxiv.org/abs/1901.04056"> ![paper](src/paper.png)</a><br>
![licence](src/CcLogo.png) Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License

- <a href="https://p2ilf.grand-challenge.org"> **P2ILF**</a> (Preoperative to Intraoperative Laparoscopy Fusion) <br>
***Keyboard:*** Laparoscopic video images, Segmentation, Registration  <br>
<a href="https://p2ilf.grand-challenge.org/evaluation/challenge/leaderboard"> ![Leaderboard](src/leaderboard.png)</a>

- <a href="https://paip2019.grand-challenge.org"> **PAIP2019**</a> <br>
***Keyboard:*** Whole-slide images (WSIs), Cancer, Segmentation, Labeled, Hepatocellular Carcinoma (HCC) <br>
<a href="https://paip2019.grand-challenge.org/Leaderboard"> ![Leaderboard](src/leaderboard.png)</a>

- <a href="https://www.smir.ch/ShapeChallenge/Start2014"> **SHAPE 2014**</a><br>
The dataset is part of the training data from the "VISCERAL Organ Segmentation and Landmark Detection Challenge" <br>
***Keyboard:*** MRI, CT scan, Labeled, Segmentation <br>

- <a href="https://sliver07.grand-challenge.org"> **SLIVER07**</a> (Segmentation of the Liver Competition 2007) <br>
***Keyboard:*** 3D CT scan <br>
<a href="https://sliver07.grand-challenge.org/evaluation/challenge/leaderboard/"> ![Leaderboard](src/leaderboard.png)</a> | <a href="https://ieeexplore.ieee.org/document/4781564?isnumber=5175685&arnumber=4781564&count=18&index=11"> ![paper](src/paper.png)</a>

- <a href="https://www.cancerimagingarchive.net/collection/tcga-lihc"> **TCGA-LIHC**</a> (The Cancer Genome Atlas Liver Hepatocellular Carcinoma) <br>
It has used in <a href='https://zenodo.org/records/8179129'> LiverHccSeg </a> <br>
***Keyboard:*** MRI, CT scan, Cancer <br>
![licence](src/CcLogo.png) CC BY 3.0



### Lungs

- <a href="https://wiki.cancerimagingarchive.net/pages/viewpage.action?pageId=21267414"> **4D Lung**</a> <br>
The images include four-dimensional (4D) fan beam (4D-FBCT) and 4D cone beam CT (4D-CBCT) <br>
***Keyboard:*** Cancer <br>
<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3647023"> ![paper](src/paper.png) The dataset is described</a> | <a href="https://pubmed.ncbi.nlm.nih.gov/22391105"> ![paper](src/paper.png)</a> <br>
![licence](src/CcLogo.png) CC BY 3.0

- <a href="https://acdc-lunghp.grand-challenge.org/"> **ACDC-LungHP**</a> (Automatic Cancer Detection and Classification in Lung Histopathology) <br>
***Keyboard:*** Cancer, H&E staining, Pathology  <br>
<a href="https://acdc-lunghp.grand-challenge.org/evaluation/challenge/leaderboard/"> ![Leaderboard](src/leaderboard.png)</a> | <a href="https://ieeexplore.ieee.org/document/9265237"> ![paper](src/paper.png)</a> | <a href="http://arxiv.org/abs/1803.05471"> ![paper](src/paper.png)</a> 

- <a href="https://datadryad.org/stash/dataset/doi:10.5061/dryad.mj76c"> **Airway**</a><br>
Airway Segmentation and Centerline Extraction from Thoracic CT scan<br>
<a href="https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0144282"> ![paper](src/paper.png)</a><br>
![licence](src/CcLogo.png) CC0 1.0 Universal (CC0 1.0) Public Domain Dedication

- <a href="https://anode09.grand-challenge.org/"> **ANODE09**</a> (Automatic Nodule Detection 2009) <br>
Automatic detection of pulmonary nodules in chest <br>
***Keyboard:*** CT-scan <br>
<a href="https://anode09.grand-challenge.org/Results"> ![Leaderboard](src/leaderboard.png)</a> | <a href="https://www.sciencedirect.com/science/article/abs/pii/S1361841510000587"> ![paper](src/paper.png)</a> <br>
![licence](src/CcLogo.png) Data downloaded from their site may only be used for the purpose of preparing an entry to be submitted on the site

- <a href="https://atm22.grand-challenge.org"> **ATM22**</a> (Airway Tree Modeling) <br>
Dataset provides CT scans with detailed pulmonary airway annotation. <br>
***Keyboard:*** CT-scan, Labeled<br>
<a href="https://atm22.grand-challenge.org/evaluation/validation-phase-1-live-leaderboard/leaderboard"> ![Leaderboard](src/leaderboard.png)</a> | <a href="https://www.sciencedirect.com/science/article/abs/pii/S1361841523002177"> ![paper](src/paper.png)</a>

- <a href="https://github.com/BIMCV-CSUSP/BIMCV-COVID-19"> **BIMCV COVID-19**</a><br>
These iterations of the database include 21342 CR, 34829 DX and 7918 CT studies.<br>
***Keyboard:*** Chest radiography (CXR), CT scan, Labeled<br>
<a href="https://arxiv.org/abs/2006.01174"> ![paper](src/paper.png)</a>

- <a href="https://brixia.github.io"> **BrixIA**</a><br>
COVID19 severity score assessment project and database. <br>
***Keyboard:*** Chest radiography (CXR), Labeled <br>
<a href="https://www.sciencedirect.com/science/article/pii/S136184152100092X"> ![paper](src/paper.png)</a>

- <a href="https://www.bsti.org.uk/training-and-education/covid-19-bsti-imaging-database"> **BSTI COVID19**</a> (British Society of Thoracic Imaging) <br>
***Keyboard:*** CT scan <br>
![licence](src/CcLogo.png) It is not intended for download or research applications.

- <a href="https://auckland.figshare.com/articles/dataset/CANDID-PTX/14173982"> **CANDID-PTX**</a><br>
19,237 anonymized adult chest x-ray datasets in 1024 x 1024 pixel <br>
***Keyboard:*** X-ray, Segmentation, Labeled<br>
![licence](src/CcLogo.png) CC BY-NC-SA 4.0

- <a href="https://www.kaggle.com/datasets/mohamedhanyyy/chest-ctscan-images"> **Chest CT-Scan images**</a><br>
CT-Scan images with different types of chest cancer <br>
***Keyboard:*** CT-scan, Labeled<br>

- <a href="https://www.kaggle.com/datasets/paultimothymooney/chest-xray-pneumonia"> **Chest X-Ray Images (Pneumonia)**</a><br>
There are 5,863 X-Ray images and 2 categories (Pneumonia/Normal).<br>
<a href="https://www.cell.com/cell/fulltext/S0092-8674(18)30154-5"> ![paper](src/paper.png)</a><br>
![licence](src/CcLogo.png) CC BY 4.0

- <a href="https://cxr-covid19.grand-challenge.org"> **Chest XR COVID-19 detection**</a> <br>
The dataset contains 20,000+ images and 3 classes: COVID-19, Pneumonia and Normal (healthy). <br>
***Keyboard:*** X-ray, Labeled <br>
![licence](src/CcLogo.png) The dataset can only be used for this challenge

- <a href="https://github.com/Deepwise-AILab/ChestX-Det-Dataset"> **ChestX-Det**</a> <br>
It consists of 3578 images from NIH ChestX-14 <br>
***Keyboard:*** X-ray, Segmentation, Labeled <br>

- <a href="https://www.nih.gov/news-events/news-releases/nih-clinical-center-provides-one-largest-publicly-available-chest-x-ray-datasets-scientific-community"> **ChestX-ray8**</a> (ChestXray-NIHCC) <br>
100,000 anonymized chest x-ray images <br>
***Keyboard:*** X-ray, Labeled <br>
<a href="https://arxiv.org/abs/1705.02315"> ![paper](src/paper.png)</a> 

- <a href="https://www.v7labs.com/open-datasets/chestx-ray14"> **ChestX-ray14**</a> (ChestXray-NIHCC) <br>
It is a dataset which comprises 112,120 frontal-view X-ray images of 30,805  unique patients with the text-mined fourteen common disease labels, mined from the text radiological reports via NLP techniques. It expands on ChestX-ray8 by adding six additional thorax diseases. <br>
***Keyboard:*** X-ray, Labeled <br>

- <a href="https://stanfordaimi.azurewebsites.net/datasets/23c56a0d-15de-405b-87c8-99c30138950c"> **CheXlocalize**</a><br>
234 images with 643 expert segmentations.<br>
***Keyboard:*** X-ray, Labeled<br>
<a href="https://www.nature.com/articles/s42256-022-00536-x"> ![paper](src/paper.png)</a><br>
![licence](src/CcLogo.png) Stanford university dataset research use aggrement

- <a href="https://physionet.org/content/chexmask-cxr-segmentation-data"> **CheXmask**</a><br>
The database aggregates 657,566 anatomical segmentation masks from five public databases.<br>
***Keyboard:*** X-ray, Labeled<br>
<a href="https://arxiv.org/abs/2307.03293"> ![paper](src/paper.png)</a><br>
![licence](src/CcLogo.png) Creative Commons Attribution 4.0 International Public License

- <a href="https://stanfordmlgroup.github.io/competitions/chexpert/"> **CheXpert**</a> <br>
A Large Chest X-Ray Dataset. <br>
***Keyboard:*** X-ray, Labeled <br>
<a href="https://arxiv.org/abs/1901.07031"> ![paper](src/paper.png)</a>

- <a href="https://stanfordaimi.azurewebsites.net/datasets/f1577fbd-6f5c-417e-be81-850939f90daa"> **CheXphoto**</a><br>
It comprises a training set of natural photos and synthetic transformations of 10,507 x-rays from 3,000 unique patients that were sampled at random from the CheXpert training set, and a validation and test set of natural and synthetic transformations applied to all 234 x-rays from 200 patients and 668 x-rays from 500 patients in the CheXpert validation and test sets, respectively.<br>
![licence](src/CcLogo.png) Stanford university dataset research use aggrement

- <a href="https://www.cancerimagingarchive.net/collection/cmb-lca"> **CMB-LCA**</a> (Cancer Moonshot Biobank - Lung Cancer)<br>
***Keyboard:*** Multi-modality, Cancer <br>
![licence](src/CcLogo.png) CC BY 4.0 - TCIA Restricted

- <a href="https://covid-segmentation.grand-challenge.org"> **COVID-19-20**</a> <br>
COVID-19 Lung CT Lesion Segmentation <br>
***Keyboard:*** CT scan, Labeled <br>
<a href="https://covid-segmentation.grand-challenge.org/evaluation/challenge/leaderboard"> ![Leaderboard](src/leaderboard.png)</a> | <a href="https://www.sciencedirect.com/science/article/pii/S1361841522002353"> ![paper](src/paper.png)</a><br>
![licence](src/CcLogo.png) Annotation data are available under CC0 license

- <a href="https://www.cancerimagingarchive.net/collection/covid-19-ar"> **COVID-19-AR**</a> <br>
Chest Imaging with Clinical and Genomic Correlates Representing a Rural COVID-19 Positive Population <br>
<a href="https://www.nature.com/articles/s41597-020-00741-6"> ![paper](src/paper.png)</a><br>
![licence](src/CcLogo.png) CC BY 4.0

- <a href="https://www.kaggle.com/datasets/bachrr/covid-chest-xray"> **COVID-19 chest xray**</a> <br>
It contains COVID-19 cases as well as MERS, SARS, and ARDS.<br>
***Keyboard:*** X-ray, CT scan<br>
![licence](src/CcLogo.png) CC0: Public Domain

- <a href="https://zenodo.org/records/3757476"> **COVID-19 CT Lung and Infection**</a> <br>
The dataset contains 20 labeled COVID-19 CT scans <br>
***Keyboard:*** Segmentation <br>
![licence](src/CcLogo.png) CC BY 4.0

- <a href="https://www.kaggle.com/datasets/andrewmvd/covid19-ct-scans"> **COVID-19 CT scans**</a><br>
20 CT scans and expert segmentations of patients with COVID-19<br>
***Keyboard:*** Labeled<br>
![licence](src/CcLogo.png) Coronacases (CC BY NC 3.0) - Radiopedia (CC BY NC SA 3.0) - Annotations (CC BY 4.0)

- <a href="https://www.kaggle.com/datasets/pranavraikokte/covid19-image-dataset"> **Covid-19 Image**</a> <br>
3 Way Classification - COVID-19, Viral Pneumonia, Normal <br>
***Keyboard:*** X ray, Labeled <br>
![licence](src/CcLogo.png) CC BY-SA 4.0

- <a href="https://data.uni-hannover.de/dataset/cov-19-img"> **COVID-19 Image Repository**</a><br>
An anonymized data set of COVID-19 cases with a focus on radiological imaging <br>
![licence](src/CcLogo.png) CC BY 3.0

- <a href="https://wiki.cancerimagingarchive.net/pages/viewpage.action?pageId=89096912"> **COVID-19-NY-SBU**</a><br>
This collection of cases was acquired at Stony Brook University from patients who tested positive for COVID-19.<br>
![licence](src/CcLogo.png) CC BY 4.0

- <a href="https://www.kaggle.com/datasets/tawsifurrahman/covid19-radiography-database"> **COVID-19 Radiography Database**</a> <br>
3616 COVID-19 Chest X-ray images and lung masks <br>
<a href="https://www.sciencedirect.com/science/article/pii/S001048252100113X"> ![paper](src/paper.png)</a> | <a href="https://ieeexplore.ieee.org/document/9144185"> ![paper](src/paper.png)</a>

- <a href="https://github.com/jannisborn/covid19_ultrasound"> **COVID-19 Ultrasound**</a><br>
200 LUS videos labelled with a diagnostic outcome <br>
<a href="https://thorax.bmj.com/content/76/Suppl_1/A230.2"> ![paper](src/paper.png) Abstract</a> | <a href="https://www.mdpi.com/2076-3417/11/2/672"> ![paper](src/paper.png) Full paper</a> | <a href="https://arxiv.org/abs/2004.12084"> ![paper](src/paper.png)</a>

- <a href="https://github.com/v7labs/covid-19-xray-dataset"> **COVID-19 xray**</a> <br>
This dataset contains 6500 images of AP/PA chest x-rays with pixel-level polygonal lung segmentations <br>

- <a href="https://github.com/NinaWie/COVID-BLUES"> **COVID-BLUES**</a> (Bluepoint Lung Ultrasound)<br>
It contains bluepoint-specific lung ultrasound videos recorded included 63 patients (33 COVID-positive and 30 COVID-negative), with the inclusion criteria being symptoms of a lung infection.<br>

- <a href="https://github.com/ieee8023/covid-chestxray-dataset"> **COVID-ChestXRay**</a> <br>
An database of COVID-19 cases with chest X-ray or CT images <br>
***Keyboard:*** CT scan, X-ray <br>
<a href="https://arxiv.org/abs/2006.11988"> ![paper](src/paper.png)</a> | <a href="https://arxiv.org/abs/2004.05405"> ![paper](src/paper.png)</a>

- <a href="https://covid-ct.grand-challenge.org"> **COVID-CT**</a> <br>
It contains 349 COVID-19 CT images from 216 patients and 463 non-COVID-19 CTs<br>
***Keyboard:*** CT scan, Classification <br>
<a href="https://covid-ct.grand-challenge.org/Leaderboard"> ![Leaderboard](src/leaderboard.png)</a> | <a href="https://arxiv.org/abs/2003.13865"> ![paper](src/paper.png)</a> 

- <a href="https://github.com/ShahinSHH/COVID-CT-MD"> **COVID-CT-MD**</a><br>
The dataset contains volumetric chest CT scans of 169 patients positive for COVID-19 infection, 60 patients with Community Acquired Pneumonia, and 76 normal patients. <br>
***Keyboard:*** CT scan, Labeled <br>
<a href="https://www.nature.com/articles/s41597-021-00900-3"> ![paper](src/paper.png) Desription of the Dataset</a>

- <a href="https://github.com/mr7495/COVID-CTset"> **COVID-CTset**</a><br>
The dataset contains 63849 images from 377 patients <br>
***Keyboard:*** CT scan, Labeled <br>
<a href="https://www.sciencedirect.com/science/article/pii/S1746809421001853"> ![paper](src/paper.png) Desription of the Dataset</a>

- <a href="https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/6ACUZJ"> **COVID19-CT**</a><br>
An Chest CT Image Repository of 1000+ Patients with Confirmed COVID-19 Diagnosis <br>
![licence](src/CcLogo.png) CC0 1.0

- <a href="https://github.com/lindawangg/COVID-Net/blob/master/docs/COVIDx.md"> **COVIDx**</a> <br>
It is a collection of 8 datasets <br>
***Keyboard:*** CT scan, X-ray <br>
<a href="https://arxiv.org/abs/2003.09871"> ![paper](src/paper.png)</a>

- <a href="https://www.cancerimagingarchive.net/collection/cptac-lscc"> **CPTAC-LSCC**</a> (Clinical Proteomic Tumor Analysis Consortium Lung Squamous Cell Carcinoma)<br>
***Keyboard:*** CT scan, PT, Histopathology, Cancer <br>
![licence](src/CcLogo.png) CC BY 3.0 - TCIA Restricted

- <a href="https://crass.grand-challenge.org"> **CRASS12**</a> (Chest Radiograph Anatomical Structure Segmentation) <br>
Automatic segmentation of anatomical structures in chest radiographs <br>
<a href="https://www.diagnijmegen.nl/publications/hoge12/?bibkey=Hoge12"> ![paper](src/paper.png)</a> 

- <a href="https://www.cancerimagingarchive.net/collection/ct-images-in-covid-19"> **CT Images in COVID-19**</a> <br>
A dataset from 632 patients with COVID-19 infections at initial point of care, and a dataset of 121 CTs from 29 patients with COVID-19 infections with serial / sequential CTs. <br>
<a href="https://www.nature.com/articles/s41467-020-17971-2"> ![paper](src/paper.png) A classification model derived</a> <br>
![licence](src/CcLogo.png) CC BY 4.0

- <a href="https://huggingface.co/datasets/ibrahimhamamci/CT-RATE"> **CT-RATE**</a> <br>
The 3D medical imaging dataset that pairs images with textual reports. <br>
***Keyboard:*** CT scan, Labeled <br>
<a href="https://arxiv.org/abs/2403.17834"> ![paper](src/paper.png)</a><br>
![licence](src/CcLogo.png) CC BY-NC-SA

- <a href="https://www.aapm.org/GrandChallenge/CTVIE"> **CTVIE19**</a> <br>
Data consist of PFTs, multi-inflation non-contrast CT (4D or breath-hold) and contrast-based ventilation images (nuclear imaging or hyperpolarised gas MRI) for patients with lung cancer and several non-oncological obstructive respiratory diseases including cystic fibrosis, asthma and COPD.<br>
***Keyboard:*** CT scan, Labeled, Segmentation<br>

- <a href="https://physionet.org/content/chest-x-ray-segmentation"> **CXLSeg**</a> <br>
Segmented Chest X-ray radiographs based on the MIMIC-CXR dataset. <br>
***Keyboard:*** Segmentation <br>
![licence](src/CcLogo.png) PhysioNet Credentialed Health Data License 1.5.0

- <a href="https://med.emory.edu/departments/radiation-oncology/research-laboratories/deformable-image-registration/index.html"> **DIR-Lab**</a> (Deformable Image Registration Laboratory)<br>
Thoracic 4DCT images. Inspiratory and expiratory breath-hold CT image pairs. <br>
***Keyboard:*** CT scan, Labeled <br>
<a href="https://med.emory.edu/departments/radiation-oncology/research-laboratories/deformable-image-registration/publications.html"> ![paper](src/paper.png)</a>

- <a href="https://veet.via.cornell.edu/lungdb.html"> **ELCAP**</a> (Early Lung Cancer Action Program) <br>
The database currently consists of an image set of 50 low-dose documented whole-lung CT scans for detection. <br>
***Keyboard:*** CT scan, Nodules, Labeled <br>

- <a href="https://empire10.grand-challenge.org"> **EMPIRE10**</a> (Evaluation of Methods for Pulmonary Image Registration 2010) <br>
***Keyboard:*** CT, Registration of thoracic <br>
<a href="https://pubmed.ncbi.nlm.nih.gov/21632295"> ![paper](src/paper.png)</a> <br>
![licence](src/CcLogo.png) Data downloaded from this site may only be used for the purpose of preparing an entry to be submitted on this site.

- <a href="http://image.diku.dk/exact"> **EXACT09**</a> (Extraction of Airways from CT 2009) <br>
The images are volumetric chest CT scans acquired at different sites using several different scanners, scanning protocols, and reconstruction parameters. <br>
<a href="https://ieeexplore.ieee.org/document/6249784"> ![paper](src/paper.png)</a>

- <a href="https://som-shahlab.github.io/inspect-website"> **INSPECT**</a><br>
It contains data from 19,402 patients, including CT images, radiology report impression sections, and structured electronic health record (EHR) data. <br>
***Keyboard:*** CT scan, Cancer, Labeled <br>
<a href="https://arxiv.org/abs/2311.10798"> ![paper](src/paper.png)</a><br>
![licence](src/CcLogo.png) Stanford university dataset research use aggrement

- <a href="https://www.kaggle.com/datasets/hamdallak/the-iqothnccd-lung-cancer-dataset"> **IQ-OTH/NCCD**</a> (Iraq-Oncology Teaching Hospital/National Center for Cancer Diseases) <br>
The dataset contains a total of 1190 images representing CT scan slices of 110 cases. <br>
***Keyboard:*** CT scan, Cancer, Labeled <br>
![licence](src/CcLogo.png) CC0: Public Domain

- <a href="http://db.jsrt.or.jp/eng.php"> **JSRT**</a> (Japanese Society of Radiological Technology) <br>
The database includes 154 conventional chest radiographs with a lung nodule and 93 radiographs without a nodule <br>
***Keyboard:*** X-ray <br>
<a href="https://ietresearch.onlinelibrary.wiley.com/doi/full/10.1049/iet-ipr.2019.0423"> ![paper](src/paper.png) Cited DB </a>  | <a href="https://arxiv.org/abs/1907.09375"> ![paper](src/paper.png) Cited DB</a>

- <a href="https://www.cancerimagingarchive.net/collection/lctsc"> **LCTSC**</a> (Lung CT Segmentation Challenge) <br>
***Keyboard:*** CT scan, Cancer <br>
<a href="https://aapm.onlinelibrary.wiley.com/doi/10.1002/mp.13141"> ![paper](src/paper.png)</a> <br>
![licence](src/CcLogo.png) CC BY 3.0 

- <a href="https://wiki.cancerimagingarchive.net/pages/viewpage.action?pageId=1966254"> **LIDC-IDRI**</a> (Lung Image Database Consortium (LIDC) and Image Database Resource Initiative (IDRI)) <br>
***Keyboard:*** CT scan, Cancer, Labeled <br>
<a href="https://aapm.onlinelibrary.wiley.com/doi/10.1118/1.3528204"> ![paper](src/paper.png)</a> <br>
![licence](src/CcLogo.png) CC BY 3.0 

- <a href="https://lndb.grand-challenge.org"> **LNDb**</a> (Lung Nodule Database) <br>
Lung nodule detection, segmentation and characterization as well as prediction of patient follow-up <br>
***Keyboard:*** Cancer, CT-scan <br>
<a href="https://lndb.grand-challenge.org/evaluation/challenge/leaderboard"> ![Leaderboard](src/leaderboard.png)</a> | <a href="https://pubmed.ncbi.nlm.nih.gov/33740739"> ![paper](src/paper.png) </a> <br> ![licence](src/CcLogo.png) CC BY-NC-ND 4.0

- <a href="https://lola11.grand-challenge.org/"> **LOLA11**</a> (LObe and Lung Analysis 2011) <br>
Compare methods for (semi-)automatic segmentation of the lungs and lobes from chest <br>
***Keyboard:*** segmentation, CT-scan <br>
<a href="https://lola11.grand-challenge.org/evaluation/challenge/leaderboard/"> ![Leaderboard](src/leaderboard.png)</a><br>
![licence](src/CcLogo.png) Data downloaded from this site may only be used for the purpose of preparing an entry to be submitted on this site. ...

- <a href="https://lumic.grand-challenge.org"> **LUMIC**</a> <br>
***Keyboard:*** CT-scan, registration, Labeled<br>
<a href="https://pubmed.ncbi.nlm.nih.gov/30888690"> ![paper](src/paper.png)</a> 

- <a href="https://luna16.grand-challenge.org"> **LUNA16**</a> (LUng Nodule Analysis 2016) <br>
Nodule location detection <br>
***Keyboard:*** Cancer, CT-scan <br>
<a href="https://luna16.grand-challenge.org/Results"> ![Leaderboard](src/leaderboard.png)</a> | <a href="https://www.sciencedirect.com/science/article/abs/pii/S1361841517301020"> ![paper](src/paper.png) Overview paper</a> </a> <br> ![licence](src/CcLogo.png) Creative Commons Attribution 4.0 International License

- <a href="https://www.cancerimagingarchive.net/collection/lung-fused-ct-pathology"> **Lung-Fused-CT-Pathology**</a><br>
Mapping the extent of Invasive Adenocarcinoma onto in vivo lung CT <br>
***Keyboard:*** Cancer, CT scan, Labeled<br>
<a href="https://link.springer.com/article/10.1007/s00330-017-4813-0"> ![paper](src/paper.png)</a><br>
![licence](src/CcLogo.png) CC BY 3.0

- <a href="https://wiki.cancerimagingarchive.net/pages/viewpage.action?pageId=70224216"> **Lung-PET-CT-Dx**</a> <br>
A Large-Scale CT and PET/CT Dataset for Lung Cancer Diagnosis <br>
***Keyboard:*** Cancer, Labeled <br>![licence](src/CcLogo.png) CC BY 4.0

- <a href="https://figshare.com/articles/dataset/MedSeg_Covid_Dataset_1/13521488"> **MedSeg Covid Dataset**</a><br>
This is a dataset of 100 axial CT images from >40 patients with COVID-19 <br>
![licence](src/CcLogo.png) CC0

- <a href="https://mela.grand-challenge.org"> **MELA**</a> (Mediastinal Lesion Analysis) <br>
Detectition mediastinal lesions from 1100 CT scans, consisting of 770 CTs for training, 110 CTs for validation, and 220 CTs for testing. <br>
***Keyboard:*** CT Scan <br>
<a href="https://mela.grand-challenge.org/evaluation/challenge/leaderboard"> ![Leaderboard](src/leaderboard.png)</a>

- <a href="https://wiki.cancerimagingarchive.net/pages/viewpage.action?pageId=80969742"> **MIDRC-RICORD-1A**</a> (Medical Imaging Data Resource Center - RSNA International COVID-19 Open Radiology Database Release 1a)<br>
120 Chest CT Covid+ <br>
***Keyboard:*** CT Scan, Labeled <br>
<a href="https://pubs.rsna.org/doi/10.1148/radiol.2021203957"> ![paper](src/paper.png)</a><br>![licence](src/CcLogo.png) CC BY-NC 4.0

- <a href="https://wiki.cancerimagingarchive.net/pages/viewpage.action?pageId=80969771"> **MIDRC-RICORD-1B**</a> (Medical Imaging Data Resource Center - RSNA International COVID-19 Open Radiology Database Release 1b)<br>
120 Chest CT Covid+ <br>
***Keyboard:*** CT Scan, Labeled <br>
<a href="https://pubs.rsna.org/doi/10.1148/radiol.2021203957"> ![paper](src/paper.png)</a><br>![licence](src/CcLogo.png) CC BY-NC 4.0

- <a href="https://wiki.cancerimagingarchive.net/pages/viewpage.action?pageId=70230281"> **MIDRC-RICORD-1C**</a> (Medical Imaging Data Resource Center - RSNA International COVID-19 Open Radiology Database Release 1c)<br>
998 Chest X-rays Covid+ <br>
***Keyboard:*** X-rays, Labeled <br>
<a href="https://pubs.rsna.org/doi/10.1148/radiol.2021203957"> ![paper](src/paper.png)</a><br>![licence](src/CcLogo.png) CC BY-NC 4.0

- <a href="https://physionet.org/content/mimic-cxr"> **MIMIC-CXR**</a> <br>
The dataset contains 377,110 images corresponding to 227,835 radiographic. <br>
***Keyboard:*** X-ray <br>
<a href="https://www.nature.com/articles/s41597-019-0322-0"> ![paper](src/paper.png)</a> | <a href="https://arxiv.org/abs/1901.07042"> ![paper](src/paper.png)</a><br>![licence](src/CcLogo.png) PhysioNet Credentialed Health Data License 1.5.0

- <a href="https://physionet.org/content/mimic-cxr-jpg"> **MIMIC-CXR-JPG**</a><br>
The MIMIC-CXR-JPG dataset is wholly derived from MIMIC-CXR, providing JPG format files derived from the DICOM images and structured labels derived from the free-text reports.<br>
***Keyboard:*** X-ray<br>
<a href="https://arxiv.org/abs/1901.07042"> ![paper](src/paper.png)</a><br>![licence](src/CcLogo.png) PhysioNet Credentialed Health Data License 1.5.0

- <a href="https://wiki.cancerimagingarchive.net/pages/viewpage.action?pageId=5800702"> **NLST**</a> (National Lung Screening Trial)<br>
26,254 low-dose CT scans <br>
***Keyboard:*** CT Scan, Labeled <br>
<a href="https://www.nejm.org/doi/10.1056/NEJMoa1102873"> ![paper](src/paper.png)</a><br>![licence](src/CcLogo.png) CC BY 4.0

- <a href="https://node21.grand-challenge.org"> **NODE21**</a> <br>
Detection and generation of lung nodules. <br>
***Keyboard:*** X-ray <br>
<a href="https://node21.grand-challenge.org/evaluation/challenge/leaderboard"> ![Leaderboard](src/leaderboard.png)</a> | <a href="https://arxiv.org/abs/2401.02192"> ![paper](src/paper.png)</a><br>![licence](src/CcLogo.png) CC BY-NC-ND 4.0

- <a href="https://www.cancerimagingarchive.net/collection/nsclc-radiogenomics"> **NSCLC Radiogenomics**</a> (Non-Small Cell Lung Cancer)<br>
The dataset comprises Computed Tomography (CT), Positron Emission Tomography (PET)/CT images, semantic annotations of the tumors as observed on the medical images using a controlled vocabulary, segmentation maps of tumors in the CT scans, and quantitative values obtained from the PET/CT scans.<br>
<a href="https://pubs.rsna.org/doi/10.1148/radiol.12111607"> ![paper](src/paper.png)</a> <br>
![licence](src/CcLogo.png) CC BY 3.0

- <a href="https://www.cancerimagingarchive.net/analysis-result/nsclc-radiogenomics-stanford"> **NSCLC Radiogenomics-Stanford**</a> (Non-Small Cell Lung Cancer) <br>
This collection contains images from patients with NSCLC imaged prior to surgical excision with both thin-section computed tomography (CT) and whole body positron emissions tomography (PET)/CT scans <br>
<a href="https://pubs.rsna.org/doi/10.1148/radiol.12111607"> ![paper](src/paper.png)</a> <br>
![licence](src/CcLogo.png) CC BY 3.0

- <a href="https://www.cancerimagingarchive.net/collection/nsclc-radiomics"> **NSCLC-Radiomics**</a> (Non-Small Cell Lung Cancer) <br>
This collection contains images from 422 patients.  <br>
***Keyboard:*** CT Scan, Labeled <br>![licence](src/CcLogo.png) CC BY-NC 3.0

- <a href="https://www.cancerimagingarchive.net/collection/nsclc-radiomics-interobserver1/"> **NSCLC-Radiomics-Interobserver1**</a> (Non-Small Cell Lung Cancer)<br>
This collection contains clinical data and computed tomography from 22 non-small cell lung cancer radiotherapy patients.<br>
***Keyboard:*** CT Scan, Labeled<br>![licence](src/CcLogo.png) CC BY-NC 3.0

- <a href="https://bimcv.cipf.es/bimcv-projects/padchest"> **PadChest**</a> <br>
This dataset includes more than 160,000 images of 67,000 patients. <br>
***Keyboard:*** X-ray, Labeled <br>
<a href="https://www.sciencedirect.com/science/article/abs/pii/S1361841520301614"> ![paper](src/paper.png)</a>

- <a href="https://www.cancerimagingarchive.net/collection/phantom-fda"> **Phantom FDA**</a><br>
As part of a more general effort to probe the interrelated factors impacting the accuracy and precision of lung nodule size estimation, it has been presented with an anthropomorphic thoracic phantom containing a vasculature insert on which synthetic nodules were inserted or attached.<br>
***Keyboard:*** CT scan<br>
<a href="https://opg.optica.org/oe/fulltext.cfm?uri=oe-18-14-15244&id=203597"> ![paper](src/paper.png)</a><br>
![licence](src/CcLogo.png) CC BY 3.0

- <a href="https://www.kaggle.com/datasets/kmader/pulmonary-chest-xray-abnormalities"> **Pulmonary Chest X-Ray Abnormalities**</a><br>
Diagnose tuberculosis and other diseases from x-rays.<br>
***Keyboard:*** Labeled<br>

- <a href="https://www.cancerimagingarchive.net/analysis-result/qin-lungct-seg"> **QIN Lung CT**</a> <br>
***Keyboard:*** Nodule, CT Scan, Segmentation <br>
![licence](src/CcLogo.png) CC BY 3.0

- <a href="https://www.cancerimagingarchive.net/collection/rider-lung-ct"> **RIDER Lung CT**</a><br>
Coffee-break lung CT collection with scan images reconstructed at multiple imaging parameters<br>
![licence](src/CcLogo.png) CC BY 4.0

- <a href="https://www.rsna.org/rsnai/ai-image-challenge/RSNA-Pneumonia-Detection-Challenge-2018"> **RSNA Pneumonia Detection**</a> (Radiological Society of North America 2018) <br>
30,000 frontal view chest radiographs <br>
***Keyboard:*** X-ray, Labeled <br>

- <a href="https://www.rsna.org/rsnai/ai-image-challenge/rsna-pe-detection-challenge-2020"> **RSNA Pulmonary Embolism**</a> (Radiological Society of North America 2020) <br>
Detect and characterize instances of pulmonary embolism (PE) on chest CT studies <br>
***Keyboard:*** CT scan, Labeled <br>
<a href="https://www.kaggle.com/c/rsna-str-pulmonary-embolism-detection/leaderboard"> ![Leaderboard](src/leaderboard.png)</a> | <a href="https://pubmed.ncbi.nlm.nih.gov/33937862"> ![paper](src/paper.png)</a>

- <a href="https://www.kaggle.com/datasets/plameneduardo/sarscov2-ctscan-dataset"> **SARS-CoV-2 CT-scan**</a><br>
Containing 1252 CT scans that are positive for SARS-CoV-2 infection (COVID-19) and 1230 CT scans for patients non-infected by SARS-CoV-2, 2482 CT scans in total <br>
<a href="https://www.medrxiv.org/content/10.1101/2020.04.24.20078584v3"> ![paper](src/paper.png)</a><br>
![licence](src/CcLogo.png) CC BY-NC-SA 4.0

- <a href="https://www.kaggle.com/datasets/yoctoman/shcxr-lung-mask"> **SHCXR Lung Mask**</a><br>
Manually Segmented Lungs Masks for Shenzhen Hospital Chest X-ray Set<br>
<a href="https://ieeexplore.ieee.org/document/8477564"> ![paper](src/paper.png)</a> | <a href="https://pubmed.ncbi.nlm.nih.gov/24108713"> ![paper](src/paper.png)</a><br>
![licence](src/CcLogo.png) CC BY-NC-SA 4.0

- <a href="https://www.kaggle.com/c/siim-acr-pneumothorax-segmentation"> **SIIM-ACR Pneumothorax Segmentation**</a><br>
Identify Pneumothorax disease in chest x-rays<br>
<a href="https://www.kaggle.com/c/siim-acr-pneumothorax-segmentation/leaderboard"> ![Leaderboard](src/leaderboard.png)</a>

- <a href="http://www.via.cornell.edu/databases/simbadb.html"> **SIMBA**</a> <br>
Chest Health Analysis System Public Lung Image Database.<br>
***Keyboard:*** CT scan, Labeled <br>

- <a href="https://www.cancerimagingarchive.net/collection/spie-aapm-lung-ct-challenge"> **SPIE-AAPM Lung CT Challenge**</a><br>
SPIE-AAPM-NCI Lung Nodule Classification Challenge Dataset<br>
<a href="https://www.spiedigitallibrary.org/journals/journal-of-medical-imaging/volume-3/issue-04/044506/LUNGx-Challenge-for-computerized-lung-nodule-classification/10.1117/1.JMI.3.4.044506.full#_=_"> ![paper](src/paper.png)</a> | <a href="https://www.spiedigitallibrary.org/journals/journal-of-medical-imaging/volume-2/issue-02/020103/Special-Section-Guest-Editorial--LUNGx-Challenge-for-computerized-lung/10.1117/1.JMI.2.2.020103.full#_=_"> ![paper](src/paper.png)</a><br>
![licence](src/CcLogo.png) CC BY 3.0

- <a href="https://stoic2021.grand-challenge.org"> **STOIC2021**</a> <br>
Study of Thoracic CT in COVID-19 <br>
***Keyboard:*** CT scan <br>
<a href="https://stoic2021.grand-challenge.org/evaluation/challenge/leaderboard"> ![Leaderboard](src/leaderboard.png)</a> | <a href="https://pubs.rsna.org/doi/10.1148/radiol.2021210384"> ![paper](src/paper.png)</a><br>
![licence](src/CcLogo.png) CC BY-NC 4.0

- <a href="https://www.cancerimagingarchive.net/collection/tcga-luad"> **TCGA-LUAD**</a> (The Cancer Genome Atlas Lung Adenocarcinoma) <br>
Data from 69 Participants <br>
***Keyboard:*** Multi-modality <br>
![licence](src/CcLogo.png) CC BY 3.0

- <a href="https://image-x.sydney.edu.au/vampire-challenge"> **VAMPIRE**</a> (Ventilation And Medical Pulmonary Image Registration Evaluation)<br>
It includes 50 pairs of 4DCT scans and corresponding clinical or experimental ventilation scans, referred to as reference ventilation images (RefVIs). The dataset includes 25 humans imaged with Galligas 4DPET/CT, 21 humans imaged with DTPA-SPECT, and 4 sheep imaged with Xenon-CT.<br>
***Keyboard:*** CT-scan, Animal<br>
<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6605778"> ![paper](src/paper.png)</a>

- <a href="https://vessel12.grand-challenge.org/"> **VESSEL12**</a> (VESsel SEgmentation in the Lung 2012) <br>
Automatic (and semi-automatic) segmentation of blood vessels in the lungs from CT images <br>
***Keyboard:*** CT-scan <br>
<a href="https://vessel12.grand-challenge.org/Results"> ![Leaderboard](src/leaderboard.png)</a> | <a href="https://www.sciencedirect.com/science/article/abs/pii/S136184151400111X"> ![paper](src/paper.png) Overview paper</a> 

- <a href="http://www.via.cornell.edu/databases/crpf.html"> **VIA/I-ELCAP**</a> <br>
The database contains a number of annotated CT image scans that highlight many of the key issues in measuring large lesions in the lung. <br>
***Keyboard:*** CT-scan <br>
<a href="https://pubmed.ncbi.nlm.nih.gov/19965010"> ![paper](src/paper.png) The dataset is described </a>

- <a href="https://physionet.org/content/vindr-pcxr"> **VinDr-PCXR**</a><br>
The dataset consists of 9,125 posteroanterior (PA) view CXR scans in patients younger than ten years and comes with both the localization of critical findings and the classification of common thoracic diseases. <br>
***Keyboard:*** Labeled <br>
![licence](src/CcLogo.png) PhysioNet Restricted Health Data License 1.5.0

- <a href="https://wsss4luad.grand-challenge.org"> **WSSS4LUAD**</a> (Weakly-supervised Tissue Semantic Segmentation for Lung Adenocarcinoma) <br>
Segment tumor epithelial, tumor-associated stroma and normal tissue with only patch-level labels. <br>
***Keyboard:*** H&E stained Whole Slide Image (WSI), Cancer <br>
<a href="https://wsss4luad.grand-challenge.org/evaluation/challenge/leaderboard"> ![Leaderboard](src/leaderboard.png)</a> | <a href="https://arxiv.org/abs/2204.06455"> ![paper](src/paper.png)</a><br>
![licence](src/CcLogo.png) CC BY 4.0



______

## Musculoskeletal System

### Bones

- <a href="https://ivdm3seg.weebly.com"> **IVDM3Seg**</a> <br>
Intervertebral Disc Localization and Segmentation from 3D Multi-modality MR (M3) Images <br>
***Keyboard:*** MRI <br>
<a href="https://ivdm3seg.weebly.com/results.html"> ![Leaderboard](src/leaderboard.png)</a>

- <a href="https://github.com/kc-santosh/medical-imaging-datasets"> **Fractured Limbs**</a><br>
5684 CT images (upper limbs: 2057 and lower limbs: 3627) to understand bone injurie. <br>
***Keyboard:*** CT scan, Labeled <br>
<a href="https://link.springer.com/article/10.1007/s10916-021-01724-9"> ![paper](src/paper.png)</a>

- <a href="https://www.cs.cit.tum.de/camp/publications/leg-3d-us-dataset"> **Leg-3D-US**</a><br>
The dataset assembles pairs of Ultrasound volumes and 3-labels muscles of the low-limb leg from 44 healthy volunteers, aged between 18 and 45 years. <br>
<a href="https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0268550"> ![paper](src/paper.png)</a><br>
![licence](src/CcLogo.png) GNU General Public License

- <a href="https://stanfordmlgroup.github.io/competitions/mura"> **MURA**</a> (MUsculoskeletal RAdiographs) <br>
Large Dataset for Abnormality Detection in Musculoskeletal Radiographs <br>
***Keyboard:*** X-ray, Labeled<br>
<a href="https://arxiv.org/abs/1712.06957"> ![paper](src/paper.png)</a> <br>
![licence](src/CcLogo.png) Stanford university dataset research use aggrement

- <a href="https://www.cancerimagingarchive.net/collection/osteosarcoma-tumor-assessment"> **Osteosarcoma-Tumor-Assessment**</a><br>
Osteosarcoma data from UT Southwestern/UT Dallas for Viable and Necrotic Tumor Assessment<br>
***Keyboard:*** Cancer, Histopathology, Labeled<br>
<a href="https://link.springer.com/chapter/10.1007/978-3-319-59575-7_2"> ![paper](src/paper.png)</a> | <a href="https://www.worldscientific.com/doi/abs/10.1142/9789813207813_0020"> ![paper](src/paper.png)</a> | <a href="https://www.liebertpub.com/doi/10.1089/cmb.2017.0153"> ![paper](src/paper.png)</a><br>
![licence](src/CcLogo.png) CC BY 3.0

- <a href="https://ribfrac.grand-challenge.org"> **RibFrac**</a> <br> 
A dataset for detect and classify around 5,000 rib fractures from 660 computed tomography (CT) scans <br>
***Keyboard:*** CT scan, Labeled <br>
<a href="https://ribfrac.grand-challenge.org/evaluation/challenge/leaderboard"> ![Leaderboard](src/leaderboard.png)</a><br>
![licence](src/CcLogo.png) CC BY-NC 4.0

- <a href="https://github.com/M3DV/RibSeg"> **RibSeg**</a><br>
It includes two subsets. <br>
***Keyboard:*** CT scan, Segmentation <br>
<a href="https://arxiv.org/abs/2210.09309"> ![paper](src/paper.png)</a> | <a href="https://arxiv.org/abs/2109.09521"> ![paper](src/paper.png)</a> <br>
![licence](src/CcLogo.png) CC BY-NC 4.0

- <a href="https://www.kaggle.com/datasets/kmader/rsna-bone-age"> **RSNA Bone Age**</a> (Radiological Society of North America 2017) <br>
Identify the age of a child from an X-ray of their hand <br>
***Keyboard:*** X-ray, Labeled<br>
<a href="https://pubmed.ncbi.nlm.nih.gov/30480490"> ![paper](src/paper.png)</a> | <a href="https://pubmed.ncbi.nlm.nih.gov/30615556"> ![paper](src/paper.png)</a> | <a href="https://pubmed.ncbi.nlm.nih.gov/29095675"> ![paper](src/paper.png)</a>

- <a href="https://www.rsna.org/rsnai/ai-image-challenge/cervical-spine-fractures-ai-detection-challenge-2022"> **RSNA Cervical Spine Fracture**</a> (Radiological Society of North America 2022) <br>
Including approximately 3,000 CT <br>
***Keyboard:*** CT scan, Labeled<br>
<a href="https://www.kaggle.com/competitions/rsna-2022-cervical-spine-fracture-detection/leaderboard"> ![Leaderboard](src/leaderboard.png)</a>

- <a href="https://spider.grand-challenge.org"> **SPIDER**</a> (SPIne Segmentation: Discs, vERtebrae, and spinal canal)<br>
A lumbar spine MR dataset with reference segmentations of vertebrae, intervertebral discs (IVDs), and spinal canal <br>
***Keyboard:*** MRI <br>
<a href="https://spider.grand-challenge.org/evaluation/challenge/leaderboard"> ![Leaderboard](src/leaderboard.png)</a> | <a href="https://arxiv.org/abs/2306.12217"> ![paper](src/paper.png)</a><br>
![licence](src/CcLogo.png) CC-BY 4.0

- <a href="https://tianchi.aliyun.com/dataset/79463"> **Spinal Disease Dataset**</a><br>
The dataset includes MRI images of T1 and T2 sagittal plane and T2 axial plane (FSE/TSE).<br>
***Keyboard:*** MRI, Segmentation, Labeled<br>
![licence](src/CcLogo.png) CC-BY-SA-NC 4.0

- <a href="http://spineweb.digitalimaginggroup.ca"> **SpineWeb**</a> <br>
16 spinal imaging datasets

- <a href="https://github.com/anjany/verse"> **VerSe**</a> <br> Large Scale Vertebrae Segmentation <br>
***Keyboard:*** CT scan, Segmentation <br>
<a href="https://verse2019.grand-challenge.org/evaluation/challenge/leaderboard"> ![Leaderboard](src/leaderboard.png)</a> | <a href="https://www.sciencedirect.com/science/article/abs/pii/S1361841521002127"> ![paper](src/paper.png)</a> | <a href="https://pubs.rsna.org/doi/10.1148/ryai.2020190138"> ![paper](src/paper.png)</a><br>
![licence](src/CcLogo.png) CC BY-SA 4.0

- <a href="https://lit.fe.uni-lj.si/xVertSeg/overview.php"> **xVertSeg**</a> <br>
Classify and segment vertebrae from the spine images that include fractured and non-fractured cases <br>
***Keyboard:*** CT scan, Segmentation, Classification <br>



### Joints

- <a href="https://data.mendeley.com/datasets/jf3pv98m9g/2"> **DDH x-ray images**</a> <br>
The hip X-ray images (in anteroposterior view) including 354 subjects (120 DDH, 234 normal)<br>
***Keyboard:*** Developmental dysplasia of the hip (DDH), Labeled<br>
<a href="https://bmcmedinformdecismak.biomedcentral.com/articles/10.1186/s12911-022-01957-9"> ![paper](src/paper.png)</a><br>
![licence](src/CcLogo.png) CC BY 4.0

- <a href="https://k2s.grand-challenge.org"> **K2S**</a> <br>
A dataset of high-resolution 3D knee MRI including raw k-space data and post-processing annotations with masks for tissue segmentation. <br>
***Keyboard:*** MRI, Labeled<br>
![licence](src/CcLogo.png) CC BY NC ND

- <a href="https://www.kaggle.com/datasets/shashwatwork/knee-osteoarthritis-dataset-with-severity"> **Knee Osteoarthritis Dataset with Severity Grading**</a> <br>
***Keyboard:*** X-ray, Labeled<br>
![licence](src/CcLogo.png) CC BY 4.0

- <a href="http://www.riteh.uniri.hr/~istajduh/projects/kneeMRI"> **kneeMRI**</a> <br>
The dataset consists of 917 12-bit grayscale volumes of either left or right knees. <br>
***Keyboard:*** MRI scans, Labeled<br>
<a href="https://pubmed.ncbi.nlm.nih.gov/28254071"> ![paper](src/paper.png)</a> <br>
![licence](src/CcLogo.png) CC BY-NC-ND 4.0

- <a href="https://knoap2020.grand-challenge.org"> **KNOAP2020**</a> (KNee OsteoArthritis Prediction) <br>
***Keyboard:*** MRI scans, X-ray, Labeled<br>
<a href="https://www.oarsijournal.com/article/S1063-4584(22)00864-0/fulltext"> ![paper](src/paper.png)</a> <br>
![licence](src/CcLogo.png) The provided data may only be used for preparing an entry to be submitted to this challenge.

- <a href="https://aimi.stanford.edu/lera-lower-extremity-radiographs"> **LERA**</a> (Lower Extremity Radiographs)<br>
Data is collected from 182 patients who underwent a radiographic examination. The dataset consists of images of the foot, knee, ankle, or hip associated with each patient.<br>
***Keyboard:*** X-ray<br>
![licence](src/CcLogo.png) Stanford University School of Medicine LERA- Lower Extremity RAdiographs Dataset Research Use Agreement

- <a href="https://stanfordmlgroup.github.io/competitions/mrnet"> **MRNet**</a> <br>
Diagnosis of abnormalities from Knee MRs <br>
***Keyboard:*** MRI, Labeled<br>
<a href="https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.1002699"> ![paper](src/paper.png)</a><br>
![licence](src/CcLogo.png) Stanford University School of Medicine MRNet Dataset Research Use Agreement

- <a href="https://pubdata.zib.de"> **OAI**</a> (Osteoarthritis Initiative) <br>
The dataset contains cases of moderate and severe OA. <br>
***Keyboard:*** MRI<br>
<a href="https://www.sciencedirect.com/science/article/pii/S1361841518304882"> ![paper](src/paper.png)</a>

- <a href="https://github.com/StanfordMIMI/skm-tea"> **SKM-TEA**</a> (Stanford Knee MRI Multi-Task Evaluation)<br>
The dataset consists of 86 scans for training, 33 scans for validation, and 36 scans for testing. <br>
***Keyboard:*** MRI, Segmentation, Labeled <br>
<a href="https://openreview.net/forum?id=YDMFgD_qJuA"> ![paper](src/paper.png)</a><br>
![licence](src/CcLogo.png) Stanford University School of Medicine SKM-TEA Dataset Research Use Agreement

- <a href="https://data.mendeley.com/datasets/zm6bxzhmfz/1"> **X-ray images of the hip joints**</a> <br>
A dataset consisting of x-ray examinations of the lower legs performed as part of routine medical service. <br>
![licence](src/CcLogo.png) CC BY 4.0


<!---
### Muscles
-->

_______

## Pelvis and Reproductive Organs

### Female Reproductive Organs

- <a href="https://a-afma.grand-challenge.org"> **A-AFMA**</a> (Automatic amniotic fluid measurement and analysis) <br>
The goal is measurement of the maximum vertical pocket (MVP) <br>
***Keyboard:*** Ultrasound Video Clip <br>
![licence](src/CcLogo.png) No publication rights are given on this data.  The data may only be used for the purpose of this challenge.

- <a href="https://github.com/cwwang1979/MICCAI_ATEC23challenge"> **ATEC23**</a> <br>
Automated prediction of treatment effectiveness in ovarian cancer using histopathological images <br>
***Keyboard:*** Whole Slide Images (WSIs), Cancer <br>
<a href="https://arxiv.org/abs/2310.12866"> ![paper](src/paper.png)</a><br>
![licence](src/CcLogo.png) CC BY-NC 4.0

- <a href="https://github.com/parham-ap/cytology_dataset"> **Cervix93**</a> <br>
A Cervical Cytology Dataset for Nucleus Detection and Image Classification and Methods for Cervical Nucleus Detection <br>
***Keyboard:*** Pap smear, Cancer, Labeled <br>
<a href="https://arxiv.org/abs/1811.09651"> ![paper](src/paper.png)</a>

- <a href="https://www.cancerimagingarchive.net/collection/cptac-ucec"> **CPTAC-UCEC**</a> (Clinical Proteomic Tumor Analysis Consortium Uterine Corpus Endometrial Carcinoma) <br>
***Keyboard:*** Multi-modality, Cancer <br>
![licence](src/CcLogo.png) CC BY 3.0

- <a href="https://mde-lab.aegean.gr/index.php/downloads"> **DTU/HERLEV (PAP-SMEAR)**</a> <br>
***Keyboard:*** Pap smear, Labeled <br>
<a href="https://www.researchgate.net/publication/265873515_Pap-smear_Benchmark_Data_For_Pattern_Classification"> ![paper](src/paper.png) Benchmark</a>

- <a href="https://zenodo.org/records/7372187"> **ENDO-AID**</a> <br>
The dataset consists of 91 digital pathology whole-slide images (WSI) of endometrium carcinoma Pipelle biopsies, stained with hematoxylin and eosin (H&E). <br>
***Keyboard:*** Whole-slide images (WSI), Cancer <br>
![licence](src/CcLogo.png) Creative Commons Attribution Non Commercial 4.0 International 

- <a href="https://www.ucl.ac.uk/interventional-surgical-sciences/weiss-open-research/weiss-open-data-server/fetoscopy-placenta-data"> **Fetoscopy Placenta**</a> <br>
The dataset contains 483 frames with ground-truth vessel segmentation annotations taken from six different in vivo fetoscopic procedure videos. <br>
***Keyboard:*** Segmentation, Labeled <br>
<a href="https://arxiv.org/abs/2007.04349"> ![paper](src/paper.png)</a><br>
![licence](src/CcLogo.png) CC BY-NC-SA 4.0

- <a href="https://hc18.grand-challenge.org"> **HC18**</a> <br>
Measurement of fetal head circumference (HC)<br>
***Keyboard:*** Ultrasound imaging, Labeled <br>
<a href="https://hc18.grand-challenge.org/evaluation/challenge/leaderboard/"> ![Leaderboard](src/leaderboard.png)</a>

- <a href="https://www.kaggle.com/c/intel-mobileodt-cervical-cancer-screening/overview"> **Intel & MobileODT Cervical Cancer Screening**</a><br>
***Keyboard:*** Colposcopy, Classification, Cancer <br>

- <a href="https://figshare.com/articles/dataset/JNU-IFM/14371652"> **JNU-IFM**</a> <br>
An intrapartum transperineal ultrasound dataset of the Intelligent Fetal Monitoring <br>
***Keyboard:*** Ultrasound videos, Labeled <br>
<a href="https://www.sciencedirect.com/science/article/pii/S2352340922001160"> ![paper](src/paper.png)</a><br>
![licence](src/CcLogo.png) CC BY 4.0

- <a href="https://data.mendeley.com/datasets/zddtpgzv63/4"> **Liquid based-cytology Pap smear**</a> <br>
The repository consists of a total of 963 LBC images <br>
***Keyboard:*** Pap Smear, Labeled <br>
<a href="https://www.sciencedirect.com/science/article/pii/S2352340920304832"> ![paper](src/paper.png)</a><br>
![licence](src/CcLogo.png) CC BY 4.0

- <a href="https://github.com/cv516Buaa/MMOTU_DS2Net">**MMOTU**</a> (Multi-Modality Ovarian Tumor Ultrasound Image) <br>
It consists of two sub-sets with two modalities, which are OTU_2d and OTU_CEUS respectively including 1469 2d ultrasound images and 170 CEUS images.<br>
***Keyboard:*** Labeled, Segmentation, Classification, Cancer <br>
<a href="https://arxiv.org/abs/2207.06799"> ![paper](src/paper.png)</a>

- <a href="https://cs.adelaide.edu.au/~carneiro/isbi14_challenge/">**Overlapping Cervical Cytology Image Segmentation**</a><br>
The targets are to extract the boundaries of individual cytoplasm and nucleus from overlapping cervical cytology images.<br>
***Keyboard:*** Segmentation, Cancer<br>
<a href="https://cs.adelaide.edu.au/~carneiro/isbi14_challenge/results_release.html"> ![Leaderboard](src/leaderboard.png)</a>

- <a href="https://cs.adelaide.edu.au/~carneiro/isbi15_challenge">**Overlapping Cervical Cytology Image Segmentation 2**</a><br>
The targets are to extract the boundaries of individual cytoplasm and nucleus from overlapping cervical cytology images.<br>
***Keyboard:*** Segmentation, Cancer<br>
<a href="https://cs.adelaide.edu.au/~carneiro/isbi15_challenge/results.html"> ![Leaderboard](src/leaderboard.png)</a>

- <a href="https://ps-fh-aop-2023.grand-challenge.org"> **Ps-Fh-Aop-2023**</a> (Pubic Symphysis-Fetal Head Segmentation and Angle of Progression) <br>
***Keyboard:*** Ultrasound imaging, Labeled <br>
<a href="https://ps-fh-aop-2023.grand-challenge.org/evaluation/phase-two/leaderboard"> ![Leaderboard](src/leaderboard.png)</a>

- <a href="https://www.cancerimagingarchive.net/collection/tcga-cesc"> **TCGA-CESC**</a> (The Cancer Genome Atlas Cervical Squamous Cell Carcinoma and Endocervical Adenocarcinoma Collection)<br>
Data from 54 subjects.<br>
***Keyboard:*** MRI<br>
![licence](src/CcLogo.png) CC BY 3.0

- <a href="https://www.cancerimagingarchive.net/collection/tcga-ov"> **TCGA-OV**</a> (The Cancer Genome Atlas Ovarian Cancer)<br>
Data from 143 subjects and 53,662 images.<br>
***Keyboard:*** Ovary, MRI, CT scan<br>
![licence](src/CcLogo.png) CC BY 3.0

- <a href="https://www.cancerimagingarchive.net/collection/tcga-ucec"> **TCGA-UCEC**</a> (The Cancer Genome Atlas Uterine Corpus Endometrial Carcinoma)<br>
Data from 65 subjects and 77214 images<br>
***Keyboard:*** Multi-modality<br>
![licence](src/CcLogo.png) CC BY 3.0

- <a href="https://www.cs.uoi.gr/~marina/sipakmed.html"> **SIPaKMeD**</a> <br>
The database consists of 4049 images of isolated cells that have been manually cropped from 966 cluster cell images of Pap smear slides. <br>
***Keyboard:*** Pap smear, Labeled <br>
<a href="https://ieeexplore.ieee.org/abstract/document/8451588"> ![paper](src/paper.png)</a><br>
![licence](src/CcLogo.png) It can be used for experimental purposes with the request to cite the paper.



### Male Reproductive Organs

- <a href="https://aggc22.grand-challenge.org">**AGGC22**</a> (Automated Gleason Grading Challenge 2022) <br>
Dataset of prostatectomy and biopsy specimens with annotations  <br>
***Keyboard:*** H&E-stained whole slide image <br>
<a href="https://aggc22.grand-challenge.org/evaluation/challenge/leaderboard"> ![Leaderboard](src/leaderboard.png)</a> | <a href="https://www.researchgate.net/publication/363780482_Comprehensive_AI_Model_Development_for_Gleason_Grading_From_Scanning_Cloud-based_Annotation_to_Pathologist-AI_Interaction"> ![paper](src/paper.png)</a><br>
![licence](src/CcLogo.png) CC BY-NC-SA 4.0

- <a href="https://auto-rtp.grand-challenge.org">**AUTO-RTP**</a> (Fully Automated Radiotherapy Treatment Planning) <br>
***Keyboard:*** Cancer<br>
<a href="https://auto-rtp.grand-challenge.org/evaluation/data-format-confirmation/leaderboard"> ![Leaderboard](src/leaderboard.png)</a><br>
![licence](src/CcLogo.png) Use of the data is restricted to this challenge and related publications

- <a href="https://zenodo.org/records/13254318">**BIMCV-Prostate**</a><br>
It includes a total of 9,341 prostate MRI sessions, distributed among 8,441 subjects.<br>
***Keyboard:*** Cancer<br>
![licence](src/CcLogo.png) CC BY 4.0

- <a href="https://www.cancerimagingarchive.net/collection/cmb-pca">**CMB-PCA**</a> (Cancer Moonshot Biobank - Prostate Cancer) <br>
***Keyboard:*** Multi-modality <br>
![licence](src/CcLogo.png) CC BY 4.0 - TCIA Restricted 

- <a href="https://gleason2019.grand-challenge.org"> **Gleason 2019**</a> <br>
Gleason grading of prostate cancer in digital histopathology images <br>
***Keyboard:*** H&E-stained histopathology image, Cancer, Labeled <br>
<a href="https://gleason2019.grand-challenge.org/Results"> ![Leaderboard](src/leaderboard.png)</a>

- <a href="https://i2cvb.github.io"> **I2CVB**</a> (Initiative for Collaborative Computer Vision Benchmarking)<br>
It provides a multi-parametric MRI dataset to help at the development of computer-aided detection and diagnosis system. <br>
***Keyboard:*** MRI, Segmentation, Labaled<br>
<a href="https://www.sciencedirect.com/science/article/abs/pii/S001048251500058X"> ![paper](src/paper.png)</a>

- <a href="https://liuquande.github.io/SAML"> **Multi-site Dataset for Prostate MRI Segmentation**</a><br>
It contains prostate T2-weighted MRI data (with segmentation mask) collected from six different data sources out of three public datasets.<br>

- <a href="https://www.cancerimagingarchive.net/analysis-result/isbi-mr-prostate-2013"> **NCI-ISBI 2013**</a><br>
Automated Segmentation of Prostate Structures. Image data were selected from PROSTATE-DIAGNOSIS and Prostate-3T collections <br>
***Keyboard:*** MRI, Labeled <br>
![licence](src/CcLogo.png) CC BY 3.0

- <a href="https://www.kaggle.com/c/prostate-cancer-grade-assessment"> **PANDA**</a> (Prostate cANcer graDe Assessment) <br>
Classifying the severity of prostate cancer from microscopy scans of prostate biopsy samples <br>
***Keyboard:*** whole-slide images (WSI), Cancer <br>
<a href="https://www.nature.com/articles/s41591-021-01620-2"> ![paper](src/paper.png)</a><br>
![licence](src/CcLogo.png) Subject to Competition Rules

- <a href="https://pi-cai.grand-challenge.org/"> **PI-CAI**</a> (Prostate Imaging: Cancer AI) <br>
***Keyboard:*** Prostate, MRI, Cancer, Labeled <br>
<a href="https://pi-cai.grand-challenge.org/evaluation/open-development-phase/leaderboard/"> ![Leaderboard](src/leaderboard.png)</a>

- <a href="https://promise12.grand-challenge.org"> **PROMISE12**</a> (Prostate MR Image Segmentation 2012) <br>
Compare interactive and (semi)-automatic segmentation algorithms for MRI of the prostate <br>
***Keyboard:*** T2-weighted MRI, Labeled <br>
<a href="https://promise12.grand-challenge.org/evaluation/challenge/leaderboard"> ![Leaderboard](src/leaderboard.png)</a> | <a href="https://www.sciencedirect.com/science/article/abs/pii/S1361841513001734"> ![paper](src/paper.png) Overview paper</a>

- <a href="https://www.cancerimagingarchive.net/collection/prostate-3t"> **Prostate-3T**</a><br>
Prostate transversal T2-weighted magnetic resonance images acquired on a 3.0T Siemens TrioTim using only a pelvic phased-array coil were acquired for prostate cancer detection. <br>
***Keyboard:*** MRI <br>
![licence](src/CcLogo.png) CC BY 3.0

- <a href="https://www.cancerimagingarchive.net/collection/prostate-diagnosis"> **PROSTATE-DIAGNOSIS**</a><br>
Prostate cancer T1- and T2-weighted magnetic resonance images were acquired at 1.5 T <br>
***Keyboard:*** MRI <br>
![licence](src/CcLogo.png) CC BY 3.0

- <a href="https://www.na-mic.org/wiki/2009_prostate_segmentation_challenge_MICCAI"> **Prostate segmentation 2009**</a><br>
***Keyboard:*** MRI<br>

- <a href="https://www.cancerimagingarchive.net/collection/prostatex"> **PROSTATEx**</a><br>
This dataset have been included in the PI-CAI Public Training and Development dataset. <br>
***Keyboard:*** MRI, Cancer <br>
![licence](src/CcLogo.png) CC BY 3.0

- <a href="https://wiki.cancerimagingarchive.net/display/Public/QIN-PROSTATE-Repeatability"> **QIN-PROSTATE-Repeatability**</a> <br>
This is a dataset with multiparametric prostate MRI applied in a test-retest setting, allowing to evaluate repeatability of the MRI-based measurements in the prostate. <br>
***Keyboard:*** MRI, Labeled <br>
<a href="https://www.nature.com/articles/sdata2018281"> ![paper](src/paper.png)</a><br>
![licence](src/CcLogo.png) CC BY 4.0

- <a href="https://www.cancerimagingarchive.net/collection/tcga-prad"> **TCGA-PRAD**</a> (The Cancer Genome Atlas Prostate Adenocarcinoma)<br>
Data from 14 subjects and 16,790 images.<br>
***Keyboard:*** Multi-modality<br>
![licence](src/CcLogo.png) CC BY 3.0



______
## Other Organs and Systems

### Lymph Nodes

- <a href="https://www.cancerimagingarchive.net/collection/calgb50303"> **CALGB50303**</a> <br>
Rituximab and Combination Chemotherapy in Treating Patients With Diffuse Large B-Cell Non-Hodgkin's Lymphoma <br>
***Keyboard:*** Cancer, Multi-modality<br>
<a href="https://ascopubs.org/doi/10.1200/JCO.18.01994"> ![paper](src/paper.png)</a> | <a href="https://ashpublications.org/blood/article/135/25/2224/452697/Prognostic-value-of-interim-FDG-PET-in-diffuse"> ![paper](src/paper.png)</a>

- <a href="https://camelyon16.grand-challenge.org"> **CAMELYON16**</a> <br>
Detection of metastases in hematoxylin and eosin (H&E) stained whole-slide images of lymph node sections <br>
***Keyboard:*** Cancer, Digital pathology, Lymph node detection <br>
<a href="https://camelyon16.grand-challenge.org/Results"> ![Leaderboard](src/leaderboard.png)</a> | <a href="https://jamanetwork.com/journals/jama/article-abstract/2665774"> ![paper](src/paper.png)</a> | <a href="https://academic.oup.com/gigascience/article/7/6/giy065/5026175"> ![paper](src/paper.png)</a>

- <a href="https://camelyon17.grand-challenge.org"> **CAMELYON17**</a> <br>
Evaluate new and existing algorithms for automated detection and classification of breast cancer metastases in whole-slide images of histological lymph node sections <br>
***Keyboard:*** Cancer, Digital pathology, Lymph node detection <br>
<a href="https://camelyon17.grand-challenge.org/evaluation/challenge/leaderboard"> ![Leaderboard](src/leaderboard.png)</a> | <a href="https://ieeexplore.ieee.org/document/8447230"> ![paper](src/paper.png)</a> | <a href="https://academic.oup.com/gigascience/article/7/6/giy065/5026175"> ![paper](src/paper.png)</a>

- <a href="https://wiki.cancerimagingarchive.net/pages/viewpage.action?pageId=19726546"> **CT Lymph nodes**</a> <br>
90 CTs dataset of lymph nodes <br>
***Keyboard:*** CT scan, Lymph node detection <br>
![licence](src/CcLogo.png) CC BY 3.0

- <a href="https://www.cancerimagingarchive.net/collection/dlbcl-morphology">**DLBCL-Morphology**</a><br>
H&E and immunohistochemical stain images of 209 cases of diffuse large B-cell lymphoma linked with cytogenetic features and clinical outcomes. <br>
***Keyboard:*** Histopathology, Cancer <br>
![licence](src/CcLogo.png) CC BY-NC 4.0

- <a href="https://lnq2023.grand-challenge.org"> **LNQ2023**</a> (Mediastinal Lymph Node Quantification) <br>
Segmentation of Heterogeneous CT Data <br>
***Keyboard:*** CT scan, Cancer  <br>
<a href="https://lnq2023.grand-challenge.org/evaluation/validation/leaderboard/"> ![Leaderboard](src/leaderboard.png)</a>

- <a href="https://huggingface.co/datasets/andreped/LyNoS"> **LyNoS**</a>  <br>
15 CTs with corresponding lymph nodes, azygos, esophagus, and subclavian carotid arteries  <br>
***Keyboard:*** CT scan, Segmentation <br>
<a href="https://www.tandfonline.com/doi/full/10.1080/21681163.2022.2043778"> ![paper](src/paper.png)</a>

- <a href="https://github.com/basveeling/pcam"> **PatchCamelyon**</a> <br>
Image classification dataset consists of 327.680 color images extracted from histopathologic scans of lymph node sections. <br>
***Keyboard:*** Labeled <br>
<a href="https://patchcamelyon.grand-challenge.org/evaluation/challenge/leaderboard"> ![Leaderboard](src/leaderboard.png)</a> | <a href="https://arxiv.org/abs/1806.03962"> ![paper](src/paper.png)</a>



### Skin

- <a href="https://www.cancerimagingarchive.net/collection/anti-pd-1_melanoma">**Anti-PD-1_MELANOMA**</a><br>
This collection includes 47 melanoma cases treated with anti-PD1 immunotherapy, each with pre-treatment and 1 or more imaging follow-up timepoints. <br>
***Keyboard:*** Multi-modality, Cancer <br>
![licence](src/CcLogo.png) TCIA Restricted

- <a href="https://www.cancerimagingarchive.net/collection/cptac-cm">**CPTAC-CM**</a> (Clinical Proteomic Tumor Analysis Consortium Cutaneous Melanoma) <br>
***Keyboard:*** Multi-modality, Cancer <br>
![licence](src/CcLogo.png) CC BY 3.0

- <a href="https://ddi-dataset.github.io"> **DDI**</a> (Diverse Dermatology Images)<br>
A biopsy-proven skin disease dataset with diverse skin tone representation. <br>
***Keyboard:*** Labeled <br>
<a href="https://www.science.org/doi/full/10.1126/sciadv.abq6147"> ![paper](src/paper.png)</a>

- <a href="https://licensing.edinburgh-innovations.ed.ac.uk/product/dermofit-image-library"> **Dermofit Image Library**</a><br>
1300 High quality skin lesion images. <br>
***Keyboard:*** Segmentation, Labeled<br>

- <a href="https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/DBW86T"> **HAM10000**</a> <br>
A collection of multi-source dermatoscopic images of common pigmented skin lesions <br>
***Keyboard:*** Dermatoscopic images <br>

- <a href="https://challenge.isic-archive.com/data"> **ISIC**</a> (International Skin Imaging Collaboration) <br>
It has multi versions. <br>
***Keyboard:*** Dermoscopic images <br>
<a href="https://arxiv.org/abs/1605.01397"> ![paper](src/paper.png)</a> | 
<a href="https://ieeexplore.ieee.org/document/8363547"> ![paper](src/paper.png)</a> | <a href="https://arxiv.org/abs/1902.03368"> ![paper](src/paper.png)</a>

- <a href="https://www.uco.es/grupos/ayrna/ieeetmi2015"> **Melanoma Dataset**</a> <br>
***Keyboard:*** Classification, Dermatoscopic images <br>
<a href="https://ieeexplore.ieee.org/document/7348708"> ![paper](src/paper.png)</a>

- <a href="https://www.fc.up.pt/addi/ph2%20database.html"> **PH<sup>2</sup>**</a> <br>
The database contains a total of 200 dermoscopic images of melanocytic lesions <br>
***Keyboard:*** Classification, Segmentation, Dermoscopic images, Labeled <br>
<a href="https://pubmed.ncbi.nlm.nih.gov/24110966"> ![paper](src/paper.png)</a>

- <a href="https://uwaterloo.ca/vision-image-processing-lab/research-demos/skin-cancer-detection"> **Skin Cancer Detection**</a><br>
This includes images extracted from the public databases DermIS and DermQuest, along with manual segmentations of the lesions. <br>
***Keyboard:*** Segmentation, Cancer<br>



______
## Multi Organs Datasets

- <a href="https://www.cancerimagingarchive.net/collection/aapm-rt-mac"> **AAPM-RT-MAC**</a><br>
The data contains a total of 55 MRI cases, each from a single examination from a distinct patient.<br>
***Keyboard:*** *Head and Neck*<br>
![licence](src/CcLogo.png) TCIA Restricted

- <a href="https://github.com/MrGiovanni/AbdomenAtlas"> **AbdomenAtlas**</a> <br>
8,448 CT volumes, totaling 3.2 million CT slices. <br>
***Keyboard:*** *Spleen, liver, kidneys, stomach, gallbladder, pancreas, aorta, and IVC*, CT Scan, Segmentation, Labeled <br>
<a href="https://arxiv.org/abs/2305.09666"> ![paper](src/paper.png)</a> <br>
![licence](src/CcLogo.png) CC BY-NC 4.0

- <a href="https://abdomenct-1k-fully-supervised-learning.grand-challenge.org"> **AbdomenCT-1K**</a> <br>
The dataset with more than 1000 (1K) abdominal organ scans. <br>
***Keyboard:*** *liver, kidney, spleen, and pancreas*, CT Scan, Segmentation, Labeled <br>
<a href="https://arxiv.org/abs/2010.14808"> ![paper](src/paper.png)</a>

 - <a href="https://www.kaggle.com/datasets/ignaciorlando/ussimandsegm"> **Abdominal ultrasound simulation scans**</a> <br>
The scans were acquired from 11 subjects without any abdominal pathology or known disease. <br>
***Keyboard:*** *Liver, kidney, pancreas, vessels, adrenals, 
 gallbladder, bones, spleen*, Ultrasound (US) imaging, Segmentation, Labeled <br>

- <a href="https://isbi-aida.grand-challenge.org"> **AIDA-E**</a> (Analysis of Images to Detect Abnormalities in Endoscopy)<br>
***Keyboard:*** Multi tissues, Endoscopy, Cancer<br>

- <a href="https://zenodo.org/records/7155725#.Y0OOCOxBztM"> **AMOS**</a> <br>
A large-scale abdominal multi-organ benchmark for versatile medical image segmentation <br>
***Keyboard:***  Multi-tissue (15 abdominal organs), MRI, CT scan<br>
<a href="https://amos22.grand-challenge.org/evaluation/amos-ct-regular-evaluation/leaderboard"> ![Leaderboard](src/leaderboard.png)</a>

- <a href="https://anhir.grand-challenge.org"> **ANHIR**</a> (Automatic Non-rigid Histological Image Registration)<br>
They have assembled 8 datasets, containing 355 images with 18 different stains, resulting in 481 image pairs to be registered.<br>
***Keyboard:***  Multi-tissue, Whole-slide images<br>
<a href="https://anhir.grand-challenge.org/evaluation/challenge/leaderboard"> ![Leaderboard](src/leaderboard.png)</a> | <a href="https://ieeexplore.ieee.org/document/9058666"> ![paper](src/paper.png)</a>

- <a href="https://www.cancerimagingarchive.net/collection/apollo-5"> **APOLLO-5**</a> (Applied Proteogenomics OrganizationaL Learning and Outcomes)<br>
A collection of 31 datasets for different organs. <br>
***Keyboard:*** Cancer, Multi-modality<br>
![licence](src/CcLogo.png) TCIA Limited (contact Support)

- <a href="https://www.cancerimagingarchive.net/collection/fdg-pet-ct-lesions"> **AutoPET**</a><br>
A whole-body FDG-PET/CT dataset with manually annotated tumor lesions (FDG-PET-CT-Lesions) <br>
***Keyboard:*** PET - CT scan, Labeled <br>
![licence](src/CcLogo.png) TCIA Restricted 

- <a href="https://neurips22-cellseg.grand-challenge.org"> **Cell Segmentation in Multi-modality Microscopy Images**</a> <br>
***Keyboard:*** Multi tissues, High-Resolution Microscopy Images, Segmentation, Labeled <br>
<a href="https://neurips22-cellseg.grand-challenge.org/evaluation/testing/leaderboard"> ![Leaderboard](src/leaderboard.png)</a> | <a href="https://arxiv.org/abs/2308.05864"> ![paper](src/paper.png) Summary Paper</a> <br>
![licence](src/CcLogo.png) CC BY-NC-ND

- <a href="https://chaos.grand-challenge.org"> **CHAOS**</a> (Combined (CT-MR) Healthy Abdominal Organ Segmentation) <br>
There are 20 training and 20 testing cases in the CT dataset. MRI dataset contains 20 training and 20 testing cases with T1-Dual and T2 SPIR sequences. <br>
***Keyboard:*** *Liver, Kidneys, Spleen*, CT Scan, MRI, Labeled <br>
<a href="https://chaos.grand-challenge.org/evaluation/challenge/leaderboard"> ![Leaderboard](src/leaderboard.png)</a> | <a href="https://www.sciencedirect.com/science/article/abs/pii/S1361841520303145"> ![paper](src/paper.png)</a>

- <a href="https://www.cancerimagingarchive.net/collection/cptac-sar"> **CPTAC-SAR**</a> (The Clinical Proteomic Tumor Analysis Consortium SARcomas)<br>
***Keyboard:*** *Abdomen, Arm, Bladder, Chest, Head-Neck, Kidney, Leg, Retroperitoneum, Stomach, and Uterus*, Multi-modality<br>
![licence](src/CcLogo.png) CC BY 3.0

- <a href="https://www.cancerimagingarchive.net/collection/ct-org"> **CT-ORG**</a><br>
This dataset consists of 140 computed tomography scans come from a wide variety of sources. <br>
***Keyboard:*** *Bone, Liver, Lung, Kidney and Bladder*, CT scan<br>
![licence](src/CcLogo.png) CC BY 3.0

- <a href="http://medicaldecathlon.com"> **Decathlon**</a> <br>
Medical Segmentation Decathlon (MSD) Generalisable 3D Semantic Segmentation. <br>
***Keyboard:***  *Liver, Brain, Hippocampus, Lung, Prostate, Cardiac, Pancreas, Colon,  Hepatic Vessels  and Spleen*, Multi-modality, Labeled <br>
<a href="http://medicaldecathlon.com/results"> ![Leaderboard](src/leaderboard.png)</a> | <a href="https://www.nature.com/articles/s41467-022-30695-9"> ![paper](src/paper.png)</a> | <a href="https://arxiv.org/abs/1902.09063"> ![paper](src/paper.png)</a> <br>
![licence](src/CcLogo.png) CC-BY-SA 4.0

- <a href="https://nihcc.app.box.com/v/DeepLesion"> **DeepLesion**</a><br>
A dataset with 32,735 lesions in 32,120 CT slices from 10,594 studies of 4,427 unique patients. <br>
***Keyboard:*** *Bone, Abdomen, Mediastinum, Liver, Lung, Kidney, Soft tissue, and Pelvis*, CT scan, Cancer<br>
<a href="https://www.spiedigitallibrary.org/journals/journal-of-medical-imaging/volume-5/issue-03/036501/DeepLesion--automated-mining-of-large-scale-lesion-annotations-and/10.1117/1.JMI.5.3.036501.full#_=_"> ![paper](src/paper.png)</a>

- <a href="https://ead2019.grand-challenge.org/"> **EAD 2019**</a> (Endoscopy artifact detection) <br>
Facilitating diagnosis and treatment of diseases in hollow organs. <br>
***Keyboard:***  Multi-tissue, Multi-modality, Video Endoscopy, Labeled <br>
<a href="https://ead2019.grand-challenge.org/evaluation/challenge/leaderboard"> ![Leaderboard](src/leaderboard.png)</a> | <a href="https://arxiv.org/abs/1905.03209"> ![paper](src/paper.png)</a>

- <a href="https://ead2020.grand-challenge.org"> **EAD 2020**</a> (Endoscopy artifact detection) <br>
The 8 classes in this challenge include specularity, bubbles, saturation, contrast, blood, instrument, blur and imaging artefacts. <br>
***Keyboard:***  Multi-tissue, Multi-modality, Video Endoscopy, Labeled <br>
<a href="https://www.researchgate.net/publication/344671984_Endoscopic_Artefact_Detection_with_Ensemble_of_Deep_Neural_Networks_and_False_Positive_Elimination"> ![paper](src/paper.png)</a>

- <a href="https://fastmri.med.nyu.edu"> **fastMRI**</a><br>
***Keyboard:*** *Knee, Brain, and Prostate*, MRI<br>
<a href="https://arxiv.org/abs/1811.08839"> ![paper](src/paper.png)</a> | <a href="https://pubs.rsna.org/doi/10.1148/ryai.2020190007"> ![paper](src/paper.png)</a> | <a href="https://arxiv.org/abs/2304.09254"> ![paper](src/paper.png)</a>

- <a href="https://fastpet-ld.grand-challenge.org"> **fastPET-LD**</a> (Fast PET-CT lesion detection) <br>
***Keyboard:*** Hot spots, PET - CT scan, Labeled, Detection <br>
<a href="https://fastpet-ld.grand-challenge.org/evaluation/challenge/leaderboard"> ![Leaderboard](src/leaderboard.png)</a> <br>
![licence](src/CcLogo.png) Participants cannot share the data, cannot use it for any commercial purpose.

- <a href="https://flare22.grand-challenge.org"> **FLARE 2022**</a> (Fast and Low-resource semi-supervised Abdominal oRgan sEgmentation) <br>
A small number of labeled cases (50) and a large number of unlabeled cases (2000) in the training set. <br>
***Keyboard:***  Multi-tissue (13 organs), CT scan, Labeled <br>
<a href="https://flare22.grand-challenge.org/evaluation/testing-dsc/leaderboard"> ![Leaderboard](src/leaderboard.png)</a> | <a href="https://arxiv.org/abs/2308.05862"> ![paper](src/paper.png)</a>

- <a href="https://flare.grand-challenge.org"> **FLARE21**</a> (Fast and Low GPU memory Abdominal oRgan sEgmentation) <br>
A abdominal CT organ dataset with 500 CT scans from 11 countries, including multi-center, multi-phase, multi-vendor, and multi-disease cases. <br>
***Keyboard:*** *Liver, Kidney, Spleen, and Pancreas*, CT scan, Cancer, Segmentation<br>
<a href="https://flare.grand-challenge.org/evaluation/challenge/leaderboard"> ![Leaderboard](src/leaderboard.png)</a> | <a href="https://www.sciencedirect.com/science/article/abs/pii/S1361841522002444"> ![paper](src/paper.png) Summary Paper</a>

- <a href="https://han-seg2023.grand-challenge.org"> **HaN-Seg**</a> (Head and Neck Segmentation) <br>
Images of 60 patients aged 34–79 years that were appointed for image-guided Radiotherapy in the HaN region <br>
***Keyboard:*** *30 organs-at-risk*, CT Scan, MRI, Labeled <br>
<a href="https://han-seg2023.grand-challenge.org/evaluation/challenge/leaderboard"> ![Leaderboard](src/leaderboard.png)</a> | <a href="https://aapm.onlinelibrary.wiley.com/doi/full/10.1002/mp.16197"> ![paper](src/paper.png)</a>

- <a href="http://www.imagenglab.com/wiki/mediawiki/index.php?title=2015_MICCAI_Challenge"> **Head and Neck Auto Segmentation**</a><br>
With manual segmentation of left and right parotid glands, brainstem, optic chiasm, optic nerves (both left and right), mandible, submandibular glands (both left and right) and manual identification of bony landmarks..<br>
***Keyboard:*** CT scan, Labeled<br>
<a href="https://aapm.onlinelibrary.wiley.com/doi/10.1002/mp.12197"> ![paper](src/paper.png)</a>

- <a href="https://www.cancerimagingarchive.net/collection/head-neck-radiomics-hn1"> **HEAD-NECK-RADIOMICS-HN1**</a><br>
This collection contains clinical data and computed tomography (CT) from 137 head and neck squamous cell carcinoma (HNSCC) patients treated by radiotherapy. <br>
***Keyboard:*** CT Scan, Segmentation, Labeled <br>
<a href="https://www.nature.com/articles/ncomms5006"> ![paper](src/paper.png)</a> <br>
![licence](src/CcLogo.png) TCIA No Commercial Limited - CC BY-NC 3.0

- <a href="https://hecktor.grand-challenge.org"> **HECKTOR**</a> (HEad and neCK TumOR segmentation and outcome prediction) <br>
The data were collected for a total of 883 cases consisting of FDG-PET/CT images and clinical information. <br>
***Keyboard:*** *Head, Neck, Lymph nodes*, FDG-PET/CT images, Cancer, Labeled <br>
<a href="https://hecktor.grand-challenge.org/evaluation/challenge/leaderboard"> ![Leaderboard](src/leaderboard.png)</a> | <a href="https://pubmed.ncbi.nlm.nih.gov/37195050"> ![paper](src/paper.png) Overview paper</a>

- <a href="https://academictorrents.com/details/7a638ed187a6180fd6e464b3666a6ea0499af4af"> **LC25000**</a> <br>
The dataset contains color 25,000 Lung and colon histopathological images <br>
***Keyboard:*** *Lung and Colon*, Cancer, Labeled <br>
<a href="https://arxiv.org/abs/1912.12142v1"> ![paper](src/paper.png)</a>

- <a href="https://www.cancerimagingarchive.net/collection/ldct-and-projection-data"> **LDCT-and-Projection-data**</a> (Low Dose CT)<br>
Reconstructed images, patient age and gender, and pathology annotation are also provided for these de-identified data sets.<br>
***Keyboard:*** *Head, Chest, and Abdomen*, CT scan<br>
<a href="https://aapm.onlinelibrary.wiley.com/doi/10.1002/mp.14594"> ![paper](src/paper.png)</a> | <a href="https://aapm.onlinelibrary.wiley.com/doi/10.1118/1.4935406"> ![paper](src/paper.png)</a><br>
![licence](src/CcLogo.png) TCIA Restricted - CC BY 3.0

- <a href="https://learn2reg.grand-challenge.org"> **Learn2Reg 2024**</a> <br>
The dataset has over 46,000 nuclei, 71 patients, four organs, and four nucleus types.<br>
***Keyboard:*** Multi-modality, Registration<br>
<a href="https://learn2reg.grand-challenge.org/evaluation/challenge/leaderboard"> ![Leaderboard](src/leaderboard.png)</a>

- <a href="https://lyon19.grand-challenge.org"> **LYON19**</a> <br>
The test set contains Region of Interests (ROIs) selected from whole-slide images (WSI) of immunohistochemistry (IHC) stained specimens <br>
***Keyboard:*** *breast, colon, prostate*, whole-slide images (WSI) <br>
<a href="https://lyon19.grand-challenge.org/evaluation/challenge/leaderboard"> ![Leaderboard](src/leaderboard.png)</a> | <a href="https://www.sciencedirect.com/science/article/abs/pii/S1361841519300829"> ![paper](src/paper.png)</a>

- <a href="https://medfm2023.grand-challenge.org"> **MedFMC**</a> <br>
Foundation Model Prompting for Medical Image Classification <br>
***Keyboard:*** *Thoracic and Colon*, Multli Modalities <br>
<a href="https://medfm2023.grand-challenge.org/evaluation/challenge-for-public-long-term/leaderboard"> ![Leaderboard](src/leaderboard.png)</a>

- <a href="https://www.medseg.ai"> **MedSeg**</a><br>
An AI tool for segmentation CT scan and MRI images. There are segmented images of other public dataset in their website<br>

- <a href="https://medshapenet.ikim.nrw"> **MedShapeNet**</a> <br>
This dataset contains over 100,000 3D medical shapes, including bones, organs, vessels, muscles, etc., as well as surgical instruments. It has used in <a href='https://autoimplant.grand-challenge.org'> AutoImplant </a> <br>
<a href="https://proj-page.github.io/medshapenet_publications.html"> ![paper](src/paper.png)</a><br>
![licence](src/CcLogo.png) CC BY NC 4.0

- <a href="https://monusac-2020.grand-challenge.org"> **MoNuSAC2020**</a> <br>
The dataset has over 46,000 nuclei, 71 patients, four organs, and four nucleus types.<br>
***Keyboard:*** *Lung, Prostate, Kidney, and Breast*, H&E staining, Classification, Segmentation<br>
<a href="https://monusac-2020.grand-challenge.org/Results"> ![Leaderboard](src/leaderboard.png)</a> | <a href="https://ieeexplore.ieee.org/abstract/document/9446924"> ![paper](src/paper.png) Details</a> <br>
![licence](src/CcLogo.png) CC BY-NC-SA 4.0

- <a href="https://monuseg.grand-challenge.org"> **MoNuSeg**</a><br>
***Keyboard:*** Multi tissues, H&E stained tissue images, Segmentation, Labeled <br>
<a href="https://monuseg.grand-challenge.org/Results"> ![Leaderboard](src/leaderboard.png)</a> | <a href="https://ieeexplore.ieee.org/document/8880654"> ![paper](src/paper.png)</a><br>
![licence](src/CcLogo.png) CC BY-NC-SA 4.0

- <a href="http://mridata.org"> **MRIdata**</a> <br>
It is a list of magnetic resonance imaging raw k-space datasets. <br>
***Keyboard:*** MRI <br>
![licence](src/CcLogo.png) CC BY-NC 4.0

- <a href="https://www.synapse.org/#!Synapse:syn3193805/wiki"> **Multi-Atlas Labeling Beyond the Cranial Vault**</a> <br>
It has two subdatasets: Abdominal and Cervix<br>
***Keyboard:*** Multi tissues, CT scan, Segmentation, Labeled <br>
<a href="https://www.synapse.org/#!Synapse:syn3193805/wiki/94514"> ![Leaderboard](src/leaderboard.png)</a>

- <a href="https://zenodo.org/records/1169361#.YETa43UzYUE"> **Multi-organ Abdominal CT**</a><br>
The data comprises reference segmentations for 90 abdominal CT images delineating multiple organs. <br>
***Keyboard:*** *Spleen, Left kidney, Gallbladder, Esophagus, Liver, Stomach, Pancreas and Duodenum*, CT scan<br>
<a href="https://ieeexplore.ieee.org/document/8291609"> ![paper](src/paper.png)</a>

- <a href="https://www.kaggle.com/datasets/ipateam/nuinsseg"> **NuInsSeg**</a> (Nuclei Instance Segmentation)<br>
This dataset contains 665 image patches with more than 30,000 manually segmented nuclei from 31 human and mouse organs. <br>
***Keyboard:*** Multi organs, H&E-Stained Images, Labeled<br>
<a href="https://arxiv.org/abs/2308.01760"> ![paper](src/paper.png)</a>

- <a href="https://lunit-io.github.io/research/ocelot_dataset"> **OCELOT**</a> <br>
A dataset purposely dedicated to the study of cell-tissue relationships for cell detection in histopathology <br>
***Keyboard:*** *Kidney, Head-neck, Prostate, Stomach, Endometrium, and Bladder*, Whole-slide images (WSIs) <br>
<a href="https://ocelot2023.grand-challenge.org/evaluation/challenge/leaderboard"> ![Leaderboard](src/leaderboard.png)</a> | <a href="https://arxiv.org/abs/2303.13110"> ![paper](src/paper.png)</a><br>
![licence](src/CcLogo.png) CC-BY-NC 4.0

- <a href="https://data.mendeley.com/datasets/rscbjbr9sj/2"> **OCT and Chest X-Ray images**</a><br>
***Keyboard:*** *Eye and Chest*, OCT, X-ray, Classification, Labeled<br>
<a href="https://www.cell.com/cell/fulltext/S0092-8674(18)30154-5"> ![paper](src/paper.png)</a><br>
![licence](src/CcLogo.png) CC BY 4.0

- <a href="https://www.olympus-europa.com/medical/en/Products-and-Solutions/Medical-Solutions/EndoAtlas"> **Olympus EndoAtlas**</a> <br>
It is solely for use by qualified medical professionals. <br>
***Keyboard:*** *Esophagus, stomach, Pancreatobiliary, Small-intestine, and Colorectum*, Gastrointestinal video endoscopy, EndoCapsule <br>

- <a href="https://paip2021.grand-challenge.org"> **PAIP2021**</a> <br>
Detection of Perineural Invasion in Multiple Organ Cancer <br>
***Keyboard:*** *Colon, Prostate and Pancreatobiliary tract*, Whole-slide images (WSIs), Cancer, Labeled <br>
<a href="https://paip2021.grand-challenge.org/evaluation/validation/leaderboard"> ![Leaderboard](src/leaderboard.png)</a><br>
![licence](src/CcLogo.png) CC BY-NC 4.0

- <a href="https://warwick.ac.uk/fac/cross_fac/tia/data/pannuke"> **PanNuke**</a> <br>
Nuclei labels across 19 different tissue types.<br>
***Keyboard:*** Multi-tissue, whole-slide images (WSIs), Classification, Segmentation<br>
<a href="https://link.springer.com/chapter/10.1007/978-3-030-23937-4_2"> ![paper](src/paper.png) Details</a> | <a href="https://arxiv.org/abs/2003.10778"> ![paper](src/paper.png) Details</a><br>
![licence](src/CcLogo.png) CC BY-NC-SA 4.0

- <a href="https://huggingface.co/datasets/flaviagiammarino/path-vqa"> **PathVQA**</a> (Pathology Visual Question Answering)<br>
This version of the dataset contains a total of 5,004 images and 32,795 question-answer pairs.<br>
***Keyboard:*** Labeled, Text<br>
<a href="https://arxiv.org/abs/2003.10286"> ![paper](src/paper.png)</a><br>
![licence](src/CcLogo.png) MIT License

- <a href="https://huggingface.co/datasets/xmcmic/PMC-VQA"> **PMC-VQA**</a><br>
It contains 227k VQA (Visual Question Answerin) pairs of 149k images, covering various modalities or diseases <br>
***Keyboard:*** Multi-modality, Labeled<br>
<a href="https://arxiv.org/abs/2305.10415"> ![paper](src/paper.png)</a>

- <a href="https://www.rsna.org/rsnai/ai-image-challenge/abdominal-trauma-detection-ai-challenge"> **RSNA Abdominal Trauma Detection**</a> (Radiological Society of North America 2023) <br>
Including more than 4,000 CT exams with various abdominal injuries and a roughly equal number of cases without injury. <br>
***Keyboard:*** *Liver, Spleen, Kidneys, and Bowel*, CT scan, Labeled<br>
<a href="https://www.kaggle.com/competitions/rsna-2023-abdominal-trauma-detection/leaderboard"> ![Leaderboard](src/leaderboard.png)</a>

- <a href="https://zenodo.org/records/7056076"> **SCR**</a><br>
Segmentations Chest X-Rays images from JSRT. <br>
***Keyboard:*** *Lungs, Heart, Clavicle*, Labeled<br>
<a href="https://www.sciencedirect.com/science/article/abs/pii/S1361841505000368"> ![paper](src/paper.png)</a><br>
![licence](src/CcLogo.png) CC BY 4.0

- <a href="https://segrap2023.grand-challenge.org"> **SegRap2023**</a> <br>
A Benchmark of Organs-at-Risk and Gross Tumor Volume Segmentation for Radiotherapy Planning of Nasopharyngeal Carcinoma <br>
***Keyboard:*** *45 organs-at-risk*, CT Scan, Cancer <br>
<a href="https://segrap2023.grand-challenge.org/evaluation/challenge/leaderboard"> ![Leaderboard](src/leaderboard.png)</a> | <a href="https://arxiv.org/abs/2312.09576"> ![paper](src/paper.png)</a>

- <a href="https://competitions.codalab.org/competitions/21145"> **SegTHOR**</a> (Segmentation of THoracic Organs at Risk)<br>
The dataset includes 60 3D CT scans, divided into a training set of 40 and a test set of 20 patients. <br>
***Keyboard:*** *Heart, Aorta, Trachea, and Esophagus*, CT Scan, Cancer, Labeled <br>
<a href="https://competitions.codalab.org/competitions/21145#results"> ![Leaderboard](src/leaderboard.png)</a> | <a href="https://ieeexplore.ieee.org/document/9286453"> ![paper](src/paper.png)</a>

- <a href="https://www.smir.ch/objects/214315"> **SMIR**</a> <br>
This collection contains post mortem CT scans of the whole body. <br>
![licence](src/CcLogo.png) CC_BY_NC_SA_3.0

- <a href="https://www.cancerimagingarchive.net/collection/soft-tissue-sarcoma"> **Soft-tissue-Sarcoma**</a> <br>
A radiomics model from joint FDG-PET and MRI texture features for the prediction of lung metastases in soft-tissue sarcomas of the extremities. <br>
<a href="https://iopscience.iop.org/article/10.1088/0031-9155/60/14/5471"> ![paper](src/paper.png)</a> <br>
![licence](src/CcLogo.png) CC BY 3.0

- <a href="https://structseg2019.grand-challenge.org"> **StructSeg2019**</a> <br>
Segmentation of organs-at-risk (OAR) and gross target volume (GTV) of tumors of two types of cancers, nasopharynx cancer and lung cancer, for radiation therapy planning. <br>
***Keyboard:*** *Head & neck, Lung*, CT scans, Cancer, Labeled <br>

- <a href="https://www.cancerimagingarchive.net/collection/tcga-sarc"> **TCGA-SARC**</a> (The Cancer Genome Atlas Sarcoma)<br>
Data from 5 subjects and 5653 images<br>
***Keyboard:*** *Chest-Abdomen-Pelvis, Leg, and TSpine*, Multi-modality, Segmentation <br>
![licence](src/CcLogo.png) CC BY 3.0 

- <a href="https://tma.im"> **tma**</a><br>
Stanford Tissue Microarray Database<br>
***Keyboard:*** Multi tissue <br>
<a href="https://tma.im/tma_portal"> ![paper](src/paper.png)</a>

- <a href="https://zenodo.org/records/10047292"> **TotalSegmentator**</a><br>
1228 images with segmented 117 anatomical structures
***Keyboard:*** Multi-tissue, CT scan, Segmentation, Labeled<br>
<a href="https://pubs.rsna.org/doi/10.1148/ryai.230024"> ![paper](src/paper.png)</a><br>
![licence](src/CcLogo.png) CC BY 4.0 

- <a href="https://ultra-low-dose-pet.grand-challenge.org"> **Ultra-low Dose PET Imaging**</a> <br>
The dataset contains 1447 subjects of whole-body 18F-FDG PET imaging <br>
***Keyboard:*** Positron emission tomography (PET) <br>

- <a href="https://ultrasoundenhance2023.grand-challenge.org"> **USenhance 2023**</a> (Ultrasound Image Enhancement) <br>
***Keyboard:*** *Thyroid, Carotid artery, Breast, Liver, and Kidney*, Ultrasound imaging <br>
<a href="https://ultrasoundenhance2023.grand-challenge.org/evaluation/1st-validationresults-submission-only/leaderboard"> ![Leaderboard](src/leaderboard.png)</a>

- <a href="https://github.com/HiLab-git/WORD"> **WORD**</a><br>
This dataset contains 150 abdominal CT volumes (30495 slices). <br>
***Keyboard:*** 16 organs, CT scan, Segmentation<br>
<a href="https://arxiv.org/abs/2111.02403"> ![paper](src/paper.png)</a><br>
![licence](src/CcLogo.png) GNU General Public License v3.0



______
## Notes and Contributions

The papers mentioned only use or explain the datasets. They are here to make it easier to find them. You don't have to cite them. <br>
**To know how to refer to each dataset and be sure of their latest usage license, <u>check its description</u>.** <br>
If you find any issues with the datasets (like broken links, order, description, etc.), please let me know.<br>
If you know of any other datasets that aren't on the list, please ***contribute*** and add them to make the list more complete.

__________________
